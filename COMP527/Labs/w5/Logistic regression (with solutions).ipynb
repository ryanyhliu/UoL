{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "union-gardening",
   "metadata": {},
   "source": [
    "# Logistic Regression (Spam Email Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-steel",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this lab we will develop a Spam email classifier using Logistic Regression.\n",
    "\n",
    "We will use [SPAM E-mail Database](https://www.kaggle.com/somesh24/spambase) from Kaggle, which was split into two almost equal parts: training dataset (train.csv) and test dataset (test.csv).\n",
    "Each record in the datasets contains 58 features, one of which is the class label. The class label is the last feature and it takes two values +1 (spam email) and -1 (non-spam email). The other features represent various characteristics of emails such as frequencies of certain words or characters in the text of an email; and lengths of sequences of consecutive capital letters (See [SPAM E-mail Database](https://www.kaggle.com/somesh24/spambase) for the detailed description of the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unlikely-dietary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-buddy",
   "metadata": {},
   "source": [
    "We start with implementing some auxiliary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alert-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement sigmoid function\n",
    "def sigmoid(x):\n",
    "    # Bound the argument to be in the interval [-500, 500] to prevent overflow\n",
    "    x = np.clip( x, -500, 500 )\n",
    "\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legitimate-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    labels = []\n",
    "    features = []\n",
    "    \n",
    "    with open(fname) as F:\n",
    "        next(F) # skip the first line with feature names\n",
    "        for line in F:\n",
    "            p = line.strip().split(',')\n",
    "            labels.append(int(p[-1]))\n",
    "            features.append(np.array(p[:-1], float))\n",
    "    return (np.array(labels), np.array(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-wheel",
   "metadata": {},
   "source": [
    "Next we read the training and the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tender-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingLabels, trainingData) = load_data(\"train.csv\")\n",
    "(testLabels, testData) = load_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-vertical",
   "metadata": {},
   "source": [
    "In the files the positive objects appear before the negative objects. So we reshuffle both datasets to avoid situation when we present to our training algorithm all positive objects and then all negative objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "straight-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshuffle training data and\n",
    "permutation =  np.random.permutation(len(trainingData))\n",
    "trainingLabels = trainingLabels[permutation]\n",
    "trainingData = trainingData[permutation]\n",
    "\n",
    "#test data\n",
    "permutation =  np.random.permutation(len(testData))\n",
    "testLabels = testLabels[permutation]\n",
    "testData = testData[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-blair",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Implement Logistic Regression training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hazardous-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(trainingData, trainingLabels, learningRate, maxIter):\n",
    "    #Compute the number of training objects\n",
    "    numTrainingObj = len(trainingData)\n",
    "    #Compute the number of features (dimension of our data)\n",
    "    numFeatures = len(trainingData[0])\n",
    "    \n",
    "    #Initialize the bias term and the weights\n",
    "    b = 0\n",
    "    W = np.zeros(numFeatures, dtype=np.float64)\n",
    "    \n",
    "    for t in range(maxIter):\n",
    "        #For every training object\n",
    "        for i in range(numTrainingObj):\n",
    "            X = trainingData[i]\n",
    "            y = trainingLabels[i]\n",
    "            #Compute the activation score\n",
    "            a = np.dot(X, W) + b\n",
    "        \n",
    "            #Update the bias term and the weights\n",
    "            b = b + learningRate*y*sigmoid(-y*a)\n",
    "            for s in range(numFeatures):\n",
    "                W[s] = W[s] + learningRate*y*sigmoid(-y*a)*X[s]\n",
    "            \n",
    "            #The above for-loop can be equivalently written in the vector form as follows\n",
    "            #W = np.add(W, learningRate*y*sigmoid(-y*a)*X)\n",
    "            \n",
    "    return (b, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-bottle",
   "metadata": {},
   "source": [
    "2. Use the training dataset to train Logistic Regression classifier. Use learningRate=0.1 and maxIter=10. Output the bias term and the weight vector of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "juvenile-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias term:  -363.15951816758025 \n",
      "Weight vector:  [ -10.90024438 -113.58073666  -20.31922296   41.807         1.73756728\n",
      "   21.08258423   58.13454541   33.98006613   13.25749851   -7.92082525\n",
      "   13.96809494 -220.03480134   17.21060329   -7.28913832   20.86422556\n",
      "  117.82563519   25.38574793   35.92883048   -7.46213282   38.64263399\n",
      "   31.99293727  104.11697144   57.3855778    65.42787761 -622.12434161\n",
      " -282.79789999 -271.27507826 -149.26978826  -91.98978349  -96.88667151\n",
      "  -61.28572679  -41.62719017 -108.67554666  -42.79419017 -120.17175428\n",
      "  -76.71996123 -153.05430971   -3.543       -88.57889446  -38.14753387\n",
      "  -58.59188729 -136.6373994   -61.21603343  -77.16082483 -129.01717334\n",
      "  -81.85799361   -7.282       -39.31316575  -11.22401092  -78.57425684\n",
      "  -12.38227811  102.9264842    45.92032563    6.77756225 -268.76593695\n",
      "  250.70487775   67.32478733]\n"
     ]
    }
   ],
   "source": [
    "(b,W) = logisticRegression(trainingData, trainingLabels, 0.1, 10)\n",
    "print(\"Bias term: \", b, \"\\nWeight vector: \", W) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-focus",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Implement Logistic Regression classifier with given bias term and weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "whole-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionTest(b, W, X):\n",
    "    #Compute the activation score\n",
    "    a = np.dot(X, W) + b\n",
    "    predictedClass = 0;\n",
    "    confidence = 0;\n",
    "    \n",
    "    if a > 0:\n",
    "        predictedClass = +1\n",
    "        confidence = sigmoid(a)\n",
    "    else:\n",
    "        predictedClass = -1\n",
    "        confidence = 1-sigmoid(a)\n",
    "    return (predictedClass, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-louisiana",
   "metadata": {},
   "source": [
    "2. Use the trained model to classify objects in the test dataset. Output an evaluation report (accuracy, precision, recall, F-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "favorite-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationReport(classTrue, classPred):\n",
    "    positive_mask = classTrue == 1\n",
    "\n",
    "    # Count the number of elements in the positive class \n",
    "    positive = np.count_nonzero(positive_mask)\n",
    "    # Count True Positive\n",
    "    tp = np.count_nonzero(classPred[positive_mask]==1)\n",
    "    # Count False Negative\n",
    "    fn = np.count_nonzero(classPred[positive_mask]==-1)\n",
    "    \n",
    "    negative_mask = classTrue == -1\n",
    "\n",
    "    # Count the number of elements in the negative class \n",
    "    negative = np.count_nonzero(negative_mask)\n",
    "    # Count False Positive\n",
    "    fp = np.count_nonzero(classPred[negative_mask]==1)\n",
    "    # Count True Negative\n",
    "    tn = np.count_nonzero(classPred[negative_mask]==-1)\n",
    "\n",
    "    # Compute Accuracy, Precision, Recall, and F-score\n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    fscore = 2*precision*recall/(precision + recall)\n",
    "    print(\"Evaluation report\")\n",
    "    print(\"Accuracy: %.2f\" % accuracy)\n",
    "    print(\"Precision: %.2f\" % precision)\n",
    "    print(\"Recall: %.2f\" % recall)\n",
    "    print(\"F-score: %.2f\" % fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "committed-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report\n",
      "Accuracy: 0.50\n",
      "Precision: 0.44\n",
      "Recall: 0.99\n",
      "F-score: 0.61\n"
     ]
    }
   ],
   "source": [
    "classTrue = np.array([int(x) for x in testLabels], dtype=int)\n",
    "classPred = np.array([int(logisticRegressionTest(b,W,X)[0]) for X in testData], dtype=int)\n",
    "evaluationReport(classTrue, classPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-accessory",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "1. Apply Gaussian Normalisation to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "continental-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianNormalisation(dataset):\n",
    "    #Compute the number of features\n",
    "    numFeatures = len(dataset[0])\n",
    "    \n",
    "    featureMean = np.empty(numFeatures, float)\n",
    "    featureStd = np.empty(numFeatures, float)\n",
    "    \n",
    "    #For every feature\n",
    "    for i in range(numFeatures):\n",
    "        #find its Mean and Std\n",
    "        featureMean[i] = dataset[:,i].mean(axis=0)\n",
    "        featureStd[i] = dataset[:,i].std(axis=0)\n",
    "        #Apply Gaussian Noramlisation\n",
    "        dataset[:,i] = (dataset[:,i] - featureMean[i])/featureStd[i]\n",
    "\n",
    "    return (featureMean, featureStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the training dataset\n",
    "(featureMean, featureStd) = GaussianNormalisation(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-excuse",
   "metadata": {},
   "source": [
    "2. Train Logistic Regression on the normalised training dataset. Use learningRate=0.1 and maxIter=10. Output the bias term and the weight vector of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mobile-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias term:  -3.8700230572307306 \n",
      "Weight vector:  [ 0.30622392 -0.29738268 -0.04827423  0.97898444  0.22550381  0.22235831\n",
      "  1.23644039  0.3995184   0.1675739  -2.17212054 -0.19072859 -0.14266101\n",
      " -0.38107243  0.18353617  0.45252564  1.17780158  0.63921452  0.23452619\n",
      " -0.28650925  0.38656092  0.24308377  2.38975508  1.08884446  1.62427053\n",
      " -4.78985762 -1.03482003 -6.3825585   0.17206847 -1.15155976  0.0880132\n",
      " -1.74818719  0.01457053 -0.44550382 -0.71287809 -1.09124483  0.46843464\n",
      " -0.63134178  0.3124822  -0.2318435  -0.00810798 -3.07630166 -2.57784402\n",
      " -0.06993102 -1.29041026 -0.50645505 -0.6733586  -0.67205198 -1.83949287\n",
      "  0.45092734 -0.03057094 -0.43808852  1.31808973  1.67539497  1.65398792\n",
      " -0.80748744  1.34248496  0.75888506]\n"
     ]
    }
   ],
   "source": [
    "#Train Logistic Regression classifier on the normalised training data\n",
    "(b,W) = logisticRegression(trainingData, trainingLabels, 0.1, 10)\n",
    "print(\"Bias term: \", b, \"\\nWeight vector: \", W) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-reference",
   "metadata": {},
   "source": [
    "3. Normalise the test dataset using Means and Standard Deviations of the features *computed on the training dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "leading-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(dataset, featureMean, featureStd):\n",
    "    #Compute the number of features\n",
    "    numFeatures = len(dataset[0])\n",
    "    \n",
    "    #For every feature\n",
    "    for i in range(numFeatures):\n",
    "        #Apply Gaussian Noramlisation with given Mean and Std values\n",
    "        dataset[:,i] = (dataset[:,i] - featureMean[i])/featureStd[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "engaged-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the test dataset using Means and Std computed on the training dataset\n",
    "normalise(testData, featureMean, featureStd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-constant",
   "metadata": {},
   "source": [
    "4. Use the model trained on the normalised training dataset to classify objects in the normalised test dataset. Output an evaluation report (accuracy, precision, recall, F-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "photographic-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report\n",
      "Accuracy: 0.88\n",
      "Precision: 0.83\n",
      "Recall: 0.89\n",
      "F-score: 0.86\n"
     ]
    }
   ],
   "source": [
    "#Predict class labels of test objects for the normalized test dataset\n",
    "classPred = np.array([int(logisticRegressionTest(b,W,X)[0]) for X in testData], dtype=int)\n",
    "evaluationReport(classTrue, classPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-syndication",
   "metadata": {},
   "source": [
    "5. Compare the quality of the classifier with normalisation and without normalisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
