{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsu1oL3hTGtu"
      },
      "source": [
        "## A simple game\n",
        "\n",
        "We need to define actions, states, state transitions, rewards and the discount factor.\n",
        "\n",
        "An MDP is a 5-tuple, $\\langle S, A, R, P, \\gamma \\rangle$\n",
        "\n",
        "--16 states\n",
        "\n",
        "--4 actions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r_bLH54S1_k",
        "outputId": "1f14cc75-e80c-481e-fb79-817c59bd0a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P [[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n",
            "-----------------------------\n",
            "R [[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]]\n",
            "\n",
            " [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "# Define the gridworld environment\n",
        "n_states = 16\n",
        "n_actions = 4\n",
        "P = np.zeros((n_states, n_actions, n_states))  # transition probabilities\n",
        "R = np.zeros((n_states, n_actions, n_states))  # rewards\n",
        "gamma = 0.9  # discount factor\n",
        "\n",
        "# Fill in the transition probabilities and rewards\n",
        "for s in range(n_states):\n",
        "    for a in range(n_actions):\n",
        "        if s == 0 or s == 15:\n",
        "            P[s, a, s] = 1\n",
        "        else:\n",
        "            if a == 0:  # up\n",
        "                s_prime = s - 4\n",
        "            elif a == 1:  # down\n",
        "                s_prime = s + 4\n",
        "            elif a == 2:  # left\n",
        "                s_prime = s - 1\n",
        "            else:  # right\n",
        "                s_prime = s + 1\n",
        "            if s_prime < 0:\n",
        "              s_prime = 0\n",
        "            if s_prime > 15:\n",
        "              s_prime = 15\n",
        "\n",
        "            if s_prime == 0:\n",
        "                R[s, a, s_prime] = -1  # start state\n",
        "            elif s_prime == 15:\n",
        "                R[s, a, s_prime] = 10  # goal state\n",
        "            else:\n",
        "                R[s, a, s_prime] = -1  # other states\n",
        "            P[s, a, s_prime] = 1 # 在这个特定的环境中，无论你在哪个状态执行什么动作，你都会确定地转移到一个新的状态，所以状态转移概率总是1\n",
        "\n",
        "print(\"P\", P)\n",
        "print(\"-----------------------------\")\n",
        "print(\"R\", R)\n",
        "# P[s, a, s_prime]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6dD3sSVDCc"
      },
      "source": [
        "## Solution - DP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MbgBxKWUVCuY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]]\n",
            "(State  0 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  1 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  2 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  3 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  4 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  5 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  6 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  7 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  8 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  9 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  10 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  11 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  12 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  13 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  14 ) Actions [0.25 0.25 0.25 0.25]\n",
            "(State  15 ) Actions [0.25 0.25 0.25 0.25]\n",
            "Value function:\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "Value function:\n",
            "[[ 0.         -2.36003667 -2.84272002 -2.80977835]\n",
            " [-2.8029887  -3.20188587 -3.02005022 -2.39774911]\n",
            " [-2.00161733 -1.60308234 -0.53564463  1.61922876]\n",
            " [ 2.35218862  3.05878273  5.06770607  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Define the policy (arbitrary for now)\n",
        "policy = np.ones((n_states, n_actions)) / n_actions # 初始化一个均匀策略，即在每个状态下，所有动作的选择概率都是相等的。\n",
        "\n",
        "print(policy)\n",
        "for s in range(n_states):\n",
        "  print(\"(State \", s, \") Actions\", policy[s])\n",
        "\n",
        "# Policy evaluation algorithm\n",
        "V = np.zeros(n_states)  # initial value function estimate 初始化状态价值函数为零。\n",
        "print(\"Value function:\")\n",
        "print(V.reshape(4, 4))\n",
        "tolerance = 1e-6  # convergence tolerance 设置收敛阈值。\n",
        "while True: # 开始策略评估\n",
        "    delta = 0\n",
        "    for s in range(n_states):\n",
        "        v = V[s]\n",
        "        bellman_update = 0 # 初始化贝尔曼更新为零。\n",
        "        for a in range(n_actions):\n",
        "            for s_prime in range(n_states):\n",
        "                bellman_update += policy[s, a] * P[s, a, s_prime] * (R[s, a, s_prime] + gamma * V[s_prime]) # 根据贝尔曼期望方程进行更新\n",
        "        V[s] = bellman_update\n",
        "        delta = max(delta, abs(v - V[s]))\n",
        "    if delta < tolerance: # 如果最大差值小于阈值，则停止迭代。\n",
        "        break\n",
        "\n",
        "print(\"Value function:\")\n",
        "print(V.reshape(4, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY6O4iKMaj5a"
      },
      "source": [
        "## Q-learning algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w2DLt6Tod0r",
        "outputId": "4754aa26-0167-4f0b-cd45-947aa08e84c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Environment\n",
        "E = np.zeros(n_states).reshape(4, 4)\n",
        "E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzFly1mtafAd",
        "outputId": "a729712b-c79d-4ca1-892b-2ac089b8ccd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5575\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3073\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9893: Starting at state 15\n",
            "\n",
            "Episode 9894: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.0207\n",
            "Exploring: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8916\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9895: Starting at state 9\n",
            "Random probability for epsilon-greedy: 0.1985\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1117\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9896: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.2130\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2315\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4915\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9897: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.5984\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999958321012, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.19999996248891\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6664\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8248\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.45663836  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9898: Starting at state 8\n",
            "Random probability for epsilon-greedy: 0.0503\n",
            "Exploring: Selected action 0\n",
            "State: 8, Action: 0, Next State: 4, Reward: -1.0\n",
            "Q(s,a) old: 4.456638355550858, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.468974519995771\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1696\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6106\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2181\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9899: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.4717\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9900: Starting at state 0\n",
            "\n",
            "Episode 9901: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.8863\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9902: Starting at state 15\n",
            "\n",
            "Episode 9903: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.2531\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999996  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9904: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.5683\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.19999996248891, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999966240018\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8195\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2868\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9905: Starting at state 15\n",
            "\n",
            "Episode 9906: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.9423\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8522\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6255\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9907: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.1001\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9908: Starting at state 11\n",
            "Random probability for epsilon-greedy: 0.5615\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9909: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.3660\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3661\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9607\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9910: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.4843\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1246\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6583\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9911: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.2762\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9793\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3206\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5260\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9912: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.6824\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8437\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5218\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5515\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2337\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9913: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.3849\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5310\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6056\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9914: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.9137\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9915: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.2893\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999966240018, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999969616015\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6959\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3771\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9916: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.8103\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9917: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.4744\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1507\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3384\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9206\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9918: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.1458\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0430\n",
            "Exploring: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7794\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9919: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.2707\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9920: Starting at state 0\n",
            "\n",
            "Episode 9921: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.8911\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6417\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.9984523   6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0693\n",
            "Exploring: Selected action 1\n",
            "State: 10, Action: 1, Next State: 14, Reward: -1.0\n",
            "Q(s,a) old: 7.998452295352086, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.998607065816877\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8066\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9922: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.4339\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3228\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5497\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9923: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.1025\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2546\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9924: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.4798\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9925: Starting at state 11\n",
            "Random probability for epsilon-greedy: 0.8932\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9926: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.7996\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3441\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4444\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9927: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.3066\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57984019  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0450\n",
            "Exploring: Selected action 0\n",
            "State: 10, Action: 0, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579840187650621, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579856168885558\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         3.94435622  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0987\n",
            "Exploring: Selected action 2\n",
            "State: 6, Action: 2, Next State: 5, Reward: -1.0\n",
            "Q(s,a) old: 3.9443562188348746, Reward: -1.0, Max Q(s',a'): 6.199999969616015, Q target: 4.579999972654414, Q(s,a) updated: 4.007920594216829\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4830\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999969616015, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999972654413\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9810\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1518\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9928: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.6385\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9929: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.9074\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5534\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3013\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9960\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7607\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9930: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.9515\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3443\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1984\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999997  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9931: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.8637\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999972654413, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999975388971\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2079\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2269\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9932: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.3875\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8715\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1304\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2285\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9933: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.3730\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1203\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4375\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9934: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.8109\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999975388971, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999977850074\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6553\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6586\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9935: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.6125\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6044\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9936: Starting at state 15\n",
            "\n",
            "Episode 9937: Starting at state 15\n",
            "\n",
            "Episode 9938: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.8735\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7666\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18241759]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0246\n",
            "Exploring: Selected action 3\n",
            "State: 6, Action: 3, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.182417592869808, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.1841758335828265\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1925\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2812\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9939: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.5045\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6385\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4197\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9940: Starting at state 8\n",
            "Random probability for epsilon-greedy: 0.1565\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7494\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9941: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.4766\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.96909685  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0675\n",
            "Exploring: Selected action 0\n",
            "State: 2, Action: 0, Next State: 0, Reward: -1.0\n",
            "Q(s,a) old: -0.9690968456173674, Reward: -1.0, Max Q(s',a'): 0.0, Q target: -1.0, Q(s,a) updated: -0.9721871610556306\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9942: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.5184\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2688\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9943: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.3758\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9944: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.6674\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5180\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4909\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6755\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9945: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.1921\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9931\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6465\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9946: Starting at state 9\n",
            "Random probability for epsilon-greedy: 0.2379\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9615\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9947: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.2135\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7317\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5823\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9948: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.3633\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8936\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3581\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7983\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9949: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.7018\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9950: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.7492\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9951: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.2575\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9995\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9952: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.1401\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9953: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.5767\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8098\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9954: Starting at state 0\n",
            "\n",
            "Episode 9955: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.1503\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9418\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9956: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.8773\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7655\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4651\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.46044464]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9957: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.0316\n",
            "Exploring: Selected action 3\n",
            "State: 2, Action: 3, Next State: 3, Reward: -1.0\n",
            "Q(s,a) old: 4.46044464116958, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.472400177052622\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6056\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2484\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6256\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9958: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.5795\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4902\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9959: Starting at state 11\n",
            "Random probability for epsilon-greedy: 0.9993\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9960: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.9789\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9961: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.2655\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999977850074, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999980065066\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8564\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2156\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9962: Starting at state 0\n",
            "\n",
            "Episode 9963: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.7324\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999980065066, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999982058558\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1930\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2093\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9964: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.6188\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999982058558, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999983852702\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5169\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3972\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9965: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.0269\n",
            "Exploring: Selected action 3\n",
            "State: 5, Action: 3, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1120\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7332\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8567\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9966: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.2475\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3570\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7027\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9967: Starting at state 15\n",
            "\n",
            "Episode 9968: Starting at state 15\n",
            "\n",
            "Episode 9969: Starting at state 11\n",
            "Random probability for epsilon-greedy: 0.0607\n",
            "Exploring: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9970: Starting at state 11\n",
            "Random probability for epsilon-greedy: 0.8619\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9971: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.9376\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2259\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9972: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.6669\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4408\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9973: Starting at state 15\n",
            "\n",
            "Episode 9974: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.9293\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6265\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9975: Starting at state 12\n",
            "Random probability for epsilon-greedy: 0.3963\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9976: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.4226\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8821\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2583\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9977: Starting at state 0\n",
            "\n",
            "Episode 9978: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.4728\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9994\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3633\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4719\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6997\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9979: Starting at state 8\n",
            "Random probability for epsilon-greedy: 0.5793\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6546\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9980: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.6285\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.5783\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3999\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9981: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.8741\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1053\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4691\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999998  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9982: Starting at state 5\n",
            "Random probability for epsilon-greedy: 0.2178\n",
            "Exploiting: Selected action 1\n",
            "State: 5, Action: 1, Next State: 9, Reward: -1.0\n",
            "Q(s,a) old: 6.199999983852702, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.19999998546743\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8942\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2280\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9983: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.7935\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9984: Starting at state 2\n",
            "Random probability for epsilon-greedy: 0.6649\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9128\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9960\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2711\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9985: Starting at state 6\n",
            "Random probability for epsilon-greedy: 0.2563\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.4214\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1007\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9986: Starting at state 0\n",
            "\n",
            "Episode 9987: Starting at state 13\n",
            "Random probability for epsilon-greedy: 0.2710\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99860707  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9988: Starting at state 10\n",
            "Random probability for epsilon-greedy: 0.0602\n",
            "Exploring: Selected action 1\n",
            "State: 10, Action: 1, Next State: 14, Reward: -1.0\n",
            "Q(s,a) old: 7.998607065816877, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.998746359235189\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.78423345]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0085\n",
            "Exploring: Selected action 3\n",
            "State: 14, Action: 3, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 8.784233454094307, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 8.905810108684877\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9989: Starting at state 15\n",
            "\n",
            "Episode 9990: Starting at state 7\n",
            "Random probability for epsilon-greedy: 0.4767\n",
            "Exploiting: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6879\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9991: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.2676\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9992: Starting at state 0\n",
            "\n",
            "Episode 9993: Starting at state 1\n",
            "Random probability for epsilon-greedy: 0.3218\n",
            "Exploiting: Selected action 3\n",
            "State: 1, Action: 3, Next State: 2, Reward: -1.0\n",
            "Q(s,a) old: 3.1219999999999857, Reward: -1.0, Max Q(s',a'): 4.579999999999986, Q target: 3.1219999999999875, Q(s,a) updated: 3.1219999999999857\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.9248\n",
            "Exploiting: Selected action 1\n",
            "State: 2, Action: 1, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579999999999986, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.579999999999986\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.6936\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57985617  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0037\n",
            "Exploring: Selected action 0\n",
            "State: 10, Action: 0, Next State: 6, Reward: -1.0\n",
            "Q(s,a) old: 4.579856168885558, Reward: -1.0, Max Q(s',a'): 6.199999999999989, Q target: 4.57999999999999, Q(s,a) updated: 4.5798705519970015\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.2634\n",
            "Exploiting: Selected action 1\n",
            "State: 6, Action: 1, Next State: 10, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.3419\n",
            "Exploiting: Selected action 3\n",
            "State: 10, Action: 3, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1546\n",
            "Exploiting: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9994: Starting at state 4\n",
            "Random probability for epsilon-greedy: 0.9017\n",
            "Exploiting: Selected action 1\n",
            "State: 4, Action: 1, Next State: 8, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.7756\n",
            "Exploiting: Selected action 1\n",
            "State: 8, Action: 1, Next State: 12, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.8737\n",
            "Exploiting: Selected action 1\n",
            "State: 12, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9995: Starting at state 0\n",
            "\n",
            "Episode 9996: Starting at state 3\n",
            "Random probability for epsilon-greedy: 0.2584\n",
            "Exploiting: Selected action 1\n",
            "State: 3, Action: 1, Next State: 7, Reward: -1.0\n",
            "Q(s,a) old: 6.199999999999989, Reward: -1.0, Max Q(s',a'): 7.999999999999991, Q target: 6.199999999999992, Q(s,a) updated: 6.199999999999989\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0549\n",
            "Exploring: Selected action 1\n",
            "State: 7, Action: 1, Next State: 11, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.0052\n",
            "Exploring: Selected action 1\n",
            "State: 11, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 9997: Starting at state 0\n",
            "\n",
            "Episode 9998: Starting at state 15\n",
            "\n",
            "Episode 9999: Starting at state 14\n",
            "Random probability for epsilon-greedy: 0.7343\n",
            "Exploiting: Selected action 1\n",
            "State: 14, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Episode 10000: Starting at state 9\n",
            "Random probability for epsilon-greedy: 0.6217\n",
            "Exploiting: Selected action 1\n",
            "State: 9, Action: 1, Next State: 13, Reward: -1.0\n",
            "Q(s,a) old: 7.999999999999991, Reward: -1.0, Max Q(s',a'): 9.999999999999993, Q target: 7.999999999999995, Q(s,a) updated: 7.999999999999991\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Random probability for epsilon-greedy: 0.1334\n",
            "Exploiting: Selected action 1\n",
            "State: 13, Action: 1, Next State: 15, Reward: 10.0\n",
            "Q(s,a) old: 9.999999999999993, Reward: 10.0, Max Q(s',a'): 0.0, Q target: 10.0, Q(s,a) updated: 9.999999999999993\n",
            "Updated Q-table:\n",
            " [[ 0.          0.          0.          0.        ]\n",
            " [-0.87842335  3.04385973 -0.89058101  3.122     ]\n",
            " [-0.97218716  4.58        1.72904546  4.47240018]\n",
            " [-0.79410887  6.2         2.34001703  4.22875262]\n",
            " [-0.83322818  6.2         3.49866004  2.19160021]\n",
            " [ 1.60019611  6.19999999  3.89072914  4.58      ]\n",
            " [ 3.11486304  6.2         4.00792059  6.18417583]\n",
            " [ 4.55608481  8.          4.35942587  6.10178206]\n",
            " [ 4.46897452  8.          6.0964741   6.11090492]\n",
            " [ 3.6027782   8.          5.34492221  5.73840682]\n",
            " [ 4.57987055  7.99874636  6.19574178  8.        ]\n",
            " [ 6.19999654 10.          6.19991243  7.99995959]\n",
            " [ 6.17996331 10.          7.93597928  7.90281173]\n",
            " [ 6.14959491 10.          7.88893684  7.90814871]\n",
            " [ 5.01230676 10.          6.66582545  8.90581011]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Optimal policy:\n",
            "[[0 3 1 1]\n",
            " [1 1 1 1]\n",
            " [1 1 3 1]\n",
            " [1 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize Q-values with zeros 16*4\n",
        "Q = np.zeros((n_states, n_actions))\n",
        "n_episodes = 10000  # Number of episodes for the learning\n",
        "alpha = 0.03  # Learning rate 设置学习率。\n",
        "epsilon = 0.6  # Epsilon-greedy exploration probability 探索概率\n",
        "print(Q)\n",
        "for episode in range(n_episodes):\n",
        "    s = np.random.randint(n_states)  # Randomly select an initial state\n",
        "    print(f\"\\nEpisode {episode + 1}: Starting at state {s}\")\n",
        "    while s not in [0, 15]:  # Continue until reaching terminal states (0 or 15)\n",
        "        prob = np.random.uniform()  # Generate a probability for epsilon-greedy 生成一个随机概率\n",
        "        print(f\"Random probability for epsilon-greedy: {prob:.4f}\")\n",
        "        if prob < epsilon: # 如果随机概率小于ε，则执行探索操作，即随机选择一个动作。\n",
        "            a = np.random.randint(n_actions)  # Explore: select a random action\n",
        "            print(f\"Exploring: Selected action {a}\")\n",
        "        else: # 否则，执行利用操作，即选择当前状态下Q值最大的动作。\n",
        "            a = np.argmax(Q[s, :])  # Exploit: select the action with the highest Q-value\n",
        "            print(f\"Exploiting: Selected action {a}\")\n",
        "        # Take the selected action and observe the next state and reward\n",
        "        s_prime = np.random.choice(range(n_states), p=P[s, a, :]) # 根据当前状态和选择的动作，按照状态转移概率选择下一个状态。\n",
        "        r = R[s, a, s_prime] # 获取从当前状态执行选择的动作转移到下一个状态的奖励。\n",
        "\n",
        "        # Print details of Q-learning update equation\n",
        "        q_old = Q[s, a]  # The old Q-value\n",
        "        max_q_next = np.max(Q[s_prime, :])  # The maximum Q-value for the next state\n",
        "        q_target = r + gamma * max_q_next  # The target Q-value\n",
        "        q_update = q_old + alpha * (q_target - q_old)  # The updated Q-value 根据Q学习的更新公式更新Q值。\n",
        "\n",
        "        # Update Q-value for the current state-action pair\n",
        "        Q[s, a] = q_update\n",
        "        print(f\"State: {s}, Action: {a}, Next State: {s_prime}, Reward: {r}\")\n",
        "        print(f\"Q(s,a) old: {q_old}, Reward: {r}, Max Q(s',a'): {max_q_next}, Q target: {q_target}, Q(s,a) updated: {q_update}\")\n",
        "        print(\"Updated Q-table:\\n\", Q)\n",
        "        s = s_prime  # Move to the next state\n",
        "\n",
        "# Extract the optimal policy from Q-values\n",
        "policy = np.argmax(Q, axis=1) # 从Q值表中提取最优策略，即对每个状态，选择Q值最大的动作。\n",
        "\n",
        "print(\"\\nOptimal policy:\")\n",
        "print(policy.reshape(4, 4))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
