{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfnC0rxdXVY"
      },
      "source": [
        "Deep learning framework -- pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLiyTM-2kGd3",
        "outputId": "0323bb6a-ea1a-4d27-c2e4-30c745e0db6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torch\n",
            "  Using cached torch-2.2.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (1.26.4)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Using cached pillow-10.2.0-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached torch-2.2.1-cp311-cp311-win_amd64.whl (198.6 MB)\n",
            "Using cached torchvision-0.17.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
            "Using cached pillow-10.2.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
            "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 pillow-10.2.0 sympy-1.12 torch-2.2.1 torchvision-0.17.1 typing-extensions-4.10.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script isympy.exe is installed in 'C:\\Users\\isrya\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\isrya\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (0.17.1)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\isrya\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sENhN_PRdd7K"
      },
      "source": [
        "pytorch version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ0C2b42kPTq",
        "outputId": "dd4dfefe-62f0-4238-af9f-45553c871c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using torch 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA Available: \",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVRSeGzudfys"
      },
      "source": [
        "Use gpu or not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cUCUfShp8as",
        "outputId": "5fa319c6-5239-461d-bff5-a30859f2d4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ],
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-78gzUAqecj",
        "outputId": "acdd43e5-e9dd-4839-dc07-dbb85e536b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONr-co8kdidY"
      },
      "source": [
        "Computing gradients for\n",
        "\n",
        "y = x1 + x2\n",
        "\n",
        "dy/dx1\n",
        "\n",
        "dy/dx2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8j3JEXdeVpD"
      },
      "source": [
        "1D data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmhCTzDX0y1j",
        "outputId": "24460d4c-ea53-49d1-da38-e21d9381a3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "X1 tensor([[0.0623]])\n",
            "X2 tensor([[0.2929]])\n",
            "Y tensor([[0.3552]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(1, 1)\n",
        "x2 = torch.rand(1, 1)\n",
        "print(x1.requires_grad)\n",
        "print(x2.requires_grad)\n",
        "\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAal8EsGfKfE"
      },
      "source": [
        "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJLCVpkO1vsA",
        "outputId": "af0042fa-99db-44c4-8e63-6792bb220d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "X1 tensor([[0.3389]], requires_grad=True)\n",
            "X2 tensor([[0.0639]], requires_grad=True)\n",
            "Y tensor([[0.4027]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(1, 1, requires_grad=True)\n",
        "x2 = torch.rand(1, 1, requires_grad=True)\n",
        "print(x1.requires_grad)\n",
        "print(x2.requires_grad)\n",
        "\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fCaPodnemqc1"
      },
      "outputs": [],
      "source": [
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDVISBEv2p0r"
      },
      "source": [
        "Recall y = x1+x2\n",
        "\n",
        "dy/dx1 = 1\n",
        "\n",
        "dy/dx2 = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfRUpF8w2Aa0",
        "outputId": "7c6f161f-a176-4b44-9618-85dc646a3f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.]])\n",
            "tensor([[1.]])\n"
          ]
        }
      ],
      "source": [
        "print(x1.grad)\n",
        "print(x2.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuiuIZ7f25Wi"
      },
      "source": [
        "y = x1+x2\n",
        "\n",
        "2D data\n",
        "\n",
        "m=mean(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep-Ol0r4mkKe",
        "outputId": "a8ff9d3c-82ac-408e-f0a4-4ab96c1ffa71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X1 tensor([[0.0472, 0.0897]], requires_grad=True)\n",
            "X2 tensor([[0.0811, 0.9281]], requires_grad=True)\n",
            "Y tensor([[0.1284, 1.0178]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.rand(1, 2, requires_grad=True)\n",
        "x2 = torch.rand(1, 2, requires_grad=True)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yz7kyV_3lgR",
        "outputId": "561b8dfa-a76b-45a0-ca10-9b5f76495fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5731, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "m = y.mean()\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GECyxQf93xLt"
      },
      "outputs": [],
      "source": [
        "m.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaZZoGSGoLE0"
      },
      "source": [
        "f = (x+y)z\n",
        "\n",
        "df/dx\n",
        "\n",
        "df/dy\n",
        "\n",
        "df/dz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfy9Sym3nFX_",
        "outputId": "f8022acc-2f42-4aae-f589-bfedb969a688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X tensor([[0.1819]], requires_grad=True)\n",
            "Y tensor([[0.2817]], requires_grad=True)\n",
            "Z tensor([[0.0628]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(1, 1, requires_grad=True)\n",
        "y = torch.rand(1, 1, requires_grad=True)\n",
        "z = torch.rand(1, 1, requires_grad=True)\n",
        "# Only float tensors can have gradients\n",
        "print(\"X\", x)\n",
        "print(\"Y\", y)\n",
        "print(\"Z\", z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENQTytWtnSwi",
        "outputId": "57d8620e-ced3-4c81-9305-a6ce63cc3f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f tensor([[0.0291]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "f = (x+y) * z\n",
        "print(\"f\", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "p10ckpkWoZi6"
      },
      "outputs": [],
      "source": [
        "f.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2jRcwSyocRI",
        "outputId": "a16d4ace-0150-4d58-9004-5e88c1d607c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4430]])\n",
            "tensor([[0.4430]])\n",
            "tensor([[0.6863]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xY6W3rY4vWJ"
      },
      "source": [
        "f = (x+y)z\n",
        "\n",
        "3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWOuxmAvpKId",
        "outputId": "4134d914-c05b-49a9-afd0-16c8984707d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X tensor([[0.5753, 0.5420, 0.0205]], requires_grad=True)\n",
            "Y tensor([[0.0074, 0.1515, 0.4673]], requires_grad=True)\n",
            "Z tensor([[0.2046, 0.2071, 0.9426]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(1, 3, requires_grad=True)\n",
        "y = torch.rand(1, 3, requires_grad=True)\n",
        "z = torch.rand(1, 3, requires_grad=True)\n",
        "# Only float tensors can have gradients\n",
        "print(\"X\", x)\n",
        "print(\"Y\", y)\n",
        "print(\"Z\", z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNZ3ljchlNh1"
      },
      "source": [
        "f = (x+y) * z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0yhQtdLpM4E",
        "outputId": "d7d01b49-2e07-4398-ccd1-06d6eae5549f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f tensor([[0.1192, 0.1437, 0.4598]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "f = (x+y) * z\n",
        "print(\"f\", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uheYy_wNpR55",
        "outputId": "7d9a61ec-071a-40f2-fe7d-c98e3952230b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7227, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "g = f.sum()\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jQRYjcjHpwbn"
      },
      "outputs": [],
      "source": [
        "g.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iJRjChppR0Z",
        "outputId": "54793d01-d172-4325-b56a-b16d786e4281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0160, 0.6838, 0.3509]])\n",
            "tensor([[0.0160, 0.6838, 0.3509]])\n",
            "tensor([[1.1946, 1.1201, 1.6076]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX8_TTjjhIf4"
      },
      "source": [
        "Deep learning\n",
        "\n",
        "Step 1, download datasets\n",
        "\n",
        "Step 2, create a deep neural network\n",
        "\n",
        "--two functions: init and forward\n",
        "\n",
        "Step 3, train the network\n",
        "\n",
        "Step 4, test the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "I5ijzAcprx_a"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FqaAkmZWrqIU"
      },
      "outputs": [],
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1000\n",
        "args['test_batch_size']=1000\n",
        "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset.\n",
        "args['lr']=0.01 #Learning rate is how fast it will decend.\n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itgZD9KQhiXw"
      },
      "source": [
        "Download datasets: the training dataset and testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQGJo_uxrr6X",
        "outputId": "3aa69726-459b-48bc-e590-d31468fe1b9d"
      },
      "outputs": [],
      "source": [
        "#load the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqS3TIvZhp9M"
      },
      "source": [
        "Show images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "otR-RSZCuLOn",
        "outputId": "f6c7effe-b7df-435e-b9b6-bfc08fad4735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "plt.imshow(images[0,0, :])\n",
        "\n",
        "print(f\"Label: {labels[0]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "qHg45H-566iK",
        "outputId": "4973a27f-a0e4-48d1-b898-a0854e324539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "plt.imshow(images[0,0, :])\n",
        "\n",
        "print(f\"Label: {labels[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT_KINlWhwJV"
      },
      "source": [
        "Create a deep neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Y9atCMANr4OZ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x)) # relu: activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4YbhWPj9nAn"
      },
      "source": [
        "Training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "beF9RGNQ532i"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] loss: 15.090\n",
            "[2] loss: 13.646\n",
            "[3] loss: 12.497\n",
            "[4] loss: 11.516\n",
            "[5] loss: 10.683\n",
            "[6] loss: 9.965\n",
            "[7] loss: 9.317\n",
            "[8] loss: 8.744\n",
            "[9] loss: 8.242\n",
            "[10] loss: 7.785\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('[%d] loss: %.3f' %\n",
        "                  (epoch + 1, running_loss))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Sg8hR25seb",
        "outputId": "17e96a5f-d309-4d75-b2d5-eafe636eeff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "[1] loss: 0.589\n",
            "[2] loss: 0.579\n",
            "[3] loss: 0.570\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[92], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     23\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\_functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    919\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# If you have multiple GPUs, wrap your model with nn.DataParallel to use data parallelism\n",
        "if torch.cuda.device_count() > 1:\n",
        "    net = nn.DataParallel(net)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "# Increase the batch size\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['batch_size']*8, shuffle=True, **kwargs)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('[%d] loss: %.3f' %\n",
        "                  (epoch + 1, running_loss))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avOMOZ549MH9",
        "outputId": "bdfcb1c1-4dee-47c3-8be9-48e57353067b"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[93], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      5\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(images)\n\u001b[0;32m      7\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[86], line 9\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)) \u001b[38;5;66;03m# relu: activation function\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PkHinOn-Y4O"
      },
      "source": [
        "Use convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "q8rYR8an97hG"
      },
      "outputs": [],
      "source": [
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "        # Convolutional layer (sees 28x28x1 image tensor)\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        # Convolutional layer (sees 14x14x32 tensor after pooling)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
        "        # Fully connected layer (sees 7x7x64 tensor after pooling)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1000)\n",
        "        # Final fully connected layer\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add sequence of convolutional and max pooling layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        # Flatten image input\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        # Add dropout layer\n",
        "        x = F.dropout(x, 0.5, training=self.training)\n",
        "        # Add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Add 2nd hidden layer, with 10 output units for 10 classes\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgF6Dz2h1Le"
      },
      "source": [
        "Training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "nmzVcvfQ-EbK"
      },
      "outputs": [],
      "source": [
        "net = CNNNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wLG6XtW-HtW",
        "outputId": "69350080-e52f-49aa-b963-30b2d666fbbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] loss: 22.038\n",
            "[2] loss: 4.862\n",
            "[3] loss: 3.362\n",
            "[4] loss: 2.557\n",
            "[5] loss: 2.194\n",
            "[6] loss: 1.917\n",
            "[7] loss: 1.699\n",
            "[8] loss: 1.447\n",
            "[9] loss: 1.345\n",
            "[10] loss: 1.073\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('[%d] loss: %.3f' %\n",
        "                  (epoch + 1, running_loss))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (8000) to match target batch_size (4000).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[97], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
            "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (8000) to match target batch_size (4000)."
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # inputs, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('[%d] loss: %.3f' %\n",
        "                  (epoch + 1, running_loss))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyFRb-qj-NQ4",
        "outputId": "36d8ab1a-d001-4ae1-bdcb-a6805f7bc52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
