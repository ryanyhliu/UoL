{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前期准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# 创建Lunar Lander环境，这里使用离散动作空间的版本\n",
    "env = gym.make(\"LunarLander-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索环境\n",
    "了解 动作空间, 观察空间\n",
    "\n",
    "后续 代理设计 需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(4)\n",
      "Observation Space: Box([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n",
      " -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n",
      " 1.       ], (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例代码\n",
    "\n",
    "随机动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 77 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 149 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 252 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 343 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 438 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 530 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 618 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 745 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 825 timesteps Cumulative Reward:  -100\n",
      "Episode finished after 960 timesteps Cumulative Reward:  -100\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    cumulative_reward = 0\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    \n",
    "    # print(\"{}, {}, {}, {}\".format(observation, reward, terminated, truncated))\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(\"Episode finished after {} timesteps\".format(_+1), \"Cumulative Reward: \", cumulative_reward)\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显卡测试\n",
    "\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "pip install torch==2.2.2+cu118 torchvision==0.14.2+cu118 torchaudio==0.12.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.2.2+cu118\n",
      "CUDA version:  11.8\n",
      "CUDA available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "\n",
    "# 输出是否可以使用 CUDA\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式工作 (使用DQN)\n",
    "\n",
    "训练一个Agent, 根据Observation和info, 决定最佳Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 导入并初始化环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 定义DQN网络模型\n",
    "\n",
    "通过PyTorch的nn模块, 来构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        # 定义网络层\n",
    "        self.fc1 = nn.Linear(state_size, 8)  # 第一个隐藏层，8个神经元\n",
    "        self.fc2 = nn.Linear(8, action_size)  # 输出层\n",
    "        self.relu = nn.ReLU()  # ReLU激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播流程\n",
    "        x = self.relu(self.fc1(x))  # 通过隐藏层并应用ReLU激活函数\n",
    "        x = self.fc2(x)  # 通过输出层\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        # Define network layers\n",
    "        self.fc1 = nn.Linear(state_size, 7)  # First hidden layer with 7 neurons\n",
    "        self.fc2 = nn.Linear(7, 6)  \n",
    "        self.fc3 = nn.Linear(6, 5)  \n",
    "        self.fc4 = nn.Linear(5, 4)  \n",
    "        self.fc5 = nn.Linear(4, action_size)  # Output layer\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        x = self.relu(self.fc1(x))  \n",
    "        x = self.relu(self.fc2(x))  \n",
    "        x = self.relu(self.fc3(x))  \n",
    "        x = self.relu(self.fc4(x))  \n",
    "        x = self.fc5(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 实现DQN Agent\n",
    "\n",
    "创建一个Agent类, 用来实现DQN的训练 (包括经验回放)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.9 # gamma 越大, 学习率衰减越快\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = DQN(state_size, action_size)  \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=100, gamma=self.gamma)  # Decay every 100 steps, \n",
    "\n",
    "    # 定义 Agent如何根据State选择Action\n",
    "    def act(self, state):\n",
    "        # state = torch.from_numpy(state).float().unsqueeze(0).to(self.device) # 将状态转换为张量 (还要添加一个维度), 以便输入到网络中\n",
    "        \n",
    "        # 使用 ε-greedy 策略选择动作\n",
    "        if np.random.rand() <= self.epsilon: # 如果随机数小于 ε, 则随机选择一个动作, 用于探索\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        # 得到Q值, 用于选择动作\n",
    "        self.model.eval() # 将模型设置为评估模式, 这样可以避免在评估模型时进行梯度更新\n",
    "        with torch.no_grad(): # 不需要计算梯度, 因为我们只是在评估模型\n",
    "            action_values = self.model(state) # 用当前状态获取每个动作的Q值\n",
    "            \n",
    "        self.model.train() # 修改回训练模式, 以便在训练模型时进行梯度更新 (模型的参数可以继续更新)\n",
    "        # print(\"Q Table: \", action_values.cpu().data.numpy())\n",
    "        return np.argmax(action_values.cpu().data.numpy()) # 根据Q值选择最佳动作\n",
    "    \n",
    "    # 用于 经验回放 (Experience Replay)\n",
    "    # 当Agent在Environment中\"\"执行Action 并观察到新的状态和奖励时, 将这些信息存储, 之后用于训练网络模型\n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # 经验回放 (Experience Replay)\n",
    "    # 打破数据之间的相关性, 提高训练的稳定性\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size: # 如果记忆库中的样本数量小于批量大小, 则不执行\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.memory, batch_size) # 从记忆库中随机选择一个批量的经验\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch) # 将批量经验拆分为状态, 动作, 奖励, 下一个状态, 完成标志\n",
    "        # 将拆分的经验转换为张量, 以便输入到网络中\n",
    "        states = torch.tensor(states, dtype =torch.float32).to(self.device).squeeze(1)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(self.device).unsqueeze(1)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(self.device).unsqueeze(1)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device).squeeze(1)\n",
    "        dones = torch.tensor(dones, dtype=torch.bool).to(self.device).unsqueeze(1)\n",
    "\n",
    "        # 打印所有张量的形状\n",
    "        # print(\"states: \", states.shape)\n",
    "        # print(\"actions: \", actions.shape)\n",
    "        # print(\"rewards: \", rewards)\n",
    "        # print(\"next_states: \", next_states.shape)\n",
    "        # print(\"dones: \", dones.shape)\n",
    "\n",
    "        Q_targets_next = self.model(next_states).detach().max(1)[0].unsqueeze(1) # 使用目标网络计算下一个状态的Q值, 用于计算目标Q值\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (~dones)) # 计算目标Q值, 用于更新当前状态的Q值\n",
    "        Q_expected = self.model(states).gather(1, actions) # 计算预期Q值, 用于计算损失\n",
    "\n",
    "        loss = nn.MSELoss()(Q_expected, Q_targets) # 计算均方误差损失\n",
    "        self.optimizer.zero_grad() # 梯度清零, 以便在每次迭代中重新计算梯度\n",
    "        loss.backward() # 反向传播, 计算梯度\n",
    "        self.optimizer.step() # 更新网络参数\n",
    "\n",
    "        if self.epsilon > self.epsilon_min: # 更新 ε, 以便在训练过程中逐渐减小探索的概率, 以便在初期更多地探索, 在后期更多地利用经验\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 训练Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Episode: 0/3000, score: 67, cumulative reward: -95.80954624123588\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isrya\\AppData\\Local\\Temp\\ipykernel_39116\\623301448.py:55: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  dones = torch.tensor(dones, dtype=torch.bool).to(self.device).unsqueeze(1)\n",
      "c:\\Users\\isrya\\.conda\\envs\\LUNARLANDER\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([64, 64, 1])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/3000, score: 81, cumulative reward: -150.93571883780425\n",
      "Episode: 3/3000, score: 56, cumulative reward: -296.1826519179241\n",
      "Episode: 4/3000, score: 51, cumulative reward: -334.4605762490487\n",
      "Episode: 5/3000, score: 58, cumulative reward: -137.91389478289332\n",
      "Episode: 6/3000, score: 87, cumulative reward: -340.0625874668472\n",
      "Episode: 7/3000, score: 70, cumulative reward: -41.424303969942684\n",
      "Episode: 9/3000, score: 79, cumulative reward: -603.5459799491896\n",
      "Episode: 10/3000, score: 95, cumulative reward: -522.4188765948097\n",
      "Episode: 11/3000, score: 59, cumulative reward: -99.7004614266726\n",
      "Episode: 12/3000, score: 55, cumulative reward: -117.03665666605909\n",
      "Episode: 14/3000, score: 72, cumulative reward: -152.46315329583047\n",
      "Episode: 15/3000, score: 57, cumulative reward: -490.89360495708286\n",
      "Episode: 16/3000, score: 84, cumulative reward: -488.62702214695184\n",
      "Episode: 17/3000, score: 85, cumulative reward: -238.31608879068867\n",
      "Episode: 18/3000, score: 54, cumulative reward: -171.89635430472242\n",
      "Episode: 19/3000, score: 50, cumulative reward: -141.77266337650505\n",
      "Episode: 20/3000, score: 54, cumulative reward: -166.7232466447332\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 21/3000, score: 68, cumulative reward: -116.1913319509892\n",
      "Episode: 22/3000, score: 77, cumulative reward: -212.47787424911937\n",
      "Episode: 23/3000, score: 57, cumulative reward: -123.36343057621619\n",
      "Episode: 24/3000, score: 78, cumulative reward: -518.4092016047379\n",
      "Episode: 25/3000, score: 65, cumulative reward: -298.6609395626655\n",
      "Episode: 26/3000, score: 68, cumulative reward: 23.706205412131055\n",
      "Episode: 27/3000, score: 85, cumulative reward: -154.46735361056267\n",
      "Episode: 28/3000, score: 67, cumulative reward: -287.6821729645628\n",
      "Episode: 29/3000, score: 56, cumulative reward: -121.32482612130428\n",
      "Episode: 30/3000, score: 52, cumulative reward: -185.3161004583295\n",
      "Episode: 31/3000, score: 71, cumulative reward: -203.6610728467311\n",
      "Episode: 32/3000, score: 77, cumulative reward: -111.15228088134457\n",
      "Episode: 33/3000, score: 60, cumulative reward: -121.22341647598212\n",
      "Episode: 34/3000, score: 75, cumulative reward: -542.9486185737451\n",
      "Episode: 35/3000, score: 66, cumulative reward: -449.5583001520436\n",
      "Episode: 36/3000, score: 72, cumulative reward: -438.937479278785\n",
      "Episode: 37/3000, score: 63, cumulative reward: -525.0096137079279\n",
      "Episode: 38/3000, score: 70, cumulative reward: -496.40695879165827\n",
      "Episode: 39/3000, score: 54, cumulative reward: -154.38501020220457\n",
      "Episode: 40/3000, score: 55, cumulative reward: -338.7098898213046\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 41/3000, score: 69, cumulative reward: -451.0795672159278\n",
      "Episode: 42/3000, score: 63, cumulative reward: -125.37293630152575\n",
      "Episode: 43/3000, score: 76, cumulative reward: -254.75258900302038\n",
      "Episode: 44/3000, score: 83, cumulative reward: -238.94598755568276\n",
      "Episode: 45/3000, score: 81, cumulative reward: -533.613758478144\n",
      "Episode: 46/3000, score: 67, cumulative reward: -188.9644619607272\n",
      "Episode: 47/3000, score: 58, cumulative reward: -232.0554897168716\n",
      "Episode: 48/3000, score: 69, cumulative reward: -139.10351380429762\n",
      "Episode: 49/3000, score: 56, cumulative reward: -156.75315013973199\n",
      "Episode: 50/3000, score: 67, cumulative reward: -154.62570832471215\n",
      "Episode: 51/3000, score: 53, cumulative reward: -357.2172536677826\n",
      "Episode: 52/3000, score: 59, cumulative reward: -146.26859615551803\n",
      "Episode: 54/3000, score: 69, cumulative reward: -131.66878387345542\n",
      "Episode: 55/3000, score: 70, cumulative reward: -234.52381570188209\n",
      "Episode: 56/3000, score: 73, cumulative reward: -615.5033078529399\n",
      "Episode: 57/3000, score: 99, cumulative reward: -268.3948077084075\n",
      "Episode: 58/3000, score: 57, cumulative reward: -380.6155717370218\n",
      "Episode: 59/3000, score: 75, cumulative reward: -159.83142189029041\n",
      "Episode: 60/3000, score: 82, cumulative reward: -380.9940309734527\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 61/3000, score: 81, cumulative reward: -107.56755628049399\n",
      "Episode: 62/3000, score: 58, cumulative reward: -132.4835159006608\n",
      "Episode: 64/3000, score: 61, cumulative reward: -241.15687924573496\n",
      "Episode: 65/3000, score: 51, cumulative reward: -205.8491098147806\n",
      "Episode: 66/3000, score: 74, cumulative reward: -596.0833197938118\n",
      "Episode: 67/3000, score: 50, cumulative reward: -105.14874515359074\n",
      "Episode: 68/3000, score: 83, cumulative reward: -149.82774011085928\n",
      "Episode: 69/3000, score: 64, cumulative reward: -289.0634111085168\n",
      "Episode: 70/3000, score: 65, cumulative reward: -555.3978126574679\n",
      "Episode: 71/3000, score: 88, cumulative reward: -1048.0109716389663\n",
      "Episode: 72/3000, score: 81, cumulative reward: -606.8833878499845\n",
      "Episode: 73/3000, score: 53, cumulative reward: -216.17321973697352\n",
      "Episode: 74/3000, score: 59, cumulative reward: -416.4015022748383\n",
      "Episode: 75/3000, score: 67, cumulative reward: -410.4118941701764\n",
      "Episode: 76/3000, score: 55, cumulative reward: -245.97643985177294\n",
      "Episode: 77/3000, score: 90, cumulative reward: -728.1591263046854\n",
      "Episode: 78/3000, score: 62, cumulative reward: -360.49279165551127\n",
      "Episode: 79/3000, score: 55, cumulative reward: -176.37704211636628\n",
      "Episode: 80/3000, score: 69, cumulative reward: -256.82170694613455\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 81/3000, score: 78, cumulative reward: -88.51959344971617\n",
      "Episode: 82/3000, score: 88, cumulative reward: -128.9967097931763\n",
      "Episode: 83/3000, score: 78, cumulative reward: -151.46985857737144\n",
      "Episode: 84/3000, score: 63, cumulative reward: -173.30122627270134\n",
      "Episode: 85/3000, score: 68, cumulative reward: -485.02700897800185\n",
      "Episode: 87/3000, score: 50, cumulative reward: -356.4024578976592\n",
      "Episode: 88/3000, score: 61, cumulative reward: -187.5175774396945\n",
      "Episode: 89/3000, score: 66, cumulative reward: -479.20594771109944\n",
      "Episode: 90/3000, score: 62, cumulative reward: -415.9544294941923\n",
      "Episode: 91/3000, score: 65, cumulative reward: -204.23763162177826\n",
      "Episode: 92/3000, score: 53, cumulative reward: -326.8810352445772\n",
      "Episode: 93/3000, score: 78, cumulative reward: -314.59571616839446\n",
      "Episode: 94/3000, score: 78, cumulative reward: -535.5449009174246\n",
      "Episode: 97/3000, score: 55, cumulative reward: -52.35564185918996\n",
      "Episode: 99/3000, score: 68, cumulative reward: -322.5207692973158\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 101/3000, score: 83, cumulative reward: -442.0340938125228\n",
      "Episode: 102/3000, score: 50, cumulative reward: -357.0813333897912\n",
      "Episode: 103/3000, score: 92, cumulative reward: -633.57997624809\n",
      "Episode: 105/3000, score: 50, cumulative reward: -362.8392655265072\n",
      "Episode: 106/3000, score: 76, cumulative reward: -781.9090303256698\n",
      "Episode: 107/3000, score: 74, cumulative reward: -378.28708782431056\n",
      "Episode: 108/3000, score: 78, cumulative reward: -580.4102151177196\n",
      "Episode: 109/3000, score: 60, cumulative reward: -518.1717680398433\n",
      "Episode: 110/3000, score: 53, cumulative reward: -161.20375845682503\n",
      "Episode: 113/3000, score: 75, cumulative reward: -517.0161840582314\n",
      "Episode: 114/3000, score: 62, cumulative reward: -577.302608795352\n",
      "Episode: 116/3000, score: 65, cumulative reward: 48.56042606182845\n",
      "Episode: 117/3000, score: 75, cumulative reward: -587.9654164904889\n",
      "Episode: 118/3000, score: 79, cumulative reward: -769.5460046024455\n",
      "Episode: 119/3000, score: 70, cumulative reward: -522.2100965180302\n",
      "Episode: 120/3000, score: 69, cumulative reward: -248.6462105105321\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 121/3000, score: 83, cumulative reward: -545.2902426378492\n",
      "Episode: 122/3000, score: 79, cumulative reward: -120.93198423436418\n",
      "Episode: 123/3000, score: 87, cumulative reward: -254.19723328339234\n",
      "Episode: 124/3000, score: 61, cumulative reward: -163.48634185689036\n",
      "Episode: 125/3000, score: 66, cumulative reward: -582.5182517872844\n",
      "Episode: 126/3000, score: 62, cumulative reward: -249.37054644061948\n",
      "Episode: 127/3000, score: 69, cumulative reward: -148.4538709295944\n",
      "Episode: 128/3000, score: 70, cumulative reward: -662.3745570619805\n",
      "Episode: 129/3000, score: 87, cumulative reward: -389.9335475602388\n",
      "Episode: 130/3000, score: 77, cumulative reward: -443.1626905952253\n",
      "Episode: 131/3000, score: 74, cumulative reward: -773.8269283125458\n",
      "Episode: 132/3000, score: 77, cumulative reward: -247.44119312209628\n",
      "Episode: 133/3000, score: 75, cumulative reward: -307.7595299045537\n",
      "Episode: 134/3000, score: 50, cumulative reward: -141.773302687892\n",
      "Episode: 135/3000, score: 83, cumulative reward: -543.6100611136499\n",
      "Episode: 136/3000, score: 91, cumulative reward: -286.8417813399719\n",
      "Episode: 137/3000, score: 56, cumulative reward: -370.25501068419794\n",
      "Episode: 138/3000, score: 64, cumulative reward: -145.2514740810448\n",
      "Episode: 139/3000, score: 59, cumulative reward: -517.6935320091927\n",
      "Episode: 140/3000, score: 81, cumulative reward: -386.38849168229905\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 141/3000, score: 50, cumulative reward: -194.07258709081992\n",
      "Episode: 142/3000, score: 67, cumulative reward: -480.67641540077125\n",
      "Episode: 143/3000, score: 58, cumulative reward: -519.5783351617697\n",
      "Episode: 144/3000, score: 80, cumulative reward: -152.68171452124727\n",
      "Episode: 145/3000, score: 62, cumulative reward: -522.5644050596493\n",
      "Episode: 146/3000, score: 75, cumulative reward: -351.3945199997072\n",
      "Episode: 147/3000, score: 68, cumulative reward: -601.6750601505933\n",
      "Episode: 148/3000, score: 52, cumulative reward: -112.43420308170039\n",
      "Episode: 149/3000, score: 56, cumulative reward: -106.68765462178484\n",
      "Episode: 150/3000, score: 89, cumulative reward: -303.56356780437295\n",
      "Episode: 151/3000, score: 87, cumulative reward: -655.6759355103239\n",
      "Episode: 152/3000, score: 69, cumulative reward: -582.5647813082103\n",
      "Episode: 154/3000, score: 78, cumulative reward: -382.2902961942818\n",
      "Episode: 155/3000, score: 81, cumulative reward: -358.7493946350507\n",
      "Episode: 156/3000, score: 50, cumulative reward: -135.83625565310132\n",
      "Episode: 157/3000, score: 65, cumulative reward: -156.7782047623691\n",
      "Episode: 158/3000, score: 65, cumulative reward: -353.54990696988193\n",
      "Episode: 159/3000, score: 57, cumulative reward: -122.91950823974986\n",
      "Episode: 160/3000, score: 86, cumulative reward: -217.5078436384872\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 161/3000, score: 58, cumulative reward: -141.419047163058\n",
      "Episode: 162/3000, score: 62, cumulative reward: -231.80954543689953\n",
      "Episode: 163/3000, score: 56, cumulative reward: -141.69424904684212\n",
      "Episode: 164/3000, score: 60, cumulative reward: -146.49785680595562\n",
      "Episode: 165/3000, score: 56, cumulative reward: -136.72686168557522\n",
      "Episode: 166/3000, score: 71, cumulative reward: -290.4416907668787\n",
      "Episode: 167/3000, score: 64, cumulative reward: -205.90301372707995\n",
      "Episode: 168/3000, score: 68, cumulative reward: -150.5700577549031\n",
      "Episode: 169/3000, score: 81, cumulative reward: -430.16463048994626\n",
      "Episode: 170/3000, score: 80, cumulative reward: -339.83054140753086\n",
      "Episode: 171/3000, score: 68, cumulative reward: -129.87867373250378\n",
      "Episode: 172/3000, score: 64, cumulative reward: -261.79278484058267\n",
      "Episode: 173/3000, score: 89, cumulative reward: -404.0152918609591\n",
      "Episode: 174/3000, score: 64, cumulative reward: -141.91192975651776\n",
      "Episode: 175/3000, score: 89, cumulative reward: -109.61027278124078\n",
      "Episode: 176/3000, score: 81, cumulative reward: -173.0053965967757\n",
      "Episode: 177/3000, score: 63, cumulative reward: -365.7055469138763\n",
      "Episode: 178/3000, score: 70, cumulative reward: -251.60806723895774\n",
      "Episode: 179/3000, score: 73, cumulative reward: -475.129518957312\n",
      "Episode: 180/3000, score: 58, cumulative reward: -153.71614259714352\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 181/3000, score: 76, cumulative reward: -156.0782636055138\n",
      "Episode: 182/3000, score: 75, cumulative reward: -544.7423426889851\n",
      "Episode: 183/3000, score: 70, cumulative reward: -477.9614297505439\n",
      "Episode: 184/3000, score: 55, cumulative reward: -390.92533003040404\n",
      "Episode: 185/3000, score: 55, cumulative reward: -309.5200103249911\n",
      "Episode: 186/3000, score: 73, cumulative reward: -451.8482919726908\n",
      "Episode: 188/3000, score: 57, cumulative reward: -269.7298647168461\n",
      "Episode: 189/3000, score: 83, cumulative reward: -557.453044254027\n",
      "Episode: 190/3000, score: 70, cumulative reward: -463.1618071930313\n",
      "Episode: 191/3000, score: 77, cumulative reward: -448.8628099166376\n",
      "Episode: 192/3000, score: 79, cumulative reward: -139.17013445871237\n",
      "Episode: 193/3000, score: 58, cumulative reward: -157.2166790647138\n",
      "Episode: 195/3000, score: 60, cumulative reward: -427.97678973196344\n",
      "Episode: 196/3000, score: 68, cumulative reward: -126.56674568905318\n",
      "Episode: 197/3000, score: 51, cumulative reward: -356.55335243912555\n",
      "Episode: 198/3000, score: 84, cumulative reward: -518.0376894810277\n",
      "Episode: 199/3000, score: 84, cumulative reward: -555.875051681694\n",
      "Episode: 200/3000, score: 80, cumulative reward: -169.3237330518794\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 201/3000, score: 97, cumulative reward: -136.5369366020235\n",
      "Episode: 202/3000, score: 69, cumulative reward: -205.59864313720803\n",
      "Episode: 203/3000, score: 99, cumulative reward: -23.896446052959703\n",
      "Episode: 204/3000, score: 66, cumulative reward: -608.5107469250512\n",
      "Episode: 205/3000, score: 51, cumulative reward: -119.52061694154446\n",
      "Episode: 206/3000, score: 84, cumulative reward: -543.8765125570144\n",
      "Episode: 207/3000, score: 61, cumulative reward: -461.7830681855057\n",
      "Episode: 208/3000, score: 81, cumulative reward: -517.2873969306138\n",
      "Episode: 209/3000, score: 64, cumulative reward: -379.5770836871555\n",
      "Episode: 210/3000, score: 63, cumulative reward: -387.468826497511\n",
      "Episode: 211/3000, score: 76, cumulative reward: -232.31577638382325\n",
      "Episode: 212/3000, score: 51, cumulative reward: -121.3447760661933\n",
      "Episode: 213/3000, score: 61, cumulative reward: -582.5151814787364\n",
      "Episode: 214/3000, score: 58, cumulative reward: -189.71877771701816\n",
      "Episode: 215/3000, score: 60, cumulative reward: -129.71134461782663\n",
      "Episode: 216/3000, score: 54, cumulative reward: -100.25083496301077\n",
      "Episode: 217/3000, score: 63, cumulative reward: -179.14918950573593\n",
      "Episode: 218/3000, score: 80, cumulative reward: -321.07277040800363\n",
      "Episode: 219/3000, score: 71, cumulative reward: -176.57101484274023\n",
      "Episode: 220/3000, score: 67, cumulative reward: -267.6691953767127\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 221/3000, score: 69, cumulative reward: -495.0263062692269\n",
      "Episode: 222/3000, score: 51, cumulative reward: -234.27077406589285\n",
      "Episode: 223/3000, score: 68, cumulative reward: -442.76745928303933\n",
      "Episode: 224/3000, score: 57, cumulative reward: -217.92659557208762\n",
      "Episode: 225/3000, score: 66, cumulative reward: -482.3260026349249\n",
      "Episode: 226/3000, score: 83, cumulative reward: -363.26759176672766\n",
      "Episode: 227/3000, score: 81, cumulative reward: -496.5897933686209\n",
      "Episode: 228/3000, score: 50, cumulative reward: -204.2915567986641\n",
      "Episode: 229/3000, score: 52, cumulative reward: -177.16861836715242\n",
      "Episode: 230/3000, score: 78, cumulative reward: -352.77989384565785\n",
      "Episode: 231/3000, score: 50, cumulative reward: -316.17920534001485\n",
      "Episode: 232/3000, score: 80, cumulative reward: -456.233622519663\n",
      "Episode: 233/3000, score: 47, cumulative reward: -405.2849088586028\n",
      "Episode: 234/3000, score: 52, cumulative reward: -125.28165742073867\n",
      "Episode: 235/3000, score: 54, cumulative reward: -137.76734416588977\n",
      "Episode: 236/3000, score: 53, cumulative reward: -410.8412383465964\n",
      "Episode: 237/3000, score: 76, cumulative reward: -138.73951099449295\n",
      "Episode: 240/3000, score: 51, cumulative reward: -98.80783239121413\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 241/3000, score: 78, cumulative reward: -530.0025011333241\n",
      "Episode: 242/3000, score: 75, cumulative reward: -221.6594832966201\n",
      "Episode: 243/3000, score: 63, cumulative reward: -171.46125245573992\n",
      "Episode: 244/3000, score: 65, cumulative reward: -334.46726751636135\n",
      "Episode: 245/3000, score: 56, cumulative reward: -142.41843619478027\n",
      "Episode: 246/3000, score: 56, cumulative reward: -476.21030161929554\n",
      "Episode: 247/3000, score: 77, cumulative reward: -539.7941584794312\n",
      "Episode: 248/3000, score: 82, cumulative reward: -165.90828073052504\n",
      "Episode: 249/3000, score: 63, cumulative reward: -121.54918502201359\n",
      "Episode: 250/3000, score: 85, cumulative reward: -16.95555574121593\n",
      "Episode: 251/3000, score: 52, cumulative reward: -81.67671901205816\n",
      "Episode: 252/3000, score: 79, cumulative reward: -398.1178284310016\n",
      "Episode: 253/3000, score: 52, cumulative reward: -228.28959152060457\n",
      "Episode: 254/3000, score: 54, cumulative reward: -113.19674807983496\n",
      "Episode: 255/3000, score: 90, cumulative reward: -237.12736207563026\n",
      "Episode: 256/3000, score: 64, cumulative reward: -364.2227348920573\n",
      "Episode: 257/3000, score: 62, cumulative reward: -344.12145116339127\n",
      "Episode: 258/3000, score: 64, cumulative reward: -190.38530615156097\n",
      "Episode: 259/3000, score: 88, cumulative reward: -453.0238804674745\n",
      "Episode: 260/3000, score: 75, cumulative reward: -539.2649419403474\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 261/3000, score: 58, cumulative reward: -240.06234019117005\n",
      "Episode: 262/3000, score: 63, cumulative reward: -472.1638208355531\n",
      "Episode: 263/3000, score: 66, cumulative reward: -480.01294893556155\n",
      "Episode: 264/3000, score: 53, cumulative reward: -207.64326546844262\n",
      "Episode: 265/3000, score: 95, cumulative reward: -384.4425751261549\n",
      "Episode: 266/3000, score: 67, cumulative reward: -621.2898235328494\n",
      "Episode: 267/3000, score: 57, cumulative reward: -410.3970187337413\n",
      "Episode: 268/3000, score: 61, cumulative reward: -631.5948386281533\n",
      "Episode: 271/3000, score: 68, cumulative reward: -357.39913959256364\n",
      "Episode: 272/3000, score: 66, cumulative reward: -404.55835638249795\n",
      "Episode: 273/3000, score: 79, cumulative reward: -613.5417063492831\n",
      "Episode: 274/3000, score: 50, cumulative reward: -374.38940296519195\n",
      "Episode: 275/3000, score: 79, cumulative reward: -123.07085077081325\n",
      "Episode: 276/3000, score: 84, cumulative reward: -318.33163783778815\n",
      "Episode: 277/3000, score: 81, cumulative reward: -611.6477425373989\n",
      "Episode: 278/3000, score: 82, cumulative reward: -560.6499546008968\n",
      "Episode: 279/3000, score: 68, cumulative reward: -380.23330157154817\n",
      "Episode: 280/3000, score: 60, cumulative reward: -292.911432349394\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 283/3000, score: 65, cumulative reward: -316.5197139482269\n",
      "Episode: 284/3000, score: 89, cumulative reward: -750.7526560467805\n",
      "Episode: 285/3000, score: 84, cumulative reward: -48.02629236637304\n",
      "Episode: 288/3000, score: 90, cumulative reward: -786.1390840334727\n",
      "Episode: 289/3000, score: 79, cumulative reward: -522.9633564576892\n",
      "Episode: 290/3000, score: 50, cumulative reward: -194.9240294999126\n",
      "Episode: 291/3000, score: 73, cumulative reward: -212.89447819242588\n",
      "Episode: 293/3000, score: 82, cumulative reward: -654.4200477414261\n",
      "Episode: 294/3000, score: 75, cumulative reward: -436.5132736349597\n",
      "Episode: 295/3000, score: 48, cumulative reward: -409.78344820765113\n",
      "Episode: 296/3000, score: 64, cumulative reward: -129.75511617103206\n",
      "Episode: 297/3000, score: 74, cumulative reward: -484.19298278937526\n",
      "Episode: 298/3000, score: 55, cumulative reward: -304.0394284896636\n",
      "Episode: 299/3000, score: 72, cumulative reward: -698.4867540981976\n",
      "Episode: 300/3000, score: 69, cumulative reward: -363.8614952416894\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 301/3000, score: 78, cumulative reward: -415.211994241256\n",
      "Episode: 302/3000, score: 54, cumulative reward: -290.65601002639585\n",
      "Episode: 303/3000, score: 66, cumulative reward: -532.8824134552343\n",
      "Episode: 304/3000, score: 78, cumulative reward: -627.3974817083707\n",
      "Episode: 305/3000, score: 75, cumulative reward: -151.03980092287236\n",
      "Episode: 306/3000, score: 54, cumulative reward: -370.87887790875413\n",
      "Episode: 308/3000, score: 64, cumulative reward: -308.5112209792954\n",
      "Episode: 309/3000, score: 65, cumulative reward: -580.7332883123423\n",
      "Episode: 310/3000, score: 90, cumulative reward: -291.87995639629185\n",
      "Episode: 311/3000, score: 82, cumulative reward: -755.5054887368748\n",
      "Episode: 312/3000, score: 74, cumulative reward: -567.3216828845218\n",
      "Episode: 314/3000, score: 51, cumulative reward: -469.57711663173137\n",
      "Episode: 315/3000, score: 69, cumulative reward: -500.2970789145394\n",
      "Episode: 316/3000, score: 60, cumulative reward: -131.3825980218867\n",
      "Episode: 317/3000, score: 51, cumulative reward: -339.40666342183874\n",
      "Episode: 318/3000, score: 88, cumulative reward: -341.7035020949163\n",
      "Episode: 319/3000, score: 83, cumulative reward: -783.463477675397\n",
      "Episode: 320/3000, score: 71, cumulative reward: -390.2467659550261\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 321/3000, score: 62, cumulative reward: -377.58025048015105\n",
      "Episode: 322/3000, score: 74, cumulative reward: -200.5984372075516\n",
      "Episode: 323/3000, score: 53, cumulative reward: -389.1505348084589\n",
      "Episode: 324/3000, score: 53, cumulative reward: -302.27798357658895\n",
      "Episode: 325/3000, score: 90, cumulative reward: -136.3211627822838\n",
      "Episode: 326/3000, score: 53, cumulative reward: -108.91002601182086\n",
      "Episode: 327/3000, score: 53, cumulative reward: -476.74779011792475\n",
      "Episode: 328/3000, score: 86, cumulative reward: -166.68044428173081\n",
      "Episode: 329/3000, score: 61, cumulative reward: -310.75819877513965\n",
      "Episode: 330/3000, score: 84, cumulative reward: -433.65628576600204\n",
      "Episode: 331/3000, score: 85, cumulative reward: -942.3991594129108\n",
      "Episode: 332/3000, score: 62, cumulative reward: -344.67519748970795\n",
      "Episode: 333/3000, score: 55, cumulative reward: -197.9676452510089\n",
      "Episode: 334/3000, score: 53, cumulative reward: -197.14216249157693\n",
      "Episode: 335/3000, score: 85, cumulative reward: -585.8188719833333\n",
      "Episode: 336/3000, score: 71, cumulative reward: -497.68660343886256\n",
      "Episode: 337/3000, score: 74, cumulative reward: -106.41298044479738\n",
      "Episode: 338/3000, score: 77, cumulative reward: -496.192337654494\n",
      "Episode: 339/3000, score: 75, cumulative reward: -380.428575603703\n",
      "Episode: 340/3000, score: 60, cumulative reward: -348.7346966258449\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 341/3000, score: 66, cumulative reward: -228.73476977011836\n",
      "Episode: 344/3000, score: 64, cumulative reward: -484.7629588953427\n",
      "Episode: 345/3000, score: 59, cumulative reward: -510.2196896403559\n",
      "Episode: 346/3000, score: 58, cumulative reward: -439.9845891601653\n",
      "Episode: 347/3000, score: 85, cumulative reward: -510.1929189928542\n",
      "Episode: 350/3000, score: 72, cumulative reward: -642.4510737126046\n",
      "Episode: 352/3000, score: 79, cumulative reward: -306.1995012104302\n",
      "Episode: 353/3000, score: 79, cumulative reward: -672.0984052318369\n",
      "Episode: 354/3000, score: 90, cumulative reward: -6.2309848439481925\n",
      "Episode: 355/3000, score: 79, cumulative reward: -513.1485169795478\n",
      "Episode: 356/3000, score: 53, cumulative reward: -154.891283619871\n",
      "Episode: 357/3000, score: 69, cumulative reward: -379.64668473237856\n",
      "Episode: 358/3000, score: 82, cumulative reward: -164.37320863208384\n",
      "Episode: 359/3000, score: 96, cumulative reward: -334.33895253532194\n",
      "Episode: 360/3000, score: 82, cumulative reward: -262.4322388873259\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 361/3000, score: 56, cumulative reward: -114.46778489318919\n",
      "Episode: 362/3000, score: 91, cumulative reward: -216.78453936762278\n",
      "Episode: 363/3000, score: 75, cumulative reward: -314.18052057798303\n",
      "Episode: 364/3000, score: 85, cumulative reward: -73.97691885515877\n",
      "Episode: 365/3000, score: 80, cumulative reward: -345.6606422140867\n",
      "Episode: 367/3000, score: 73, cumulative reward: -182.8778048993353\n",
      "Episode: 368/3000, score: 93, cumulative reward: -382.44522806851677\n",
      "Episode: 370/3000, score: 64, cumulative reward: -142.0605875250329\n",
      "Episode: 371/3000, score: 56, cumulative reward: -154.5255559076565\n",
      "Episode: 372/3000, score: 56, cumulative reward: -109.88583374550748\n",
      "Episode: 373/3000, score: 62, cumulative reward: -148.794840611915\n",
      "Episode: 374/3000, score: 67, cumulative reward: -454.50243841899317\n",
      "Episode: 375/3000, score: 51, cumulative reward: -218.42382729833346\n",
      "Episode: 376/3000, score: 98, cumulative reward: 10.42796468796729\n",
      "Episode: 377/3000, score: 66, cumulative reward: -120.2580792679612\n",
      "Episode: 378/3000, score: 54, cumulative reward: -144.35125037801936\n",
      "Episode: 379/3000, score: 68, cumulative reward: -230.8551078921742\n",
      "Episode: 380/3000, score: 82, cumulative reward: -169.93932969616952\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 381/3000, score: 63, cumulative reward: -133.9344850440524\n",
      "Episode: 384/3000, score: 65, cumulative reward: -129.71852128031986\n",
      "Episode: 385/3000, score: 76, cumulative reward: -139.89875440342888\n",
      "Episode: 387/3000, score: 55, cumulative reward: -314.98093770136813\n",
      "Episode: 388/3000, score: 88, cumulative reward: -1077.5306609374925\n",
      "Episode: 389/3000, score: 70, cumulative reward: -557.3029679257172\n",
      "Episode: 390/3000, score: 77, cumulative reward: -172.79181591312266\n",
      "Episode: 391/3000, score: 60, cumulative reward: -548.7584168250626\n",
      "Episode: 392/3000, score: 51, cumulative reward: -456.4336518550815\n",
      "Episode: 393/3000, score: 75, cumulative reward: -556.4171382314792\n",
      "Episode: 394/3000, score: 60, cumulative reward: -552.2794935872867\n",
      "Episode: 395/3000, score: 50, cumulative reward: -404.8738508497247\n",
      "Episode: 396/3000, score: 76, cumulative reward: -584.8868450015416\n",
      "Episode: 398/3000, score: 85, cumulative reward: -514.205961149764\n",
      "Episode: 399/3000, score: 66, cumulative reward: -156.81528097924718\n",
      "Episode: 400/3000, score: 53, cumulative reward: -112.59488682591203\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 401/3000, score: 87, cumulative reward: -446.9011419073635\n",
      "Episode: 402/3000, score: 60, cumulative reward: -127.95280632366283\n",
      "Episode: 403/3000, score: 65, cumulative reward: -550.6636854227654\n",
      "Episode: 404/3000, score: 63, cumulative reward: -156.09244833226222\n",
      "Episode: 405/3000, score: 82, cumulative reward: -182.3682058593171\n",
      "Episode: 406/3000, score: 58, cumulative reward: -464.7267366532215\n",
      "Episode: 407/3000, score: 73, cumulative reward: -284.8933873033985\n",
      "Episode: 408/3000, score: 63, cumulative reward: -198.24707434080995\n",
      "Episode: 409/3000, score: 77, cumulative reward: -134.997838230359\n",
      "Episode: 410/3000, score: 52, cumulative reward: -290.92736987959006\n",
      "Episode: 411/3000, score: 60, cumulative reward: -153.87218688801747\n",
      "Episode: 412/3000, score: 50, cumulative reward: -111.39565552931464\n",
      "Episode: 413/3000, score: 77, cumulative reward: -377.5714812433956\n",
      "Episode: 414/3000, score: 62, cumulative reward: -350.7850108960729\n",
      "Episode: 415/3000, score: 52, cumulative reward: -154.7013548718972\n",
      "Episode: 416/3000, score: 55, cumulative reward: -330.77322375812673\n",
      "Episode: 417/3000, score: 84, cumulative reward: -515.9734468853562\n",
      "Episode: 418/3000, score: 53, cumulative reward: -465.8902862442655\n",
      "Episode: 419/3000, score: 89, cumulative reward: -119.44338383932742\n",
      "Episode: 420/3000, score: 58, cumulative reward: -378.85572906781874\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 421/3000, score: 65, cumulative reward: -433.44215738898447\n",
      "Episode: 422/3000, score: 73, cumulative reward: -355.91476871052066\n",
      "Episode: 423/3000, score: 61, cumulative reward: -486.313893550295\n",
      "Episode: 424/3000, score: 58, cumulative reward: -151.4078931908145\n",
      "Episode: 425/3000, score: 57, cumulative reward: -94.91446682487052\n",
      "Episode: 426/3000, score: 88, cumulative reward: -151.0858854608584\n",
      "Episode: 427/3000, score: 66, cumulative reward: -351.2350932801063\n",
      "Episode: 428/3000, score: 89, cumulative reward: -320.75740874093947\n",
      "Episode: 429/3000, score: 50, cumulative reward: -417.340614459001\n",
      "Episode: 430/3000, score: 68, cumulative reward: -180.2437092587063\n",
      "Episode: 431/3000, score: 68, cumulative reward: -376.73994614480955\n",
      "Episode: 432/3000, score: 83, cumulative reward: -248.64783122344568\n",
      "Episode: 433/3000, score: 58, cumulative reward: -253.55769781316874\n",
      "Episode: 434/3000, score: 89, cumulative reward: -553.7078309804776\n",
      "Episode: 435/3000, score: 54, cumulative reward: -178.37446520608438\n",
      "Episode: 436/3000, score: 70, cumulative reward: -346.08187817123417\n",
      "Episode: 437/3000, score: 52, cumulative reward: -255.442690082566\n",
      "Episode: 438/3000, score: 86, cumulative reward: -589.595945477492\n",
      "Episode: 439/3000, score: 64, cumulative reward: -503.8755440712939\n",
      "Episode: 440/3000, score: 77, cumulative reward: -124.85802089963428\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 441/3000, score: 61, cumulative reward: -589.5566964544173\n",
      "Episode: 442/3000, score: 71, cumulative reward: -738.3558625384186\n",
      "Episode: 444/3000, score: 71, cumulative reward: -415.39829708420535\n",
      "Episode: 445/3000, score: 68, cumulative reward: -154.88182102267425\n",
      "Episode: 446/3000, score: 76, cumulative reward: -504.9765805539745\n",
      "Episode: 447/3000, score: 74, cumulative reward: -611.9790977399032\n",
      "Episode: 448/3000, score: 65, cumulative reward: -238.49517103913777\n",
      "Episode: 449/3000, score: 73, cumulative reward: -137.6854649977355\n",
      "Episode: 450/3000, score: 59, cumulative reward: -154.43117180839502\n",
      "Episode: 451/3000, score: 77, cumulative reward: -383.13176871636654\n",
      "Episode: 452/3000, score: 52, cumulative reward: -403.3573757143896\n",
      "Episode: 453/3000, score: 64, cumulative reward: -115.30769649170571\n",
      "Episode: 454/3000, score: 72, cumulative reward: -448.7936372472321\n",
      "Episode: 455/3000, score: 65, cumulative reward: -586.2701064111945\n",
      "Episode: 456/3000, score: 66, cumulative reward: -396.49824893888655\n",
      "Episode: 457/3000, score: 79, cumulative reward: -415.8673917380529\n",
      "Episode: 458/3000, score: 65, cumulative reward: -279.7646082480414\n",
      "Episode: 459/3000, score: 90, cumulative reward: -330.7696364599917\n",
      "Episode: 460/3000, score: 66, cumulative reward: -621.1373001279438\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 461/3000, score: 78, cumulative reward: -664.874312944329\n",
      "Episode: 462/3000, score: 71, cumulative reward: -622.0884498231483\n",
      "Episode: 463/3000, score: 51, cumulative reward: -417.9136698434456\n",
      "Episode: 464/3000, score: 93, cumulative reward: -306.67721538499535\n",
      "Episode: 465/3000, score: 67, cumulative reward: -336.8634689583523\n",
      "Episode: 466/3000, score: 62, cumulative reward: -157.65385056443438\n",
      "Episode: 467/3000, score: 65, cumulative reward: -604.5402420496084\n",
      "Episode: 468/3000, score: 72, cumulative reward: -548.8418391454713\n",
      "Episode: 469/3000, score: 55, cumulative reward: -116.54019558029854\n",
      "Episode: 470/3000, score: 55, cumulative reward: -347.99703411308803\n",
      "Episode: 471/3000, score: 81, cumulative reward: -377.98691708591525\n",
      "Episode: 472/3000, score: 77, cumulative reward: -715.6986128893343\n",
      "Episode: 473/3000, score: 88, cumulative reward: -161.89183538914492\n",
      "Episode: 474/3000, score: 64, cumulative reward: -432.93733668124054\n",
      "Episode: 475/3000, score: 79, cumulative reward: -294.4748229324467\n",
      "Episode: 476/3000, score: 70, cumulative reward: -726.3594319346955\n",
      "Episode: 478/3000, score: 70, cumulative reward: -290.76878767740374\n",
      "Episode: 479/3000, score: 65, cumulative reward: -122.22362500121207\n",
      "Episode: 480/3000, score: 76, cumulative reward: -264.2711553190804\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 481/3000, score: 74, cumulative reward: -555.4149756628065\n",
      "Episode: 482/3000, score: 59, cumulative reward: -426.0565201541297\n",
      "Episode: 483/3000, score: 75, cumulative reward: -716.0016764464838\n",
      "Episode: 484/3000, score: 65, cumulative reward: -593.8552404375221\n",
      "Episode: 485/3000, score: 97, cumulative reward: -721.4131609650585\n",
      "Episode: 487/3000, score: 92, cumulative reward: -490.2238155149635\n",
      "Episode: 490/3000, score: 96, cumulative reward: -682.5039522249963\n",
      "Episode: 491/3000, score: 64, cumulative reward: -97.8893258348503\n",
      "Episode: 492/3000, score: 62, cumulative reward: -399.64678936804205\n",
      "Episode: 493/3000, score: 91, cumulative reward: -734.2925208290194\n",
      "Episode: 494/3000, score: 50, cumulative reward: -157.4378034668304\n",
      "Episode: 496/3000, score: 85, cumulative reward: -508.00809614934616\n",
      "Episode: 497/3000, score: 91, cumulative reward: -181.6447532620457\n",
      "Episode: 498/3000, score: 62, cumulative reward: -403.25412491235517\n",
      "Episode: 499/3000, score: 77, cumulative reward: -226.20363562083793\n",
      "Episode: 500/3000, score: 72, cumulative reward: -598.8422733146476\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 501/3000, score: 84, cumulative reward: -410.1703745336662\n",
      "Episode: 502/3000, score: 64, cumulative reward: -468.80744314864006\n",
      "Episode: 503/3000, score: 81, cumulative reward: -281.4290835223752\n",
      "Episode: 504/3000, score: 53, cumulative reward: -141.92750382518943\n",
      "Episode: 505/3000, score: 76, cumulative reward: -545.5414576619185\n",
      "Episode: 506/3000, score: 58, cumulative reward: -152.27919429060114\n",
      "Episode: 507/3000, score: 71, cumulative reward: -596.2261661332417\n",
      "Episode: 508/3000, score: 62, cumulative reward: -343.5333873027244\n",
      "Episode: 509/3000, score: 68, cumulative reward: -181.97318744280898\n",
      "Episode: 510/3000, score: 83, cumulative reward: -95.7544867064774\n",
      "Episode: 511/3000, score: 52, cumulative reward: -136.8596626468771\n",
      "Episode: 512/3000, score: 55, cumulative reward: -140.94753820166898\n",
      "Episode: 513/3000, score: 96, cumulative reward: -240.05031692625838\n",
      "Episode: 514/3000, score: 53, cumulative reward: -134.3113410326753\n",
      "Episode: 515/3000, score: 71, cumulative reward: -181.29791883904562\n",
      "Episode: 516/3000, score: 65, cumulative reward: -141.93073429184048\n",
      "Episode: 517/3000, score: 86, cumulative reward: -152.99124662415787\n",
      "Episode: 518/3000, score: 64, cumulative reward: -114.96083830260145\n",
      "Episode: 519/3000, score: 81, cumulative reward: -150.57861696061255\n",
      "Episode: 520/3000, score: 87, cumulative reward: -137.61446926389777\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 521/3000, score: 56, cumulative reward: -122.96081125518435\n",
      "Episode: 522/3000, score: 63, cumulative reward: -141.5524160131334\n",
      "Episode: 523/3000, score: 76, cumulative reward: -115.21771203556577\n",
      "Episode: 524/3000, score: 70, cumulative reward: -117.97284402342424\n",
      "Episode: 525/3000, score: 84, cumulative reward: 3.52158973404201\n",
      "Episode: 526/3000, score: 54, cumulative reward: -91.2555998329317\n",
      "Episode: 527/3000, score: 65, cumulative reward: -146.32252149072423\n",
      "Episode: 528/3000, score: 79, cumulative reward: -144.43684172548387\n",
      "Episode: 529/3000, score: 78, cumulative reward: -129.13313998631494\n",
      "Episode: 530/3000, score: 84, cumulative reward: -138.32513636591372\n",
      "Episode: 531/3000, score: 69, cumulative reward: -167.1369819765581\n",
      "Episode: 532/3000, score: 88, cumulative reward: -181.62362929203337\n",
      "Episode: 533/3000, score: 54, cumulative reward: -119.1005521774656\n",
      "Episode: 534/3000, score: 51, cumulative reward: -110.88894545894863\n",
      "Episode: 535/3000, score: 79, cumulative reward: -126.95825911514981\n",
      "Episode: 536/3000, score: 54, cumulative reward: -130.18349247313597\n",
      "Episode: 537/3000, score: 65, cumulative reward: -152.81073550633533\n",
      "Episode: 538/3000, score: 95, cumulative reward: -1.7494752887941445\n",
      "Episode: 539/3000, score: 84, cumulative reward: -113.85471417936378\n",
      "Episode: 540/3000, score: 78, cumulative reward: -156.34319280103293\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 541/3000, score: 51, cumulative reward: -92.97301199855872\n",
      "Episode: 542/3000, score: 82, cumulative reward: -119.7926647491242\n",
      "Episode: 543/3000, score: 78, cumulative reward: -138.4123404864043\n",
      "Episode: 544/3000, score: 70, cumulative reward: -135.8582632419937\n",
      "Episode: 545/3000, score: 78, cumulative reward: -160.11590253664198\n",
      "Episode: 546/3000, score: 92, cumulative reward: -263.28845700368845\n",
      "Episode: 547/3000, score: 82, cumulative reward: -122.1235043805076\n",
      "Episode: 548/3000, score: 57, cumulative reward: -152.88567083593986\n",
      "Episode: 549/3000, score: 68, cumulative reward: -122.3877157953873\n",
      "Episode: 550/3000, score: 79, cumulative reward: -101.27009101078735\n",
      "Episode: 551/3000, score: 91, cumulative reward: -174.90371849221833\n",
      "Episode: 552/3000, score: 74, cumulative reward: -120.96179471834748\n",
      "Episode: 553/3000, score: 87, cumulative reward: -449.6138231574032\n",
      "Episode: 556/3000, score: 88, cumulative reward: -555.5377346405468\n",
      "Episode: 558/3000, score: 85, cumulative reward: -467.2806841584559\n",
      "Episode: 559/3000, score: 79, cumulative reward: -730.2174630792549\n",
      "Episode: 560/3000, score: 46, cumulative reward: -387.0918062128672\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 561/3000, score: 89, cumulative reward: -157.2906003598926\n",
      "Episode: 562/3000, score: 58, cumulative reward: -109.42776187111178\n",
      "Episode: 564/3000, score: 99, cumulative reward: -218.0619245767581\n",
      "Episode: 565/3000, score: 76, cumulative reward: -285.6926916521054\n",
      "Episode: 567/3000, score: 74, cumulative reward: -144.58876355226164\n",
      "Episode: 569/3000, score: 74, cumulative reward: -754.2748924848371\n",
      "Episode: 570/3000, score: 55, cumulative reward: -311.6744847825048\n",
      "Episode: 571/3000, score: 63, cumulative reward: -296.1834388636198\n",
      "Episode: 572/3000, score: 59, cumulative reward: -128.0569868722727\n",
      "Episode: 573/3000, score: 67, cumulative reward: -213.46069793913102\n",
      "Episode: 574/3000, score: 59, cumulative reward: -546.3970208948065\n",
      "Episode: 575/3000, score: 58, cumulative reward: -16.257664062744738\n",
      "Episode: 576/3000, score: 76, cumulative reward: -467.4631200112368\n",
      "Episode: 577/3000, score: 84, cumulative reward: -124.12479312587577\n",
      "Episode: 578/3000, score: 71, cumulative reward: -618.6471520924151\n",
      "Episode: 579/3000, score: 75, cumulative reward: -173.79245437061317\n",
      "Episode: 580/3000, score: 69, cumulative reward: -458.3710511012437\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 581/3000, score: 68, cumulative reward: -74.12109881449257\n",
      "Episode: 582/3000, score: 58, cumulative reward: -165.44913217230368\n",
      "Episode: 583/3000, score: 54, cumulative reward: -519.2342613448739\n",
      "Episode: 584/3000, score: 77, cumulative reward: -523.9459158254467\n",
      "Episode: 586/3000, score: 65, cumulative reward: -200.20649793503523\n",
      "Episode: 587/3000, score: 70, cumulative reward: -263.5760240045115\n",
      "Episode: 588/3000, score: 50, cumulative reward: -259.5453327279182\n",
      "Episode: 589/3000, score: 81, cumulative reward: -354.20933202425203\n",
      "Episode: 590/3000, score: 69, cumulative reward: -321.46779047352936\n",
      "Episode: 591/3000, score: 66, cumulative reward: -696.8743961039239\n",
      "Episode: 592/3000, score: 87, cumulative reward: -401.2443737054968\n",
      "Episode: 593/3000, score: 62, cumulative reward: -439.9243001879433\n",
      "Episode: 594/3000, score: 64, cumulative reward: -245.4352626231209\n",
      "Episode: 595/3000, score: 94, cumulative reward: -261.60392958019685\n",
      "Episode: 596/3000, score: 79, cumulative reward: -582.8460928166284\n",
      "Episode: 597/3000, score: 74, cumulative reward: -588.2012594691173\n",
      "Episode: 599/3000, score: 65, cumulative reward: -136.92379197993705\n",
      "Episode: 600/3000, score: 55, cumulative reward: -483.5012239901402\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 602/3000, score: 49, cumulative reward: -318.69000830427666\n",
      "Episode: 603/3000, score: 66, cumulative reward: -633.445100699387\n",
      "Episode: 604/3000, score: 92, cumulative reward: -693.1575235915806\n",
      "Episode: 605/3000, score: 67, cumulative reward: -159.80995847054726\n",
      "Episode: 606/3000, score: 52, cumulative reward: -316.6074852049732\n",
      "Episode: 607/3000, score: 76, cumulative reward: -102.29233084835093\n",
      "Episode: 610/3000, score: 74, cumulative reward: -500.45813835394506\n",
      "Episode: 611/3000, score: 58, cumulative reward: -449.3216040704709\n",
      "Episode: 612/3000, score: 69, cumulative reward: -163.58945806498855\n",
      "Episode: 613/3000, score: 79, cumulative reward: -599.428893444541\n",
      "Episode: 614/3000, score: 77, cumulative reward: -231.31206963594897\n",
      "Episode: 615/3000, score: 76, cumulative reward: -301.91535342760983\n",
      "Episode: 616/3000, score: 59, cumulative reward: -463.0250907257349\n",
      "Episode: 617/3000, score: 86, cumulative reward: -928.7129489695164\n",
      "Episode: 618/3000, score: 52, cumulative reward: -475.89789504369384\n",
      "Episode: 619/3000, score: 75, cumulative reward: -545.7925051653551\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 621/3000, score: 95, cumulative reward: -518.1826895431507\n",
      "Episode: 622/3000, score: 66, cumulative reward: -291.3599445129968\n",
      "Episode: 624/3000, score: 54, cumulative reward: -109.57908661033177\n",
      "Episode: 625/3000, score: 66, cumulative reward: -268.255607954599\n",
      "Episode: 626/3000, score: 69, cumulative reward: -713.6124120208132\n",
      "Episode: 627/3000, score: 82, cumulative reward: -218.6566947118724\n",
      "Episode: 628/3000, score: 68, cumulative reward: -509.20549035175713\n",
      "Episode: 629/3000, score: 76, cumulative reward: -499.88525843123705\n",
      "Episode: 630/3000, score: 72, cumulative reward: -151.57129654210706\n",
      "Episode: 631/3000, score: 60, cumulative reward: -410.99972245622666\n",
      "Episode: 632/3000, score: 58, cumulative reward: -425.0940454317853\n",
      "Episode: 633/3000, score: 65, cumulative reward: -582.9334243997614\n",
      "Episode: 636/3000, score: 64, cumulative reward: -599.9237104427666\n",
      "Episode: 637/3000, score: 63, cumulative reward: -147.33318123168493\n",
      "Episode: 638/3000, score: 55, cumulative reward: -334.28322126608214\n",
      "Episode: 639/3000, score: 69, cumulative reward: -141.7808657096358\n",
      "Episode: 640/3000, score: 94, cumulative reward: -257.2160570021876\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 641/3000, score: 82, cumulative reward: -253.82925824682152\n",
      "Episode: 642/3000, score: 52, cumulative reward: -226.45487994706508\n",
      "Episode: 643/3000, score: 66, cumulative reward: -9.664824012683738\n",
      "Episode: 645/3000, score: 82, cumulative reward: -117.56926294592678\n",
      "Episode: 646/3000, score: 84, cumulative reward: -776.3331113599681\n",
      "Episode: 647/3000, score: 52, cumulative reward: -369.95823461272795\n",
      "Episode: 648/3000, score: 86, cumulative reward: -524.6921215900145\n",
      "Episode: 649/3000, score: 80, cumulative reward: -568.9390617673073\n",
      "Episode: 650/3000, score: 62, cumulative reward: -480.18936085147186\n",
      "Episode: 651/3000, score: 83, cumulative reward: -173.57717986558634\n",
      "Episode: 652/3000, score: 67, cumulative reward: -636.5027292860598\n",
      "Episode: 654/3000, score: 59, cumulative reward: -541.3888538477361\n",
      "Episode: 655/3000, score: 76, cumulative reward: -189.22524884596106\n",
      "Episode: 656/3000, score: 70, cumulative reward: -258.8735622748816\n",
      "Episode: 657/3000, score: 86, cumulative reward: -839.6308849906567\n",
      "Episode: 658/3000, score: 98, cumulative reward: -421.4288290686014\n",
      "Episode: 660/3000, score: 62, cumulative reward: -360.867537937971\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 661/3000, score: 59, cumulative reward: -558.9019360707304\n",
      "Episode: 662/3000, score: 74, cumulative reward: -124.34320885830004\n",
      "Episode: 663/3000, score: 81, cumulative reward: -480.5513209781227\n",
      "Episode: 664/3000, score: 89, cumulative reward: -221.98715158385343\n",
      "Episode: 665/3000, score: 53, cumulative reward: -139.93610463128604\n",
      "Episode: 666/3000, score: 77, cumulative reward: -115.00477893080344\n",
      "Episode: 667/3000, score: 80, cumulative reward: -324.84622027240005\n",
      "Episode: 669/3000, score: 62, cumulative reward: -416.43080000658136\n",
      "Episode: 670/3000, score: 55, cumulative reward: -198.83354549326114\n",
      "Episode: 671/3000, score: 75, cumulative reward: -266.4669069802427\n",
      "Episode: 672/3000, score: 68, cumulative reward: -154.6364605109414\n",
      "Episode: 673/3000, score: 73, cumulative reward: -445.0738332912132\n",
      "Episode: 674/3000, score: 69, cumulative reward: -584.3404215615417\n",
      "Episode: 675/3000, score: 62, cumulative reward: -119.46667458133926\n",
      "Episode: 676/3000, score: 91, cumulative reward: -223.02007798792812\n",
      "Episode: 677/3000, score: 82, cumulative reward: -176.76863764467686\n",
      "Episode: 678/3000, score: 80, cumulative reward: -318.9109580326604\n",
      "Episode: 679/3000, score: 70, cumulative reward: -542.2630614579416\n",
      "Episode: 680/3000, score: 75, cumulative reward: -592.5034263427912\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 681/3000, score: 99, cumulative reward: -425.4722983737479\n",
      "Episode: 682/3000, score: 91, cumulative reward: -270.16386565692073\n",
      "Episode: 683/3000, score: 79, cumulative reward: -820.2562194087261\n",
      "Episode: 685/3000, score: 53, cumulative reward: -165.58916589437348\n",
      "Episode: 687/3000, score: 76, cumulative reward: -419.27865001247807\n",
      "Episode: 688/3000, score: 63, cumulative reward: -579.2108964170251\n",
      "Episode: 689/3000, score: 68, cumulative reward: -284.69008286378755\n",
      "Episode: 690/3000, score: 65, cumulative reward: -339.3264770148446\n",
      "Episode: 691/3000, score: 69, cumulative reward: -598.1303131861156\n",
      "Episode: 692/3000, score: 92, cumulative reward: -103.99158115817815\n",
      "Episode: 693/3000, score: 65, cumulative reward: -176.95290587095138\n",
      "Episode: 694/3000, score: 81, cumulative reward: -787.5232573254424\n",
      "Episode: 695/3000, score: 65, cumulative reward: -201.18729565236802\n",
      "Episode: 696/3000, score: 85, cumulative reward: -189.3302785942766\n",
      "Episode: 697/3000, score: 71, cumulative reward: -133.77504117598082\n",
      "Episode: 698/3000, score: 70, cumulative reward: -568.2778489163151\n",
      "Episode: 699/3000, score: 51, cumulative reward: -336.3032769969847\n",
      "Episode: 700/3000, score: 49, cumulative reward: -382.9098299189321\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 701/3000, score: 65, cumulative reward: -118.22232418312112\n",
      "Episode: 702/3000, score: 93, cumulative reward: -174.17925582270905\n",
      "Episode: 703/3000, score: 56, cumulative reward: -255.0204080177905\n",
      "Episode: 704/3000, score: 54, cumulative reward: -492.1955664047275\n",
      "Episode: 705/3000, score: 53, cumulative reward: -321.351282353364\n",
      "Episode: 706/3000, score: 65, cumulative reward: -131.4636773282477\n",
      "Episode: 707/3000, score: 77, cumulative reward: -707.7639036338475\n",
      "Episode: 708/3000, score: 67, cumulative reward: -530.4714234580407\n",
      "Episode: 709/3000, score: 79, cumulative reward: -414.54472292266337\n",
      "Episode: 710/3000, score: 93, cumulative reward: -781.9470211800838\n",
      "Episode: 712/3000, score: 59, cumulative reward: -331.79766312558274\n",
      "Episode: 713/3000, score: 72, cumulative reward: -396.35551400053674\n",
      "Episode: 714/3000, score: 64, cumulative reward: -248.2304758986668\n",
      "Episode: 715/3000, score: 78, cumulative reward: -470.81384330672756\n",
      "Episode: 716/3000, score: 53, cumulative reward: -98.31568059884927\n",
      "Episode: 717/3000, score: 68, cumulative reward: -515.7358285665608\n",
      "Episode: 718/3000, score: 62, cumulative reward: -445.0885564395328\n",
      "Episode: 719/3000, score: 66, cumulative reward: -424.9103220538057\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 721/3000, score: 62, cumulative reward: -464.3471067635068\n",
      "Episode: 722/3000, score: 60, cumulative reward: -124.07293128891116\n",
      "Episode: 723/3000, score: 55, cumulative reward: -400.8295391059814\n",
      "Episode: 724/3000, score: 83, cumulative reward: -846.8039660980636\n",
      "Episode: 725/3000, score: 54, cumulative reward: -354.8020676468373\n",
      "Episode: 726/3000, score: 82, cumulative reward: -632.2620666621827\n",
      "Episode: 727/3000, score: 74, cumulative reward: -162.85341372492528\n",
      "Episode: 728/3000, score: 68, cumulative reward: -341.0418365801336\n",
      "Episode: 729/3000, score: 76, cumulative reward: -157.36259578653704\n",
      "Episode: 730/3000, score: 67, cumulative reward: -502.8019520773288\n",
      "Episode: 731/3000, score: 57, cumulative reward: -136.22319277554337\n",
      "Episode: 732/3000, score: 79, cumulative reward: -67.18704931708555\n",
      "Episode: 733/3000, score: 63, cumulative reward: -110.30873476564312\n",
      "Episode: 734/3000, score: 83, cumulative reward: -334.36611005849346\n",
      "Episode: 735/3000, score: 62, cumulative reward: -170.60794662530589\n",
      "Episode: 736/3000, score: 70, cumulative reward: -126.91835379889508\n",
      "Episode: 737/3000, score: 56, cumulative reward: -103.16290812477479\n",
      "Episode: 738/3000, score: 70, cumulative reward: -713.8289952072302\n",
      "Episode: 739/3000, score: 59, cumulative reward: -531.8467706079239\n",
      "Episode: 740/3000, score: 54, cumulative reward: -324.7279181836475\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 741/3000, score: 76, cumulative reward: -118.68777173556646\n",
      "Episode: 742/3000, score: 55, cumulative reward: -510.12612233390325\n",
      "Episode: 743/3000, score: 81, cumulative reward: -825.7011996231108\n",
      "Episode: 744/3000, score: 78, cumulative reward: -234.7756708127492\n",
      "Episode: 745/3000, score: 81, cumulative reward: -344.29257267875903\n",
      "Episode: 746/3000, score: 69, cumulative reward: -716.6967983509869\n",
      "Episode: 747/3000, score: 65, cumulative reward: -116.52974626616725\n",
      "Episode: 748/3000, score: 90, cumulative reward: -361.1189636369361\n",
      "Episode: 749/3000, score: 95, cumulative reward: -393.67347177724366\n",
      "Episode: 750/3000, score: 56, cumulative reward: -445.60336947686284\n",
      "Episode: 751/3000, score: 85, cumulative reward: -578.0086653966639\n",
      "Episode: 752/3000, score: 80, cumulative reward: -466.0703782966398\n",
      "Episode: 753/3000, score: 56, cumulative reward: -257.52005228050757\n",
      "Episode: 754/3000, score: 54, cumulative reward: -391.94731434855044\n",
      "Episode: 755/3000, score: 72, cumulative reward: -303.47703901158945\n",
      "Episode: 756/3000, score: 68, cumulative reward: -510.93329445604616\n",
      "Episode: 757/3000, score: 95, cumulative reward: -1140.9864793770103\n",
      "Episode: 758/3000, score: 89, cumulative reward: -527.4180451644198\n",
      "Episode: 760/3000, score: 51, cumulative reward: -132.4826816190112\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 761/3000, score: 54, cumulative reward: -178.84629924301015\n",
      "Episode: 762/3000, score: 63, cumulative reward: -137.96557701775046\n",
      "Episode: 763/3000, score: 63, cumulative reward: -220.17148405620037\n",
      "Episode: 764/3000, score: 62, cumulative reward: -125.63064535866826\n",
      "Episode: 765/3000, score: 72, cumulative reward: -225.77526745537574\n",
      "Episode: 766/3000, score: 63, cumulative reward: -197.77229820735113\n",
      "Episode: 767/3000, score: 50, cumulative reward: -430.7138315964841\n",
      "Episode: 768/3000, score: 64, cumulative reward: -505.6085878305581\n",
      "Episode: 769/3000, score: 81, cumulative reward: -453.49713351091526\n",
      "Episode: 770/3000, score: 68, cumulative reward: -576.7314904016664\n",
      "Episode: 772/3000, score: 82, cumulative reward: -806.9197301687517\n",
      "Episode: 773/3000, score: 67, cumulative reward: -351.8517019109958\n",
      "Episode: 774/3000, score: 70, cumulative reward: -536.8545195756856\n",
      "Episode: 775/3000, score: 59, cumulative reward: -318.060928773572\n",
      "Episode: 776/3000, score: 68, cumulative reward: -345.5277169747733\n",
      "Episode: 777/3000, score: 51, cumulative reward: -360.70308151471846\n",
      "Episode: 778/3000, score: 62, cumulative reward: -111.29378861348121\n",
      "Episode: 779/3000, score: 58, cumulative reward: -332.5313161724422\n",
      "Episode: 780/3000, score: 67, cumulative reward: 16.282329961819542\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 781/3000, score: 64, cumulative reward: -615.8184854525999\n",
      "Episode: 782/3000, score: 67, cumulative reward: -167.08066329902863\n",
      "Episode: 783/3000, score: 54, cumulative reward: -325.144112198259\n",
      "Episode: 784/3000, score: 51, cumulative reward: -355.43240705745745\n",
      "Episode: 785/3000, score: 69, cumulative reward: -421.3732977783935\n",
      "Episode: 786/3000, score: 65, cumulative reward: -362.7463124560395\n",
      "Episode: 787/3000, score: 53, cumulative reward: -472.974227149632\n",
      "Episode: 788/3000, score: 73, cumulative reward: -672.0543607201535\n",
      "Episode: 789/3000, score: 61, cumulative reward: -356.0507206175542\n",
      "Episode: 790/3000, score: 65, cumulative reward: -181.5527435189981\n",
      "Episode: 791/3000, score: 64, cumulative reward: -456.5064742378399\n",
      "Episode: 792/3000, score: 63, cumulative reward: -114.1040747114811\n",
      "Episode: 793/3000, score: 94, cumulative reward: -2.051618017574725\n",
      "Episode: 794/3000, score: 85, cumulative reward: -253.85668926729716\n",
      "Episode: 795/3000, score: 62, cumulative reward: -444.1667473731119\n",
      "Episode: 796/3000, score: 87, cumulative reward: -366.3193435266478\n",
      "Episode: 797/3000, score: 68, cumulative reward: -167.07652436645265\n",
      "Episode: 798/3000, score: 69, cumulative reward: -351.17265419062346\n",
      "Episode: 799/3000, score: 65, cumulative reward: -250.83159740511164\n",
      "Episode: 800/3000, score: 87, cumulative reward: -709.4030849293324\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 801/3000, score: 54, cumulative reward: -340.45012174625697\n",
      "Episode: 802/3000, score: 52, cumulative reward: -261.082673437392\n",
      "Episode: 803/3000, score: 74, cumulative reward: -143.15727753085176\n",
      "Episode: 804/3000, score: 70, cumulative reward: -11.799475390397987\n",
      "Episode: 805/3000, score: 52, cumulative reward: -129.2420195930585\n",
      "Episode: 806/3000, score: 72, cumulative reward: -152.9925750708485\n",
      "Episode: 807/3000, score: 99, cumulative reward: -21.761996322339755\n",
      "Episode: 808/3000, score: 85, cumulative reward: -179.08164559996268\n",
      "Episode: 809/3000, score: 64, cumulative reward: -144.2568032378749\n",
      "Episode: 810/3000, score: 80, cumulative reward: -102.17531499026083\n",
      "Episode: 811/3000, score: 55, cumulative reward: -136.35974596041027\n",
      "Episode: 812/3000, score: 52, cumulative reward: -135.07207471696384\n",
      "Episode: 813/3000, score: 68, cumulative reward: -43.92592029644166\n",
      "Episode: 814/3000, score: 89, cumulative reward: -85.65351973075036\n",
      "Episode: 815/3000, score: 86, cumulative reward: -169.92786018732374\n",
      "Episode: 816/3000, score: 70, cumulative reward: -155.93106368390949\n",
      "Episode: 817/3000, score: 76, cumulative reward: -105.34722607691228\n",
      "Episode: 818/3000, score: 61, cumulative reward: -152.38468193920454\n",
      "Episode: 819/3000, score: 65, cumulative reward: -117.69657101984251\n",
      "Episode: 820/3000, score: 71, cumulative reward: -157.77362882772965\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 821/3000, score: 69, cumulative reward: -138.21657189451886\n",
      "Episode: 822/3000, score: 89, cumulative reward: -147.09666715926681\n",
      "Episode: 823/3000, score: 78, cumulative reward: -129.48808264263135\n",
      "Episode: 824/3000, score: 82, cumulative reward: -101.33844311080057\n",
      "Episode: 825/3000, score: 66, cumulative reward: -76.14530351456315\n",
      "Episode: 826/3000, score: 89, cumulative reward: -5.502592598597758\n",
      "Episode: 827/3000, score: 56, cumulative reward: -94.89286737626392\n",
      "Episode: 828/3000, score: 56, cumulative reward: -98.03947441765408\n",
      "Episode: 829/3000, score: 78, cumulative reward: -295.281047572898\n",
      "Episode: 830/3000, score: 54, cumulative reward: -139.69102835621203\n",
      "Episode: 831/3000, score: 79, cumulative reward: -180.33092502704764\n",
      "Episode: 832/3000, score: 70, cumulative reward: -130.44386558164155\n",
      "Episode: 833/3000, score: 56, cumulative reward: -121.67437754936154\n",
      "Episode: 834/3000, score: 67, cumulative reward: -136.28871029549947\n",
      "Episode: 835/3000, score: 79, cumulative reward: -144.9979530489004\n",
      "Episode: 836/3000, score: 56, cumulative reward: -114.10687585130188\n",
      "Episode: 837/3000, score: 64, cumulative reward: -108.5096951740938\n",
      "Episode: 838/3000, score: 64, cumulative reward: -132.74347490790362\n",
      "Episode: 839/3000, score: 62, cumulative reward: -152.44143196297244\n",
      "Episode: 840/3000, score: 76, cumulative reward: -88.10048964437364\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 841/3000, score: 55, cumulative reward: -142.06873659065565\n",
      "Episode: 842/3000, score: 58, cumulative reward: -116.9056129885349\n",
      "Episode: 843/3000, score: 88, cumulative reward: -117.0550063136444\n",
      "Episode: 844/3000, score: 76, cumulative reward: -107.12800582887402\n",
      "Episode: 845/3000, score: 77, cumulative reward: -108.4084675637479\n",
      "Episode: 846/3000, score: 65, cumulative reward: -137.91604241660986\n",
      "Episode: 847/3000, score: 57, cumulative reward: -114.50797049490441\n",
      "Episode: 848/3000, score: 66, cumulative reward: -162.2746714540009\n",
      "Episode: 849/3000, score: 73, cumulative reward: -165.07760338405308\n",
      "Episode: 850/3000, score: 65, cumulative reward: -110.70204800949705\n",
      "Episode: 851/3000, score: 67, cumulative reward: -160.56864905989215\n",
      "Episode: 852/3000, score: 58, cumulative reward: -139.25862859838585\n",
      "Episode: 853/3000, score: 63, cumulative reward: -7.8737291644707454\n",
      "Episode: 854/3000, score: 63, cumulative reward: -135.54694629861976\n",
      "Episode: 855/3000, score: 72, cumulative reward: -135.4102240582493\n",
      "Episode: 856/3000, score: 65, cumulative reward: 66.48352333513213\n",
      "Episode: 857/3000, score: 65, cumulative reward: -168.86393943926214\n",
      "Episode: 858/3000, score: 78, cumulative reward: -151.1742939176318\n",
      "Episode: 859/3000, score: 59, cumulative reward: -129.0948856825198\n",
      "Episode: 860/3000, score: 75, cumulative reward: -113.62913497872506\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 861/3000, score: 77, cumulative reward: -130.98411030162484\n",
      "Episode: 862/3000, score: 52, cumulative reward: -98.49304660154985\n",
      "Episode: 863/3000, score: 63, cumulative reward: -171.81921560750885\n",
      "Episode: 864/3000, score: 67, cumulative reward: -135.20493785835595\n",
      "Episode: 865/3000, score: 60, cumulative reward: -124.10797493780187\n",
      "Episode: 866/3000, score: 92, cumulative reward: -157.3950210255033\n",
      "Episode: 867/3000, score: 67, cumulative reward: -126.08957798237097\n",
      "Episode: 868/3000, score: 80, cumulative reward: -192.22483933148237\n",
      "Episode: 869/3000, score: 62, cumulative reward: -156.26003767438007\n",
      "Episode: 870/3000, score: 61, cumulative reward: -141.4866196496394\n",
      "Episode: 871/3000, score: 71, cumulative reward: -190.25978460968642\n",
      "Episode: 872/3000, score: 62, cumulative reward: -133.24620510006966\n",
      "Episode: 873/3000, score: 71, cumulative reward: -140.85741653315898\n",
      "Episode: 874/3000, score: 75, cumulative reward: -110.1826982018863\n",
      "Episode: 875/3000, score: 80, cumulative reward: -174.66563093452186\n",
      "Episode: 876/3000, score: 78, cumulative reward: -145.72076646247325\n",
      "Episode: 877/3000, score: 64, cumulative reward: -102.3686387435745\n",
      "Episode: 878/3000, score: 79, cumulative reward: -201.7357152315963\n",
      "Episode: 879/3000, score: 77, cumulative reward: -164.51092048318722\n",
      "Episode: 880/3000, score: 64, cumulative reward: -146.40629149762094\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 881/3000, score: 55, cumulative reward: -105.7357483100502\n",
      "Episode: 882/3000, score: 65, cumulative reward: -140.2884177111073\n",
      "Episode: 883/3000, score: 59, cumulative reward: -127.19595449343569\n",
      "Episode: 884/3000, score: 99, cumulative reward: -828.2972398911082\n",
      "Episode: 885/3000, score: 84, cumulative reward: -576.8476075427067\n",
      "Episode: 886/3000, score: 81, cumulative reward: -739.503884688804\n",
      "Episode: 887/3000, score: 55, cumulative reward: -513.1795749837071\n",
      "Episode: 888/3000, score: 76, cumulative reward: -191.73534787608008\n",
      "Episode: 890/3000, score: 89, cumulative reward: -125.10789356531858\n",
      "Episode: 891/3000, score: 68, cumulative reward: -360.79302564382766\n",
      "Episode: 892/3000, score: 52, cumulative reward: -445.9569057682748\n",
      "Episode: 895/3000, score: 66, cumulative reward: -599.644837590146\n",
      "Episode: 896/3000, score: 52, cumulative reward: -95.60369917068692\n",
      "Episode: 897/3000, score: 69, cumulative reward: -190.0316607431\n",
      "Episode: 898/3000, score: 78, cumulative reward: -701.6950908309071\n",
      "Episode: 899/3000, score: 53, cumulative reward: -320.7760787640223\n",
      "Episode: 900/3000, score: 83, cumulative reward: -475.9531914448772\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 901/3000, score: 72, cumulative reward: -536.6624457024407\n",
      "Episode: 902/3000, score: 78, cumulative reward: -100.56942252118894\n",
      "Episode: 904/3000, score: 62, cumulative reward: -344.2536700145994\n",
      "Episode: 905/3000, score: 57, cumulative reward: -247.80945754168278\n",
      "Episode: 906/3000, score: 64, cumulative reward: -136.2784335983527\n",
      "Episode: 907/3000, score: 62, cumulative reward: -454.2916526754726\n",
      "Episode: 908/3000, score: 54, cumulative reward: -142.87714167536433\n",
      "Episode: 909/3000, score: 80, cumulative reward: -176.11945386591643\n",
      "Episode: 910/3000, score: 55, cumulative reward: -262.91708184879315\n",
      "Episode: 911/3000, score: 56, cumulative reward: -122.27561719127158\n",
      "Episode: 912/3000, score: 58, cumulative reward: -233.45519701635965\n",
      "Episode: 913/3000, score: 67, cumulative reward: -431.6708174215387\n",
      "Episode: 914/3000, score: 54, cumulative reward: -118.01684264744245\n",
      "Episode: 915/3000, score: 85, cumulative reward: -442.40038453429617\n",
      "Episode: 916/3000, score: 55, cumulative reward: -393.3274720120471\n",
      "Episode: 917/3000, score: 59, cumulative reward: -106.28014413244568\n",
      "Episode: 918/3000, score: 56, cumulative reward: -230.82537387974477\n",
      "Episode: 919/3000, score: 55, cumulative reward: -510.8997514756007\n",
      "Episode: 920/3000, score: 72, cumulative reward: -706.1437718718233\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 921/3000, score: 85, cumulative reward: -480.6598598560487\n",
      "Episode: 922/3000, score: 84, cumulative reward: -756.5871725109909\n",
      "Episode: 923/3000, score: 76, cumulative reward: -320.06004820026396\n",
      "Episode: 924/3000, score: 60, cumulative reward: -228.71632355579672\n",
      "Episode: 925/3000, score: 67, cumulative reward: -209.9958474146793\n",
      "Episode: 926/3000, score: 57, cumulative reward: -392.0756611893448\n",
      "Episode: 927/3000, score: 56, cumulative reward: -94.73538373417023\n",
      "Episode: 928/3000, score: 64, cumulative reward: -401.07333454206577\n",
      "Episode: 929/3000, score: 88, cumulative reward: -438.6200233496502\n",
      "Episode: 930/3000, score: 57, cumulative reward: -135.47597957570028\n",
      "Episode: 931/3000, score: 67, cumulative reward: -273.85071327488123\n",
      "Episode: 932/3000, score: 74, cumulative reward: -693.1956063866421\n",
      "Episode: 933/3000, score: 51, cumulative reward: -454.444823040879\n",
      "Episode: 934/3000, score: 51, cumulative reward: -379.8590796283301\n",
      "Episode: 935/3000, score: 97, cumulative reward: -538.6267562682197\n",
      "Episode: 936/3000, score: 54, cumulative reward: -284.4197686702205\n",
      "Episode: 937/3000, score: 62, cumulative reward: -103.29464493797451\n",
      "Episode: 938/3000, score: 76, cumulative reward: -733.9714971830334\n",
      "Episode: 939/3000, score: 80, cumulative reward: -162.60115371051407\n",
      "Episode: 940/3000, score: 95, cumulative reward: -33.14901602900096\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 941/3000, score: 66, cumulative reward: -401.14111550864624\n",
      "Episode: 942/3000, score: 65, cumulative reward: -253.0770009012631\n",
      "Episode: 943/3000, score: 65, cumulative reward: -583.697788661908\n",
      "Episode: 944/3000, score: 88, cumulative reward: -450.4949988764738\n",
      "Episode: 945/3000, score: 73, cumulative reward: -164.26902939380514\n",
      "Episode: 946/3000, score: 56, cumulative reward: -199.5508752345475\n",
      "Episode: 947/3000, score: 76, cumulative reward: -702.3647148825426\n",
      "Episode: 948/3000, score: 99, cumulative reward: -287.19838226357666\n",
      "Episode: 950/3000, score: 97, cumulative reward: -436.339241413192\n",
      "Episode: 951/3000, score: 65, cumulative reward: -2.7666163218272857\n",
      "Episode: 952/3000, score: 80, cumulative reward: -824.6439471524507\n",
      "Episode: 953/3000, score: 86, cumulative reward: -610.7987770452316\n",
      "Episode: 954/3000, score: 87, cumulative reward: -144.52793893990145\n",
      "Episode: 955/3000, score: 66, cumulative reward: -330.835200594055\n",
      "Episode: 957/3000, score: 97, cumulative reward: -207.85320638736135\n",
      "Episode: 958/3000, score: 65, cumulative reward: -451.5005460806702\n",
      "Episode: 959/3000, score: 65, cumulative reward: -269.1624882996901\n",
      "Episode: 960/3000, score: 56, cumulative reward: -178.57785081252013\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 961/3000, score: 81, cumulative reward: -328.73367568848397\n",
      "Episode: 962/3000, score: 53, cumulative reward: -89.13068831321834\n",
      "Episode: 963/3000, score: 78, cumulative reward: -143.89661434931566\n",
      "Episode: 964/3000, score: 63, cumulative reward: -155.93820299438966\n",
      "Episode: 965/3000, score: 60, cumulative reward: -133.061284224866\n",
      "Episode: 966/3000, score: 52, cumulative reward: -115.10027812719161\n",
      "Episode: 967/3000, score: 84, cumulative reward: -115.86800994538048\n",
      "Episode: 968/3000, score: 82, cumulative reward: -607.9794521842251\n",
      "Episode: 969/3000, score: 64, cumulative reward: -156.47745860032873\n",
      "Episode: 970/3000, score: 59, cumulative reward: -59.941209997679145\n",
      "Episode: 971/3000, score: 81, cumulative reward: -451.56599517761356\n",
      "Episode: 973/3000, score: 76, cumulative reward: -556.2272047319589\n",
      "Episode: 975/3000, score: 81, cumulative reward: -230.6553259294519\n",
      "Episode: 976/3000, score: 54, cumulative reward: -332.0418199710999\n",
      "Episode: 977/3000, score: 78, cumulative reward: -426.051567402611\n",
      "Episode: 978/3000, score: 71, cumulative reward: -744.4034583289413\n",
      "Episode: 979/3000, score: 65, cumulative reward: -546.7621334986338\n",
      "Episode: 980/3000, score: 74, cumulative reward: -624.959224377874\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 981/3000, score: 56, cumulative reward: -147.6938256867814\n",
      "Episode: 982/3000, score: 66, cumulative reward: -475.76195930617854\n",
      "Episode: 983/3000, score: 61, cumulative reward: -547.428200485494\n",
      "Episode: 985/3000, score: 82, cumulative reward: -444.446855600652\n",
      "Episode: 987/3000, score: 54, cumulative reward: -391.7160146607221\n",
      "Episode: 988/3000, score: 89, cumulative reward: -622.6956779562349\n",
      "Episode: 989/3000, score: 91, cumulative reward: -105.62370183670012\n",
      "Episode: 990/3000, score: 74, cumulative reward: -684.0719966307596\n",
      "Episode: 991/3000, score: 65, cumulative reward: -289.2925725076832\n",
      "Episode: 992/3000, score: 73, cumulative reward: -118.402408900784\n",
      "Episode: 994/3000, score: 78, cumulative reward: -573.2467907434886\n",
      "Episode: 996/3000, score: 55, cumulative reward: -115.57752160538735\n",
      "Episode: 997/3000, score: 53, cumulative reward: -471.46049194683957\n",
      "Episode: 998/3000, score: 74, cumulative reward: -118.04004159564556\n",
      "Episode: 999/3000, score: 62, cumulative reward: -322.75323219620896\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1001/3000, score: 71, cumulative reward: -616.8954107850901\n",
      "Episode: 1002/3000, score: 63, cumulative reward: -188.46531185924792\n",
      "Episode: 1003/3000, score: 91, cumulative reward: -408.64237745055846\n",
      "Episode: 1004/3000, score: 69, cumulative reward: -628.9434461978872\n",
      "Episode: 1005/3000, score: 55, cumulative reward: -324.3121729160288\n",
      "Episode: 1006/3000, score: 66, cumulative reward: -152.61527724833098\n",
      "Episode: 1007/3000, score: 51, cumulative reward: -355.6540098340154\n",
      "Episode: 1008/3000, score: 67, cumulative reward: -205.28564398463882\n",
      "Episode: 1009/3000, score: 67, cumulative reward: -276.9589197092429\n",
      "Episode: 1010/3000, score: 66, cumulative reward: -167.54677706117627\n",
      "Episode: 1011/3000, score: 76, cumulative reward: -179.94259640940416\n",
      "Episode: 1012/3000, score: 76, cumulative reward: -180.09471764516493\n",
      "Episode: 1013/3000, score: 54, cumulative reward: -118.92431516757952\n",
      "Episode: 1014/3000, score: 51, cumulative reward: -356.1744309447266\n",
      "Episode: 1015/3000, score: 65, cumulative reward: -131.52510525983075\n",
      "Episode: 1016/3000, score: 75, cumulative reward: -162.84598910484314\n",
      "Episode: 1017/3000, score: 85, cumulative reward: -144.82745006141764\n",
      "Episode: 1018/3000, score: 55, cumulative reward: -98.87002754634455\n",
      "Episode: 1019/3000, score: 73, cumulative reward: -223.60368344692623\n",
      "Episode: 1020/3000, score: 63, cumulative reward: -171.18328762449153\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1021/3000, score: 74, cumulative reward: -161.2510084510716\n",
      "Episode: 1022/3000, score: 80, cumulative reward: -4.806008712319823\n",
      "Episode: 1023/3000, score: 55, cumulative reward: -377.24641818302797\n",
      "Episode: 1024/3000, score: 82, cumulative reward: -147.46382283466667\n",
      "Episode: 1025/3000, score: 67, cumulative reward: -140.1100147614562\n",
      "Episode: 1026/3000, score: 80, cumulative reward: -111.14451333560618\n",
      "Episode: 1027/3000, score: 78, cumulative reward: -110.90166109000083\n",
      "Episode: 1028/3000, score: 63, cumulative reward: -129.0412840477869\n",
      "Episode: 1029/3000, score: 54, cumulative reward: -88.81552712783366\n",
      "Episode: 1030/3000, score: 74, cumulative reward: -134.39216098852052\n",
      "Episode: 1031/3000, score: 76, cumulative reward: -145.8950378985249\n",
      "Episode: 1032/3000, score: 54, cumulative reward: -142.92168694067612\n",
      "Episode: 1033/3000, score: 88, cumulative reward: -118.19470484849226\n",
      "Episode: 1034/3000, score: 69, cumulative reward: -157.93208269858496\n",
      "Episode: 1035/3000, score: 90, cumulative reward: -197.7687460015689\n",
      "Episode: 1036/3000, score: 68, cumulative reward: -124.7834471387682\n",
      "Episode: 1037/3000, score: 72, cumulative reward: -158.21001718863994\n",
      "Episode: 1038/3000, score: 79, cumulative reward: -116.1473453690588\n",
      "Episode: 1039/3000, score: 68, cumulative reward: -151.16673857543645\n",
      "Episode: 1040/3000, score: 76, cumulative reward: -193.52741949210872\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1041/3000, score: 78, cumulative reward: -139.95033148812948\n",
      "Episode: 1042/3000, score: 61, cumulative reward: -145.96896956916623\n",
      "Episode: 1043/3000, score: 62, cumulative reward: -133.5798086850958\n",
      "Episode: 1044/3000, score: 60, cumulative reward: -102.84828325132446\n",
      "Episode: 1045/3000, score: 53, cumulative reward: -87.47076936332263\n",
      "Episode: 1046/3000, score: 83, cumulative reward: -92.10858044020654\n",
      "Episode: 1047/3000, score: 77, cumulative reward: -188.66911268647812\n",
      "Episode: 1048/3000, score: 79, cumulative reward: -0.2850732107718841\n",
      "Episode: 1049/3000, score: 67, cumulative reward: -168.4078314070189\n",
      "Episode: 1050/3000, score: 64, cumulative reward: -137.0923681308576\n",
      "Episode: 1051/3000, score: 82, cumulative reward: -140.27217080409372\n",
      "Episode: 1052/3000, score: 89, cumulative reward: -161.01347954239043\n",
      "Episode: 1053/3000, score: 80, cumulative reward: -141.74994808407666\n",
      "Episode: 1054/3000, score: 82, cumulative reward: -154.75062790793874\n",
      "Episode: 1055/3000, score: 65, cumulative reward: -125.79571739232595\n",
      "Episode: 1056/3000, score: 90, cumulative reward: 11.059826718450523\n",
      "Episode: 1057/3000, score: 83, cumulative reward: -90.9874973724952\n",
      "Episode: 1058/3000, score: 72, cumulative reward: -160.0157935923598\n",
      "Episode: 1059/3000, score: 55, cumulative reward: -89.49282528811726\n",
      "Episode: 1060/3000, score: 84, cumulative reward: -132.94165873427696\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1061/3000, score: 60, cumulative reward: -152.69854435301798\n",
      "Episode: 1062/3000, score: 69, cumulative reward: -134.02593349089787\n",
      "Episode: 1063/3000, score: 55, cumulative reward: -145.07363852139665\n",
      "Episode: 1064/3000, score: 62, cumulative reward: -128.93943163074977\n",
      "Episode: 1065/3000, score: 69, cumulative reward: -108.77322553126646\n",
      "Episode: 1067/3000, score: 60, cumulative reward: -155.49497557890135\n",
      "Episode: 1068/3000, score: 54, cumulative reward: -95.43112926315032\n",
      "Episode: 1069/3000, score: 80, cumulative reward: -203.88635637662492\n",
      "Episode: 1070/3000, score: 60, cumulative reward: -136.216349989848\n",
      "Episode: 1071/3000, score: 67, cumulative reward: -119.91095978952691\n",
      "Episode: 1072/3000, score: 83, cumulative reward: -128.99899633166396\n",
      "Episode: 1073/3000, score: 80, cumulative reward: -137.3935953098136\n",
      "Episode: 1074/3000, score: 73, cumulative reward: -119.57944732852775\n",
      "Episode: 1075/3000, score: 52, cumulative reward: -124.17441560368374\n",
      "Episode: 1076/3000, score: 82, cumulative reward: -186.00251303446345\n",
      "Episode: 1077/3000, score: 62, cumulative reward: -107.84618135731841\n",
      "Episode: 1078/3000, score: 65, cumulative reward: -146.485112029127\n",
      "Episode: 1079/3000, score: 56, cumulative reward: -138.14336707644415\n",
      "Episode: 1080/3000, score: 76, cumulative reward: -53.039663884253\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1081/3000, score: 71, cumulative reward: -173.19830393030588\n",
      "Episode: 1082/3000, score: 81, cumulative reward: -128.03574486809123\n",
      "Episode: 1083/3000, score: 94, cumulative reward: 12.665686464196838\n",
      "Episode: 1084/3000, score: 71, cumulative reward: -173.39425985685756\n",
      "Episode: 1085/3000, score: 58, cumulative reward: -147.59202157896033\n",
      "Episode: 1086/3000, score: 73, cumulative reward: -130.5325063884149\n",
      "Episode: 1087/3000, score: 66, cumulative reward: -147.09757237857454\n",
      "Episode: 1089/3000, score: 56, cumulative reward: -119.50771692707255\n",
      "Episode: 1090/3000, score: 65, cumulative reward: -151.54616536194914\n",
      "Episode: 1091/3000, score: 64, cumulative reward: -164.68702675015209\n",
      "Episode: 1092/3000, score: 71, cumulative reward: 12.806531315255299\n",
      "Episode: 1093/3000, score: 61, cumulative reward: -106.55276095779098\n",
      "Episode: 1094/3000, score: 58, cumulative reward: -102.38081942748158\n",
      "Episode: 1095/3000, score: 62, cumulative reward: -110.78535710455174\n",
      "Episode: 1096/3000, score: 81, cumulative reward: -134.7157606560579\n",
      "Episode: 1097/3000, score: 58, cumulative reward: -144.31686238433855\n",
      "Episode: 1098/3000, score: 56, cumulative reward: -126.82106233681958\n",
      "Episode: 1099/3000, score: 72, cumulative reward: -155.45191560599756\n",
      "Episode: 1100/3000, score: 58, cumulative reward: -135.5227480580935\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1101/3000, score: 65, cumulative reward: -155.63535504327325\n",
      "Episode: 1103/3000, score: 53, cumulative reward: -118.87311206287293\n",
      "Episode: 1104/3000, score: 63, cumulative reward: -166.05961970197853\n",
      "Episode: 1105/3000, score: 84, cumulative reward: -386.1976371785622\n",
      "Episode: 1107/3000, score: 75, cumulative reward: -476.12879619795456\n",
      "Episode: 1108/3000, score: 59, cumulative reward: -546.9326517848439\n",
      "Episode: 1109/3000, score: 85, cumulative reward: -193.5149219286571\n",
      "Episode: 1110/3000, score: 53, cumulative reward: -506.67610537186556\n",
      "Episode: 1111/3000, score: 72, cumulative reward: -298.4469096116861\n",
      "Episode: 1112/3000, score: 79, cumulative reward: -135.3028742294708\n",
      "Episode: 1113/3000, score: 75, cumulative reward: -341.02419419751993\n",
      "Episode: 1114/3000, score: 53, cumulative reward: -90.72555927395813\n",
      "Episode: 1115/3000, score: 57, cumulative reward: -101.46146351604375\n",
      "Episode: 1116/3000, score: 79, cumulative reward: -330.84676561450357\n",
      "Episode: 1117/3000, score: 69, cumulative reward: -502.1420391774146\n",
      "Episode: 1118/3000, score: 85, cumulative reward: -325.3988935772477\n",
      "Episode: 1119/3000, score: 87, cumulative reward: -223.2460133819302\n",
      "Episode: 1120/3000, score: 76, cumulative reward: -159.849240047052\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1121/3000, score: 62, cumulative reward: -494.8118165407584\n",
      "Episode: 1122/3000, score: 76, cumulative reward: 8.765006072791579\n",
      "Episode: 1123/3000, score: 55, cumulative reward: -135.54903223560302\n",
      "Episode: 1124/3000, score: 73, cumulative reward: -119.7505080628142\n",
      "Episode: 1125/3000, score: 77, cumulative reward: -178.95152148937007\n",
      "Episode: 1126/3000, score: 71, cumulative reward: -522.0855289334478\n",
      "Episode: 1127/3000, score: 70, cumulative reward: -138.32157900749016\n",
      "Episode: 1128/3000, score: 55, cumulative reward: -411.6212834979231\n",
      "Episode: 1129/3000, score: 56, cumulative reward: -393.38708622747225\n",
      "Episode: 1130/3000, score: 50, cumulative reward: -201.43854616751267\n",
      "Episode: 1131/3000, score: 54, cumulative reward: -110.3894173622235\n",
      "Episode: 1132/3000, score: 67, cumulative reward: -123.15483959523311\n",
      "Episode: 1133/3000, score: 69, cumulative reward: -350.5562954398624\n",
      "Episode: 1134/3000, score: 84, cumulative reward: -482.082039433211\n",
      "Episode: 1135/3000, score: 75, cumulative reward: -425.1494574519745\n",
      "Episode: 1136/3000, score: 87, cumulative reward: -349.2720313344427\n",
      "Episode: 1137/3000, score: 75, cumulative reward: -392.1680982187802\n",
      "Episode: 1138/3000, score: 65, cumulative reward: -495.5290060788002\n",
      "Episode: 1139/3000, score: 76, cumulative reward: -294.37070288502144\n",
      "Episode: 1140/3000, score: 59, cumulative reward: -128.1414356021265\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1141/3000, score: 81, cumulative reward: -177.13858367040478\n",
      "Episode: 1142/3000, score: 54, cumulative reward: -424.2992987934368\n",
      "Episode: 1143/3000, score: 62, cumulative reward: -145.4458067259419\n",
      "Episode: 1144/3000, score: 53, cumulative reward: -117.48384690699805\n",
      "Episode: 1145/3000, score: 55, cumulative reward: -462.55549966150994\n",
      "Episode: 1147/3000, score: 73, cumulative reward: -645.3744117833985\n",
      "Episode: 1149/3000, score: 65, cumulative reward: -420.7743663099243\n",
      "Episode: 1150/3000, score: 66, cumulative reward: -141.86868126385664\n",
      "Episode: 1151/3000, score: 79, cumulative reward: -404.2217959877173\n",
      "Episode: 1152/3000, score: 58, cumulative reward: -352.87754670328644\n",
      "Episode: 1153/3000, score: 59, cumulative reward: -303.06325814543555\n",
      "Episode: 1155/3000, score: 85, cumulative reward: -980.0152468783464\n",
      "Episode: 1156/3000, score: 66, cumulative reward: -106.01779094741607\n",
      "Episode: 1157/3000, score: 58, cumulative reward: -447.0357894744186\n",
      "Episode: 1158/3000, score: 67, cumulative reward: -550.9402927215076\n",
      "Episode: 1159/3000, score: 61, cumulative reward: -348.9695995943644\n",
      "Episode: 1160/3000, score: 78, cumulative reward: -403.58316988249817\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1161/3000, score: 61, cumulative reward: -109.77795270983627\n",
      "Episode: 1162/3000, score: 56, cumulative reward: -473.68590618454266\n",
      "Episode: 1165/3000, score: 77, cumulative reward: -722.4101308891676\n",
      "Episode: 1166/3000, score: 71, cumulative reward: -204.52370076666557\n",
      "Episode: 1167/3000, score: 61, cumulative reward: -364.6812528692707\n",
      "Episode: 1168/3000, score: 50, cumulative reward: -393.8825633151156\n",
      "Episode: 1169/3000, score: 65, cumulative reward: -145.33359262068421\n",
      "Episode: 1170/3000, score: 82, cumulative reward: -533.5236636764996\n",
      "Episode: 1171/3000, score: 67, cumulative reward: -360.70701329041185\n",
      "Episode: 1172/3000, score: 92, cumulative reward: -492.13123569887847\n",
      "Episode: 1173/3000, score: 55, cumulative reward: -82.65596356312818\n",
      "Episode: 1174/3000, score: 83, cumulative reward: -199.1961508712663\n",
      "Episode: 1175/3000, score: 86, cumulative reward: -455.9283637109735\n",
      "Episode: 1176/3000, score: 68, cumulative reward: -610.8245252477655\n",
      "Episode: 1177/3000, score: 94, cumulative reward: -318.33372214631964\n",
      "Episode: 1178/3000, score: 94, cumulative reward: -437.82473681001215\n",
      "Episode: 1180/3000, score: 56, cumulative reward: -189.25821173608983\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1181/3000, score: 65, cumulative reward: -163.12442992958512\n",
      "Episode: 1182/3000, score: 61, cumulative reward: -82.11502428424185\n",
      "Episode: 1183/3000, score: 58, cumulative reward: -129.94812942209379\n",
      "Episode: 1184/3000, score: 84, cumulative reward: -145.58963870209402\n",
      "Episode: 1185/3000, score: 78, cumulative reward: -186.72780658145302\n",
      "Episode: 1186/3000, score: 58, cumulative reward: -149.30504156389463\n",
      "Episode: 1187/3000, score: 98, cumulative reward: 5.083087225006679\n",
      "Episode: 1188/3000, score: 62, cumulative reward: -119.05062678402354\n",
      "Episode: 1189/3000, score: 70, cumulative reward: -132.26798763061896\n",
      "Episode: 1190/3000, score: 85, cumulative reward: -139.22810473562146\n",
      "Episode: 1191/3000, score: 58, cumulative reward: -133.76632947544974\n",
      "Episode: 1192/3000, score: 86, cumulative reward: -174.1428249015993\n",
      "Episode: 1193/3000, score: 64, cumulative reward: -118.86141110085859\n",
      "Episode: 1194/3000, score: 78, cumulative reward: -163.07222525542107\n",
      "Episode: 1195/3000, score: 49, cumulative reward: -104.8756890622179\n",
      "Episode: 1196/3000, score: 59, cumulative reward: -137.4075447292407\n",
      "Episode: 1197/3000, score: 97, cumulative reward: -305.5624974761116\n",
      "Episode: 1198/3000, score: 69, cumulative reward: -156.46480428338202\n",
      "Episode: 1199/3000, score: 55, cumulative reward: -149.20102688526472\n",
      "Episode: 1200/3000, score: 53, cumulative reward: -91.49814401678131\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1201/3000, score: 61, cumulative reward: -160.46541854795612\n",
      "Episode: 1202/3000, score: 91, cumulative reward: -180.13461870212538\n",
      "Episode: 1203/3000, score: 91, cumulative reward: -141.99250476276347\n",
      "Episode: 1204/3000, score: 65, cumulative reward: -128.76510268854148\n",
      "Episode: 1205/3000, score: 60, cumulative reward: -109.22629565070224\n",
      "Episode: 1206/3000, score: 67, cumulative reward: -152.01190412766954\n",
      "Episode: 1207/3000, score: 62, cumulative reward: -114.70499955879268\n",
      "Episode: 1208/3000, score: 62, cumulative reward: -110.36202142661057\n",
      "Episode: 1209/3000, score: 56, cumulative reward: -143.65850521837461\n",
      "Episode: 1210/3000, score: 73, cumulative reward: 17.912524887351594\n",
      "Episode: 1212/3000, score: 87, cumulative reward: -191.71448350154066\n",
      "Episode: 1213/3000, score: 82, cumulative reward: -48.562813141510674\n",
      "Episode: 1214/3000, score: 66, cumulative reward: -160.3506086103841\n",
      "Episode: 1215/3000, score: 84, cumulative reward: -90.32700085960212\n",
      "Episode: 1216/3000, score: 57, cumulative reward: -131.10850638499707\n",
      "Episode: 1217/3000, score: 53, cumulative reward: -133.82942979869645\n",
      "Episode: 1218/3000, score: 53, cumulative reward: -132.7796122321837\n",
      "Episode: 1219/3000, score: 56, cumulative reward: -133.57120754121058\n",
      "Episode: 1220/3000, score: 74, cumulative reward: -160.37835519554216\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1221/3000, score: 82, cumulative reward: -149.94764278901258\n",
      "Episode: 1222/3000, score: 78, cumulative reward: -93.0386318882262\n",
      "Episode: 1223/3000, score: 72, cumulative reward: -117.5286628152065\n",
      "Episode: 1224/3000, score: 76, cumulative reward: -134.07354356059014\n",
      "Episode: 1225/3000, score: 51, cumulative reward: -137.14845826781294\n",
      "Episode: 1226/3000, score: 57, cumulative reward: -130.95458404972882\n",
      "Episode: 1227/3000, score: 46, cumulative reward: -128.27427504437287\n",
      "Episode: 1228/3000, score: 54, cumulative reward: -136.0208647224519\n",
      "Episode: 1229/3000, score: 84, cumulative reward: -125.97886075511144\n",
      "Episode: 1230/3000, score: 73, cumulative reward: -158.46609560788485\n",
      "Episode: 1231/3000, score: 62, cumulative reward: -139.31682044672715\n",
      "Episode: 1232/3000, score: 61, cumulative reward: -148.2788095810256\n",
      "Episode: 1233/3000, score: 53, cumulative reward: -134.49508490344192\n",
      "Episode: 1234/3000, score: 55, cumulative reward: -157.29095140854457\n",
      "Episode: 1235/3000, score: 86, cumulative reward: -95.25862710008042\n",
      "Episode: 1236/3000, score: 84, cumulative reward: -127.39986274567792\n",
      "Episode: 1237/3000, score: 86, cumulative reward: -131.4416547887491\n",
      "Episode: 1238/3000, score: 68, cumulative reward: -134.3802217916353\n",
      "Episode: 1239/3000, score: 56, cumulative reward: -159.0083816409332\n",
      "Episode: 1240/3000, score: 60, cumulative reward: -132.91789870096918\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1241/3000, score: 52, cumulative reward: -74.48570711521705\n",
      "Episode: 1243/3000, score: 93, cumulative reward: -143.9371342777693\n",
      "Episode: 1244/3000, score: 83, cumulative reward: -129.16208275825207\n",
      "Episode: 1246/3000, score: 93, cumulative reward: -525.9437897426467\n",
      "Episode: 1247/3000, score: 51, cumulative reward: -88.96325118086435\n",
      "Episode: 1248/3000, score: 79, cumulative reward: -612.8276126174756\n",
      "Episode: 1249/3000, score: 50, cumulative reward: -104.6917197728558\n",
      "Episode: 1250/3000, score: 62, cumulative reward: -156.96942687483306\n",
      "Episode: 1251/3000, score: 53, cumulative reward: -141.87822537362737\n",
      "Episode: 1252/3000, score: 76, cumulative reward: -372.7122286370619\n",
      "Episode: 1253/3000, score: 59, cumulative reward: -49.41275221890754\n",
      "Episode: 1254/3000, score: 63, cumulative reward: -190.48396991083365\n",
      "Episode: 1255/3000, score: 53, cumulative reward: -330.9836208855422\n",
      "Episode: 1256/3000, score: 54, cumulative reward: -215.0506512144832\n",
      "Episode: 1257/3000, score: 57, cumulative reward: -514.1644486932146\n",
      "Episode: 1258/3000, score: 63, cumulative reward: -582.8341821768057\n",
      "Episode: 1259/3000, score: 51, cumulative reward: -110.67500835706579\n",
      "Episode: 1260/3000, score: 59, cumulative reward: -170.59344343426582\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1261/3000, score: 53, cumulative reward: -142.56469714494747\n",
      "Episode: 1262/3000, score: 53, cumulative reward: -148.46459761261286\n",
      "Episode: 1263/3000, score: 79, cumulative reward: -55.080165034006235\n",
      "Episode: 1264/3000, score: 90, cumulative reward: -121.61357999888898\n",
      "Episode: 1265/3000, score: 68, cumulative reward: -390.4237854264063\n",
      "Episode: 1266/3000, score: 64, cumulative reward: -420.87590933492845\n",
      "Episode: 1267/3000, score: 62, cumulative reward: -433.2271703918686\n",
      "Episode: 1268/3000, score: 52, cumulative reward: -133.51404229459126\n",
      "Episode: 1269/3000, score: 85, cumulative reward: -144.96872894306892\n",
      "Episode: 1270/3000, score: 80, cumulative reward: -108.58690833286695\n",
      "Episode: 1271/3000, score: 51, cumulative reward: -96.75099343825079\n",
      "Episode: 1272/3000, score: 53, cumulative reward: -367.87858534037656\n",
      "Episode: 1273/3000, score: 88, cumulative reward: -300.53381674544585\n",
      "Episode: 1274/3000, score: 57, cumulative reward: -102.47369909122875\n",
      "Episode: 1275/3000, score: 71, cumulative reward: -128.91326411610098\n",
      "Episode: 1276/3000, score: 52, cumulative reward: -173.81748943494898\n",
      "Episode: 1277/3000, score: 51, cumulative reward: -327.6423362544702\n",
      "Episode: 1278/3000, score: 78, cumulative reward: -181.355527482267\n",
      "Episode: 1279/3000, score: 83, cumulative reward: -360.31697827026517\n",
      "Episode: 1280/3000, score: 52, cumulative reward: -474.85692180700767\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1281/3000, score: 69, cumulative reward: -558.1684964823567\n",
      "Episode: 1282/3000, score: 84, cumulative reward: -421.40582085904083\n",
      "Episode: 1284/3000, score: 64, cumulative reward: -93.2716544415756\n",
      "Episode: 1286/3000, score: 67, cumulative reward: -473.8095982914297\n",
      "Episode: 1287/3000, score: 55, cumulative reward: -425.27120475662247\n",
      "Episode: 1288/3000, score: 53, cumulative reward: -159.64042892825347\n",
      "Episode: 1289/3000, score: 73, cumulative reward: -134.08968509774866\n",
      "Episode: 1290/3000, score: 88, cumulative reward: -125.88516551704154\n",
      "Episode: 1291/3000, score: 53, cumulative reward: -361.12875382438335\n",
      "Episode: 1292/3000, score: 76, cumulative reward: -785.1900356300307\n",
      "Episode: 1293/3000, score: 82, cumulative reward: -237.72666813026456\n",
      "Episode: 1294/3000, score: 78, cumulative reward: -151.3121017890911\n",
      "Episode: 1295/3000, score: 61, cumulative reward: -147.2435294767804\n",
      "Episode: 1296/3000, score: 50, cumulative reward: -135.21962164458628\n",
      "Episode: 1297/3000, score: 77, cumulative reward: -2.4842274254791334\n",
      "Episode: 1298/3000, score: 55, cumulative reward: -115.73792960334654\n",
      "Episode: 1299/3000, score: 61, cumulative reward: -120.86654569302291\n",
      "Episode: 1300/3000, score: 52, cumulative reward: -80.65481132778254\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1301/3000, score: 51, cumulative reward: -81.6803868855452\n",
      "Episode: 1302/3000, score: 54, cumulative reward: -127.8545407024003\n",
      "Episode: 1303/3000, score: 59, cumulative reward: -127.62195898201001\n",
      "Episode: 1304/3000, score: 55, cumulative reward: -96.26781281788791\n",
      "Episode: 1305/3000, score: 57, cumulative reward: -100.89378464300543\n",
      "Episode: 1306/3000, score: 53, cumulative reward: -145.9077498140848\n",
      "Episode: 1307/3000, score: 61, cumulative reward: -127.31588260716782\n",
      "Episode: 1308/3000, score: 62, cumulative reward: -143.98526716666237\n",
      "Episode: 1309/3000, score: 77, cumulative reward: -134.17231450811164\n",
      "Episode: 1310/3000, score: 67, cumulative reward: -424.78565343763455\n",
      "Episode: 1311/3000, score: 53, cumulative reward: -77.74270713328924\n",
      "Episode: 1312/3000, score: 86, cumulative reward: -104.24125688148828\n",
      "Episode: 1313/3000, score: 77, cumulative reward: -103.3966091663136\n",
      "Episode: 1314/3000, score: 56, cumulative reward: -116.64415488510689\n",
      "Episode: 1315/3000, score: 70, cumulative reward: -171.18110670251025\n",
      "Episode: 1316/3000, score: 66, cumulative reward: -144.2230474861433\n",
      "Episode: 1317/3000, score: 59, cumulative reward: -136.34310503144673\n",
      "Episode: 1318/3000, score: 54, cumulative reward: -142.60292301584354\n",
      "Episode: 1319/3000, score: 68, cumulative reward: -143.3355199615991\n",
      "Episode: 1320/3000, score: 74, cumulative reward: -121.68385157583481\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1321/3000, score: 60, cumulative reward: -154.03364672976025\n",
      "Episode: 1322/3000, score: 72, cumulative reward: -143.23873254116535\n",
      "Episode: 1323/3000, score: 63, cumulative reward: -160.0420235572319\n",
      "Episode: 1324/3000, score: 58, cumulative reward: -106.56408033124197\n",
      "Episode: 1325/3000, score: 80, cumulative reward: -208.45168585742152\n",
      "Episode: 1326/3000, score: 69, cumulative reward: -139.49417296207037\n",
      "Episode: 1327/3000, score: 81, cumulative reward: -153.36212605311158\n",
      "Episode: 1328/3000, score: 83, cumulative reward: -119.41196381902478\n",
      "Episode: 1329/3000, score: 88, cumulative reward: -150.60465708708955\n",
      "Episode: 1330/3000, score: 79, cumulative reward: -149.11560112567994\n",
      "Episode: 1331/3000, score: 80, cumulative reward: -100.98988078280499\n",
      "Episode: 1332/3000, score: 66, cumulative reward: -148.03033027535992\n",
      "Episode: 1333/3000, score: 72, cumulative reward: -137.79754392233866\n",
      "Episode: 1334/3000, score: 55, cumulative reward: -108.09670363192203\n",
      "Episode: 1335/3000, score: 53, cumulative reward: -126.45876964734195\n",
      "Episode: 1336/3000, score: 58, cumulative reward: -114.97073002113089\n",
      "Episode: 1337/3000, score: 48, cumulative reward: -96.85458016394233\n",
      "Episode: 1338/3000, score: 65, cumulative reward: -124.07537972197618\n",
      "Episode: 1339/3000, score: 71, cumulative reward: -133.42678454437953\n",
      "Episode: 1340/3000, score: 82, cumulative reward: -130.20523617133733\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1341/3000, score: 64, cumulative reward: -159.56531520961985\n",
      "Episode: 1342/3000, score: 83, cumulative reward: -124.4908484726771\n",
      "Episode: 1343/3000, score: 90, cumulative reward: -133.7118767710354\n",
      "Episode: 1344/3000, score: 74, cumulative reward: -154.19260949423997\n",
      "Episode: 1345/3000, score: 69, cumulative reward: -146.0182781098799\n",
      "Episode: 1346/3000, score: 84, cumulative reward: -23.297510644247694\n",
      "Episode: 1347/3000, score: 71, cumulative reward: -120.90454996447559\n",
      "Episode: 1348/3000, score: 52, cumulative reward: -115.01475644345695\n",
      "Episode: 1349/3000, score: 84, cumulative reward: -182.35073731414508\n",
      "Episode: 1350/3000, score: 82, cumulative reward: -101.69118018841442\n",
      "Episode: 1351/3000, score: 51, cumulative reward: -112.06248958422242\n",
      "Episode: 1352/3000, score: 52, cumulative reward: -129.66087197839133\n",
      "Episode: 1353/3000, score: 90, cumulative reward: -131.86508527522167\n",
      "Episode: 1354/3000, score: 56, cumulative reward: -140.2474945143776\n",
      "Episode: 1355/3000, score: 81, cumulative reward: -106.17960400675554\n",
      "Episode: 1356/3000, score: 61, cumulative reward: -117.45353301325615\n",
      "Episode: 1357/3000, score: 66, cumulative reward: -176.1104953090886\n",
      "Episode: 1358/3000, score: 52, cumulative reward: -83.40179104020848\n",
      "Episode: 1359/3000, score: 87, cumulative reward: -197.77741790512968\n",
      "Episode: 1360/3000, score: 98, cumulative reward: -311.76079039199396\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1361/3000, score: 53, cumulative reward: -123.63377439657638\n",
      "Episode: 1362/3000, score: 87, cumulative reward: -121.6823495036883\n",
      "Episode: 1363/3000, score: 85, cumulative reward: -145.6131955581253\n",
      "Episode: 1364/3000, score: 52, cumulative reward: -113.02996716679624\n",
      "Episode: 1365/3000, score: 62, cumulative reward: -96.66756351825964\n",
      "Episode: 1366/3000, score: 92, cumulative reward: -233.2877401644363\n",
      "Episode: 1367/3000, score: 67, cumulative reward: -126.76495210184908\n",
      "Episode: 1368/3000, score: 87, cumulative reward: -144.36143078287267\n",
      "Episode: 1369/3000, score: 75, cumulative reward: -173.95855438692195\n",
      "Episode: 1370/3000, score: 77, cumulative reward: -158.9970131159729\n",
      "Episode: 1371/3000, score: 56, cumulative reward: -131.51335584197045\n",
      "Episode: 1372/3000, score: 63, cumulative reward: -28.98832946805291\n",
      "Episode: 1373/3000, score: 83, cumulative reward: -148.83469104072833\n",
      "Episode: 1374/3000, score: 61, cumulative reward: -164.0749894913774\n",
      "Episode: 1375/3000, score: 59, cumulative reward: -142.59117254129603\n",
      "Episode: 1376/3000, score: 64, cumulative reward: -133.7681588734497\n",
      "Episode: 1377/3000, score: 79, cumulative reward: -136.94831854079257\n",
      "Episode: 1378/3000, score: 62, cumulative reward: -162.75670998769914\n",
      "Episode: 1379/3000, score: 88, cumulative reward: -172.27780870311418\n",
      "Episode: 1380/3000, score: 55, cumulative reward: -126.12610604648373\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1381/3000, score: 52, cumulative reward: -89.34477185732146\n",
      "Episode: 1382/3000, score: 55, cumulative reward: -114.39472638823631\n",
      "Episode: 1383/3000, score: 49, cumulative reward: -108.473974330836\n",
      "Episode: 1384/3000, score: 61, cumulative reward: -144.65537624640098\n",
      "Episode: 1385/3000, score: 73, cumulative reward: -115.7134263431997\n",
      "Episode: 1386/3000, score: 63, cumulative reward: -128.2922720094364\n",
      "Episode: 1387/3000, score: 53, cumulative reward: -144.26807626184646\n",
      "Episode: 1389/3000, score: 96, cumulative reward: -215.27215965718233\n",
      "Episode: 1390/3000, score: 94, cumulative reward: -291.72471091438615\n",
      "Episode: 1392/3000, score: 53, cumulative reward: -353.9232409178891\n",
      "Episode: 1393/3000, score: 86, cumulative reward: -352.0190738398053\n",
      "Episode: 1394/3000, score: 78, cumulative reward: -106.67661058004963\n",
      "Episode: 1395/3000, score: 58, cumulative reward: -128.83219000605774\n",
      "Episode: 1396/3000, score: 62, cumulative reward: -129.471220859034\n",
      "Episode: 1397/3000, score: 73, cumulative reward: -418.34995952404375\n",
      "Episode: 1398/3000, score: 78, cumulative reward: -137.7047893530871\n",
      "Episode: 1399/3000, score: 51, cumulative reward: -137.46072421652974\n",
      "Episode: 1400/3000, score: 64, cumulative reward: -4.575936468084478\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1401/3000, score: 63, cumulative reward: -167.68394824308348\n",
      "Episode: 1402/3000, score: 53, cumulative reward: -198.53831099701128\n",
      "Episode: 1403/3000, score: 57, cumulative reward: -194.7306850942794\n",
      "Episode: 1404/3000, score: 78, cumulative reward: -145.16767865583952\n",
      "Episode: 1405/3000, score: 62, cumulative reward: -408.11501275557936\n",
      "Episode: 1406/3000, score: 91, cumulative reward: -81.96431171755526\n",
      "Episode: 1407/3000, score: 81, cumulative reward: -123.33459793512105\n",
      "Episode: 1408/3000, score: 86, cumulative reward: -706.5586686249349\n",
      "Episode: 1409/3000, score: 87, cumulative reward: -255.37965003788125\n",
      "Episode: 1410/3000, score: 78, cumulative reward: -529.3174793831398\n",
      "Episode: 1411/3000, score: 84, cumulative reward: -125.47856853785598\n",
      "Episode: 1412/3000, score: 53, cumulative reward: -144.09882217350062\n",
      "Episode: 1413/3000, score: 65, cumulative reward: -24.6806422754331\n",
      "Episode: 1414/3000, score: 63, cumulative reward: -261.70971977749605\n",
      "Episode: 1415/3000, score: 49, cumulative reward: -386.502033273053\n",
      "Episode: 1416/3000, score: 58, cumulative reward: -89.85779078854071\n",
      "Episode: 1418/3000, score: 86, cumulative reward: -166.05122460259275\n",
      "Episode: 1419/3000, score: 71, cumulative reward: -431.12722957100783\n",
      "Episode: 1420/3000, score: 74, cumulative reward: -142.69925685271693\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1421/3000, score: 53, cumulative reward: -419.06336581961165\n",
      "Episode: 1422/3000, score: 63, cumulative reward: -556.5894807301245\n",
      "Episode: 1423/3000, score: 67, cumulative reward: 8.301423879926034\n",
      "Episode: 1424/3000, score: 51, cumulative reward: -407.84809064388037\n",
      "Episode: 1425/3000, score: 79, cumulative reward: -582.5208713677748\n",
      "Episode: 1426/3000, score: 60, cumulative reward: -240.636216424793\n",
      "Episode: 1427/3000, score: 81, cumulative reward: -298.1847117380987\n",
      "Episode: 1428/3000, score: 56, cumulative reward: -576.7004036671086\n",
      "Episode: 1430/3000, score: 87, cumulative reward: -201.80540897851063\n",
      "Episode: 1431/3000, score: 51, cumulative reward: -131.80676754776783\n",
      "Episode: 1432/3000, score: 74, cumulative reward: -120.44223579512357\n",
      "Episode: 1433/3000, score: 52, cumulative reward: -216.72748385691028\n",
      "Episode: 1434/3000, score: 54, cumulative reward: -394.6609825445656\n",
      "Episode: 1435/3000, score: 61, cumulative reward: -333.21071834190013\n",
      "Episode: 1436/3000, score: 57, cumulative reward: -495.1670774156665\n",
      "Episode: 1437/3000, score: 62, cumulative reward: -137.80001758061357\n",
      "Episode: 1438/3000, score: 57, cumulative reward: -449.2297251962109\n",
      "Episode: 1439/3000, score: 78, cumulative reward: -396.74796445898005\n",
      "Episode: 1440/3000, score: 52, cumulative reward: -125.20127266085831\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1441/3000, score: 62, cumulative reward: -128.00527091842673\n",
      "Episode: 1442/3000, score: 81, cumulative reward: -147.47132513631828\n",
      "Episode: 1443/3000, score: 72, cumulative reward: -300.0233873308286\n",
      "Episode: 1444/3000, score: 80, cumulative reward: -459.2910076780968\n",
      "Episode: 1445/3000, score: 74, cumulative reward: -117.14602477973526\n",
      "Episode: 1446/3000, score: 79, cumulative reward: -189.15812235970813\n",
      "Episode: 1447/3000, score: 51, cumulative reward: -350.8050184114055\n",
      "Episode: 1448/3000, score: 56, cumulative reward: -105.97503500892046\n",
      "Episode: 1449/3000, score: 52, cumulative reward: -193.15186488798923\n",
      "Episode: 1450/3000, score: 81, cumulative reward: -80.8057269824914\n",
      "Episode: 1452/3000, score: 83, cumulative reward: -144.1333095028437\n",
      "Episode: 1453/3000, score: 80, cumulative reward: -370.4393677330577\n",
      "Episode: 1454/3000, score: 86, cumulative reward: -147.5999799509137\n",
      "Episode: 1455/3000, score: 82, cumulative reward: -141.0626279985494\n",
      "Episode: 1456/3000, score: 49, cumulative reward: -122.8352762471606\n",
      "Episode: 1457/3000, score: 60, cumulative reward: -171.76696812951536\n",
      "Episode: 1458/3000, score: 82, cumulative reward: -151.23585354872773\n",
      "Episode: 1459/3000, score: 90, cumulative reward: -128.49381490837604\n",
      "Episode: 1460/3000, score: 70, cumulative reward: -158.10182002556866\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1461/3000, score: 68, cumulative reward: -150.9649601133132\n",
      "Episode: 1462/3000, score: 50, cumulative reward: -100.31669670806136\n",
      "Episode: 1463/3000, score: 53, cumulative reward: -97.93502423278025\n",
      "Episode: 1464/3000, score: 61, cumulative reward: -129.6018589201065\n",
      "Episode: 1465/3000, score: 59, cumulative reward: -127.33378143993787\n",
      "Episode: 1466/3000, score: 61, cumulative reward: -127.77467013855315\n",
      "Episode: 1467/3000, score: 64, cumulative reward: -131.35631794734502\n",
      "Episode: 1468/3000, score: 55, cumulative reward: -132.46578092163742\n",
      "Episode: 1469/3000, score: 61, cumulative reward: -105.45774299768078\n",
      "Episode: 1470/3000, score: 65, cumulative reward: -116.5250016150422\n",
      "Episode: 1471/3000, score: 71, cumulative reward: -160.9839235449574\n",
      "Episode: 1472/3000, score: 51, cumulative reward: -132.64440921164157\n",
      "Episode: 1473/3000, score: 64, cumulative reward: -135.02030192400898\n",
      "Episode: 1474/3000, score: 76, cumulative reward: -159.77949976912234\n",
      "Episode: 1475/3000, score: 51, cumulative reward: -95.69927976979122\n",
      "Episode: 1476/3000, score: 75, cumulative reward: -169.99523223346984\n",
      "Episode: 1477/3000, score: 78, cumulative reward: -127.68994621560822\n",
      "Episode: 1478/3000, score: 52, cumulative reward: -150.37042515823262\n",
      "Episode: 1479/3000, score: 86, cumulative reward: -146.5590530114418\n",
      "Episode: 1480/3000, score: 56, cumulative reward: -113.06990853161041\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1481/3000, score: 53, cumulative reward: -65.00358432065401\n",
      "Episode: 1482/3000, score: 56, cumulative reward: -95.7844531487483\n",
      "Episode: 1483/3000, score: 55, cumulative reward: -149.97601605867544\n",
      "Episode: 1484/3000, score: 50, cumulative reward: -77.22655806909938\n",
      "Episode: 1485/3000, score: 80, cumulative reward: -127.72883744936127\n",
      "Episode: 1486/3000, score: 78, cumulative reward: -128.16265488400967\n",
      "Episode: 1487/3000, score: 77, cumulative reward: -131.11570482733703\n",
      "Episode: 1488/3000, score: 60, cumulative reward: -124.94079746478752\n",
      "Episode: 1489/3000, score: 77, cumulative reward: -94.96908759496841\n",
      "Episode: 1490/3000, score: 51, cumulative reward: -110.2809058665056\n",
      "Episode: 1491/3000, score: 66, cumulative reward: -156.9280916513452\n",
      "Episode: 1492/3000, score: 82, cumulative reward: -137.55351763147326\n",
      "Episode: 1493/3000, score: 72, cumulative reward: -180.6293460341432\n",
      "Episode: 1494/3000, score: 77, cumulative reward: -162.36107603246072\n",
      "Episode: 1495/3000, score: 49, cumulative reward: -122.52839049026525\n",
      "Episode: 1496/3000, score: 89, cumulative reward: -42.85608415123187\n",
      "Episode: 1497/3000, score: 79, cumulative reward: -111.91995190489294\n",
      "Episode: 1498/3000, score: 82, cumulative reward: -107.13162013633874\n",
      "Episode: 1499/3000, score: 87, cumulative reward: -199.45424913362126\n",
      "Episode: 1500/3000, score: 88, cumulative reward: -99.20124328697014\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1501/3000, score: 72, cumulative reward: -164.25317461618383\n",
      "Episode: 1502/3000, score: 62, cumulative reward: -122.86069991110534\n",
      "Episode: 1503/3000, score: 90, cumulative reward: -154.96767614400022\n",
      "Episode: 1504/3000, score: 76, cumulative reward: -180.612948624465\n",
      "Episode: 1505/3000, score: 86, cumulative reward: -63.36357617810148\n",
      "Episode: 1506/3000, score: 62, cumulative reward: -152.29642625694106\n",
      "Episode: 1507/3000, score: 77, cumulative reward: -151.38160479313675\n",
      "Episode: 1508/3000, score: 53, cumulative reward: -92.66673213391962\n",
      "Episode: 1509/3000, score: 60, cumulative reward: -111.15720056156084\n",
      "Episode: 1510/3000, score: 58, cumulative reward: -110.86253664555119\n",
      "Episode: 1511/3000, score: 78, cumulative reward: -160.51832237322165\n",
      "Episode: 1512/3000, score: 87, cumulative reward: -92.29146944943791\n",
      "Episode: 1513/3000, score: 61, cumulative reward: -123.45000304103861\n",
      "Episode: 1514/3000, score: 59, cumulative reward: -127.31930148421341\n",
      "Episode: 1515/3000, score: 72, cumulative reward: -144.2859194845613\n",
      "Episode: 1516/3000, score: 55, cumulative reward: -101.35946356564534\n",
      "Episode: 1517/3000, score: 60, cumulative reward: -141.25041513298515\n",
      "Episode: 1518/3000, score: 63, cumulative reward: -157.792042422219\n",
      "Episode: 1519/3000, score: 89, cumulative reward: -115.82092526665818\n",
      "Episode: 1520/3000, score: 82, cumulative reward: -151.99532577039423\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1521/3000, score: 70, cumulative reward: -156.3681148477053\n",
      "Episode: 1522/3000, score: 81, cumulative reward: -150.59468822285385\n",
      "Episode: 1523/3000, score: 55, cumulative reward: -89.90889151326392\n",
      "Episode: 1524/3000, score: 81, cumulative reward: -105.7102568959287\n",
      "Episode: 1525/3000, score: 63, cumulative reward: -148.9008608916342\n",
      "Episode: 1526/3000, score: 87, cumulative reward: -130.09945962232297\n",
      "Episode: 1527/3000, score: 98, cumulative reward: -301.2348019866504\n",
      "Episode: 1530/3000, score: 58, cumulative reward: -141.68948727831992\n",
      "Episode: 1531/3000, score: 56, cumulative reward: -137.5126841160842\n",
      "Episode: 1532/3000, score: 90, cumulative reward: -173.2914146265395\n",
      "Episode: 1533/3000, score: 62, cumulative reward: -135.21636050395097\n",
      "Episode: 1534/3000, score: 58, cumulative reward: -127.99310137596896\n",
      "Episode: 1535/3000, score: 83, cumulative reward: -166.6757938355538\n",
      "Episode: 1536/3000, score: 74, cumulative reward: -165.95341571798562\n",
      "Episode: 1538/3000, score: 60, cumulative reward: -513.0135122351161\n",
      "Episode: 1539/3000, score: 53, cumulative reward: -413.3647363275078\n",
      "Episode: 1540/3000, score: 89, cumulative reward: -359.55416427286684\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1541/3000, score: 53, cumulative reward: -116.43456146360029\n",
      "Episode: 1542/3000, score: 53, cumulative reward: -82.77445184236132\n",
      "Episode: 1543/3000, score: 52, cumulative reward: -238.9355094841333\n",
      "Episode: 1544/3000, score: 84, cumulative reward: -462.0858850462098\n",
      "Episode: 1545/3000, score: 55, cumulative reward: -110.08613935286424\n",
      "Episode: 1546/3000, score: 90, cumulative reward: -169.49445027398178\n",
      "Episode: 1547/3000, score: 66, cumulative reward: -605.0568942059566\n",
      "Episode: 1548/3000, score: 64, cumulative reward: -501.03891993040065\n",
      "Episode: 1549/3000, score: 87, cumulative reward: -174.21559668512168\n",
      "Episode: 1550/3000, score: 66, cumulative reward: -463.98201255730123\n",
      "Episode: 1551/3000, score: 74, cumulative reward: -444.12577580184643\n",
      "Episode: 1552/3000, score: 76, cumulative reward: -152.56197965489676\n",
      "Episode: 1553/3000, score: 66, cumulative reward: -158.7655552605731\n",
      "Episode: 1554/3000, score: 69, cumulative reward: -324.6733317329786\n",
      "Episode: 1555/3000, score: 53, cumulative reward: -428.3362143954638\n",
      "Episode: 1556/3000, score: 85, cumulative reward: -484.76277534525474\n",
      "Episode: 1557/3000, score: 81, cumulative reward: -462.8526935795045\n",
      "Episode: 1558/3000, score: 49, cumulative reward: -378.65766716482455\n",
      "Episode: 1559/3000, score: 86, cumulative reward: -539.4870615622277\n",
      "Episode: 1560/3000, score: 64, cumulative reward: -578.3163712348537\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1561/3000, score: 74, cumulative reward: -611.216120070519\n",
      "Episode: 1563/3000, score: 85, cumulative reward: -373.6313074129661\n",
      "Episode: 1564/3000, score: 66, cumulative reward: -617.3829665693016\n",
      "Episode: 1565/3000, score: 52, cumulative reward: -133.64186365821445\n",
      "Episode: 1566/3000, score: 52, cumulative reward: -146.9992982182697\n",
      "Episode: 1567/3000, score: 56, cumulative reward: -437.80178411299823\n",
      "Episode: 1568/3000, score: 56, cumulative reward: -501.8430956515483\n",
      "Episode: 1569/3000, score: 73, cumulative reward: -746.5746231260856\n",
      "Episode: 1570/3000, score: 68, cumulative reward: -190.18708844542587\n",
      "Episode: 1571/3000, score: 67, cumulative reward: -528.0498785360128\n",
      "Episode: 1572/3000, score: 52, cumulative reward: -196.51285801457448\n",
      "Episode: 1573/3000, score: 50, cumulative reward: -137.35671330359202\n",
      "Episode: 1574/3000, score: 55, cumulative reward: -452.46409211279274\n",
      "Episode: 1575/3000, score: 54, cumulative reward: -203.0284951831427\n",
      "Episode: 1576/3000, score: 83, cumulative reward: -331.5463056173163\n",
      "Episode: 1577/3000, score: 69, cumulative reward: -537.6018810071075\n",
      "Episode: 1578/3000, score: 86, cumulative reward: -206.50546515301127\n",
      "Episode: 1579/3000, score: 73, cumulative reward: -703.4756069925772\n",
      "Episode: 1580/3000, score: 79, cumulative reward: -474.16298271849087\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1581/3000, score: 80, cumulative reward: -130.0118430536205\n",
      "Episode: 1582/3000, score: 54, cumulative reward: -158.44231318821952\n",
      "Episode: 1583/3000, score: 49, cumulative reward: -427.1865214864269\n",
      "Episode: 1584/3000, score: 61, cumulative reward: -479.3686540636611\n",
      "Episode: 1585/3000, score: 57, cumulative reward: -410.68833723843596\n",
      "Episode: 1586/3000, score: 54, cumulative reward: -195.2405868984119\n",
      "Episode: 1587/3000, score: 59, cumulative reward: -156.2701515811258\n",
      "Episode: 1588/3000, score: 58, cumulative reward: -102.25641248039265\n",
      "Episode: 1589/3000, score: 84, cumulative reward: -590.006031066975\n",
      "Episode: 1590/3000, score: 81, cumulative reward: -304.59936605652797\n",
      "Episode: 1591/3000, score: 82, cumulative reward: -197.7493738556364\n",
      "Episode: 1592/3000, score: 86, cumulative reward: -251.77770547310894\n",
      "Episode: 1593/3000, score: 91, cumulative reward: -206.9554765405226\n",
      "Episode: 1595/3000, score: 83, cumulative reward: -131.03697061678142\n",
      "Episode: 1596/3000, score: 51, cumulative reward: -119.98949129423252\n",
      "Episode: 1597/3000, score: 55, cumulative reward: -131.24437427920276\n",
      "Episode: 1598/3000, score: 57, cumulative reward: -99.91930411229836\n",
      "Episode: 1599/3000, score: 68, cumulative reward: -143.63227216807914\n",
      "Episode: 1600/3000, score: 62, cumulative reward: 0.6263217506381409\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1601/3000, score: 70, cumulative reward: -149.02351134571236\n",
      "Episode: 1602/3000, score: 53, cumulative reward: -116.98346390279488\n",
      "Episode: 1603/3000, score: 70, cumulative reward: -162.5918511520893\n",
      "Episode: 1604/3000, score: 52, cumulative reward: -137.9437250806534\n",
      "Episode: 1605/3000, score: 66, cumulative reward: -43.416046780775815\n",
      "Episode: 1606/3000, score: 83, cumulative reward: -87.74093155579324\n",
      "Episode: 1607/3000, score: 53, cumulative reward: -138.15751584276228\n",
      "Episode: 1608/3000, score: 73, cumulative reward: -110.92298447354003\n",
      "Episode: 1609/3000, score: 67, cumulative reward: -124.87918116776586\n",
      "Episode: 1610/3000, score: 56, cumulative reward: -118.26170348252995\n",
      "Episode: 1611/3000, score: 88, cumulative reward: -168.7481252131156\n",
      "Episode: 1612/3000, score: 62, cumulative reward: -113.13738048137904\n",
      "Episode: 1613/3000, score: 52, cumulative reward: -90.24509956282446\n",
      "Episode: 1614/3000, score: 57, cumulative reward: -119.84744643028642\n",
      "Episode: 1615/3000, score: 71, cumulative reward: -134.253538138932\n",
      "Episode: 1616/3000, score: 83, cumulative reward: -95.85745472178837\n",
      "Episode: 1617/3000, score: 53, cumulative reward: -130.9626817925253\n",
      "Episode: 1618/3000, score: 65, cumulative reward: -159.91229539971783\n",
      "Episode: 1619/3000, score: 76, cumulative reward: -167.36022965411743\n",
      "Episode: 1620/3000, score: 95, cumulative reward: 21.285225297818045\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1621/3000, score: 61, cumulative reward: -98.28438526591165\n",
      "Episode: 1622/3000, score: 61, cumulative reward: -151.34870296253297\n",
      "Episode: 1623/3000, score: 63, cumulative reward: -113.07630094164942\n",
      "Episode: 1624/3000, score: 59, cumulative reward: -126.83765399338333\n",
      "Episode: 1625/3000, score: 89, cumulative reward: -139.11655150906358\n",
      "Episode: 1626/3000, score: 71, cumulative reward: -144.34203403580437\n",
      "Episode: 1627/3000, score: 77, cumulative reward: -131.57872246883403\n",
      "Episode: 1628/3000, score: 57, cumulative reward: -146.7559326576093\n",
      "Episode: 1629/3000, score: 62, cumulative reward: -165.5284672027204\n",
      "Episode: 1630/3000, score: 77, cumulative reward: -124.69990320934258\n",
      "Episode: 1631/3000, score: 64, cumulative reward: -125.75751624912289\n",
      "Episode: 1632/3000, score: 58, cumulative reward: -134.51180113709597\n",
      "Episode: 1633/3000, score: 76, cumulative reward: -144.43062748440224\n",
      "Episode: 1634/3000, score: 73, cumulative reward: -144.1014685949244\n",
      "Episode: 1635/3000, score: 65, cumulative reward: -157.0606607128587\n",
      "Episode: 1636/3000, score: 50, cumulative reward: -120.17429264083306\n",
      "Episode: 1637/3000, score: 90, cumulative reward: -106.88083064702604\n",
      "Episode: 1638/3000, score: 51, cumulative reward: -97.48957682494026\n",
      "Episode: 1639/3000, score: 68, cumulative reward: -141.03455555487037\n",
      "Episode: 1640/3000, score: 52, cumulative reward: -137.06615061407615\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1641/3000, score: 69, cumulative reward: -136.97565805478123\n",
      "Episode: 1642/3000, score: 79, cumulative reward: -153.10590966738567\n",
      "Episode: 1643/3000, score: 61, cumulative reward: -111.91803611025361\n",
      "Episode: 1644/3000, score: 79, cumulative reward: -137.95077010702425\n",
      "Episode: 1645/3000, score: 82, cumulative reward: -3.1215452741272145\n",
      "Episode: 1646/3000, score: 64, cumulative reward: -129.81635964558092\n",
      "Episode: 1647/3000, score: 66, cumulative reward: -128.81644013807488\n",
      "Episode: 1648/3000, score: 69, cumulative reward: -136.82544112917444\n",
      "Episode: 1649/3000, score: 77, cumulative reward: -143.68434714268088\n",
      "Episode: 1650/3000, score: 77, cumulative reward: -109.99416635928256\n",
      "Episode: 1651/3000, score: 85, cumulative reward: -107.39174940017986\n",
      "Episode: 1652/3000, score: 73, cumulative reward: -99.95087778982753\n",
      "Episode: 1653/3000, score: 66, cumulative reward: -153.39475505553793\n",
      "Episode: 1654/3000, score: 81, cumulative reward: -147.87162754554953\n",
      "Episode: 1655/3000, score: 54, cumulative reward: -97.55794796104456\n",
      "Episode: 1656/3000, score: 54, cumulative reward: -121.94423277300007\n",
      "Episode: 1657/3000, score: 88, cumulative reward: -140.7650723740034\n",
      "Episode: 1658/3000, score: 80, cumulative reward: -125.787366154202\n",
      "Episode: 1659/3000, score: 71, cumulative reward: -183.50663489976557\n",
      "Episode: 1660/3000, score: 63, cumulative reward: -147.9586168967337\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1661/3000, score: 52, cumulative reward: -108.49786764274151\n",
      "Episode: 1662/3000, score: 70, cumulative reward: -125.89512266720351\n",
      "Episode: 1663/3000, score: 56, cumulative reward: -98.74978291452638\n",
      "Episode: 1664/3000, score: 72, cumulative reward: -151.5450972391468\n",
      "Episode: 1665/3000, score: 64, cumulative reward: -125.9063340262011\n",
      "Episode: 1666/3000, score: 90, cumulative reward: -87.32147766326696\n",
      "Episode: 1667/3000, score: 78, cumulative reward: -218.6580809742402\n",
      "Episode: 1668/3000, score: 96, cumulative reward: -3.189262917476441\n",
      "Episode: 1669/3000, score: 68, cumulative reward: -123.90237596366292\n",
      "Episode: 1670/3000, score: 85, cumulative reward: -112.65511227185343\n",
      "Episode: 1671/3000, score: 87, cumulative reward: -37.36481665907169\n",
      "Episode: 1672/3000, score: 61, cumulative reward: -135.67999174934457\n",
      "Episode: 1674/3000, score: 62, cumulative reward: -113.925164884232\n",
      "Episode: 1675/3000, score: 56, cumulative reward: -150.433016444579\n",
      "Episode: 1676/3000, score: 60, cumulative reward: -116.5004470105888\n",
      "Episode: 1677/3000, score: 73, cumulative reward: -143.36212939659268\n",
      "Episode: 1678/3000, score: 84, cumulative reward: -146.17105834825554\n",
      "Episode: 1679/3000, score: 56, cumulative reward: -135.6818532385384\n",
      "Episode: 1680/3000, score: 61, cumulative reward: -114.76056378083655\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1681/3000, score: 65, cumulative reward: -11.299782038905875\n",
      "Episode: 1682/3000, score: 71, cumulative reward: -122.90993155997577\n",
      "Episode: 1683/3000, score: 73, cumulative reward: -30.347597935973823\n",
      "Episode: 1684/3000, score: 87, cumulative reward: -216.08476232001894\n",
      "Episode: 1685/3000, score: 71, cumulative reward: -167.47645328162525\n",
      "Episode: 1686/3000, score: 86, cumulative reward: -156.2778036259611\n",
      "Episode: 1687/3000, score: 76, cumulative reward: -142.55635701460417\n",
      "Episode: 1688/3000, score: 79, cumulative reward: -121.36426592811623\n",
      "Episode: 1689/3000, score: 92, cumulative reward: -160.80307115690815\n",
      "Episode: 1690/3000, score: 75, cumulative reward: -125.1725270691706\n",
      "Episode: 1691/3000, score: 61, cumulative reward: -152.97459761764216\n",
      "Episode: 1692/3000, score: 53, cumulative reward: -145.23074375638168\n",
      "Episode: 1693/3000, score: 76, cumulative reward: -121.16495787673381\n",
      "Episode: 1694/3000, score: 83, cumulative reward: -120.02044247792878\n",
      "Episode: 1695/3000, score: 74, cumulative reward: -153.1660876172901\n",
      "Episode: 1696/3000, score: 71, cumulative reward: -175.05355191334993\n",
      "Episode: 1697/3000, score: 75, cumulative reward: -185.36114208088003\n",
      "Episode: 1698/3000, score: 72, cumulative reward: -122.61133385506464\n",
      "Episode: 1699/3000, score: 54, cumulative reward: -92.31884351744648\n",
      "Episode: 1700/3000, score: 82, cumulative reward: -61.40501987736104\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1701/3000, score: 73, cumulative reward: -122.13976337275207\n",
      "Episode: 1702/3000, score: 62, cumulative reward: -50.80662734551859\n",
      "Episode: 1705/3000, score: 68, cumulative reward: -139.0900632391934\n",
      "Episode: 1706/3000, score: 61, cumulative reward: -166.27311594896514\n",
      "Episode: 1707/3000, score: 69, cumulative reward: -155.45525850817225\n",
      "Episode: 1708/3000, score: 64, cumulative reward: -114.35501711811015\n",
      "Episode: 1709/3000, score: 57, cumulative reward: -94.96791697994331\n",
      "Episode: 1711/3000, score: 61, cumulative reward: -130.46690312663716\n",
      "Episode: 1712/3000, score: 52, cumulative reward: -341.76192457363675\n",
      "Episode: 1713/3000, score: 58, cumulative reward: -346.7981472709346\n",
      "Episode: 1714/3000, score: 52, cumulative reward: -132.58140082654577\n",
      "Episode: 1715/3000, score: 79, cumulative reward: -76.4535161716167\n",
      "Episode: 1716/3000, score: 62, cumulative reward: -137.21351696490208\n",
      "Episode: 1717/3000, score: 60, cumulative reward: -157.55153348275877\n",
      "Episode: 1718/3000, score: 86, cumulative reward: -148.45470714178387\n",
      "Episode: 1719/3000, score: 85, cumulative reward: -108.60666154907761\n",
      "Episode: 1720/3000, score: 60, cumulative reward: -123.36626385420772\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1721/3000, score: 59, cumulative reward: -166.4848273479194\n",
      "Episode: 1722/3000, score: 51, cumulative reward: -135.70087867659834\n",
      "Episode: 1723/3000, score: 66, cumulative reward: -129.31684718063423\n",
      "Episode: 1724/3000, score: 59, cumulative reward: -107.36579905107371\n",
      "Episode: 1725/3000, score: 82, cumulative reward: -125.10463572716088\n",
      "Episode: 1726/3000, score: 62, cumulative reward: 4.910875700016618\n",
      "Episode: 1727/3000, score: 82, cumulative reward: -101.08390830872747\n",
      "Episode: 1728/3000, score: 80, cumulative reward: -178.848417975245\n",
      "Episode: 1729/3000, score: 65, cumulative reward: -118.0399673100757\n",
      "Episode: 1730/3000, score: 76, cumulative reward: -207.76426693831723\n",
      "Episode: 1731/3000, score: 51, cumulative reward: -393.497770708715\n",
      "Episode: 1732/3000, score: 56, cumulative reward: -271.25911957868686\n",
      "Episode: 1733/3000, score: 70, cumulative reward: -126.20121570391345\n",
      "Episode: 1734/3000, score: 56, cumulative reward: -222.7048885971127\n",
      "Episode: 1735/3000, score: 71, cumulative reward: -503.7564342929426\n",
      "Episode: 1736/3000, score: 66, cumulative reward: -55.98895761558639\n",
      "Episode: 1737/3000, score: 83, cumulative reward: -435.5731583095858\n",
      "Episode: 1739/3000, score: 67, cumulative reward: -144.61758716628665\n",
      "Episode: 1740/3000, score: 57, cumulative reward: -72.12334524330097\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1741/3000, score: 94, cumulative reward: -535.6993113388\n",
      "Episode: 1743/3000, score: 66, cumulative reward: -652.9719044406787\n",
      "Episode: 1744/3000, score: 57, cumulative reward: -249.57719666633193\n",
      "Episode: 1745/3000, score: 67, cumulative reward: -406.7921769554137\n",
      "Episode: 1746/3000, score: 74, cumulative reward: -160.38182515037528\n",
      "Episode: 1747/3000, score: 87, cumulative reward: -192.75677671519279\n",
      "Episode: 1748/3000, score: 72, cumulative reward: -149.07477226652145\n",
      "Episode: 1749/3000, score: 50, cumulative reward: -81.36710402416088\n",
      "Episode: 1750/3000, score: 65, cumulative reward: -114.70317245418147\n",
      "Episode: 1751/3000, score: 80, cumulative reward: -122.61513913066055\n",
      "Episode: 1752/3000, score: 78, cumulative reward: -374.80913154156724\n",
      "Episode: 1754/3000, score: 64, cumulative reward: -378.11518259985786\n",
      "Episode: 1755/3000, score: 55, cumulative reward: -111.8446573431837\n",
      "Episode: 1756/3000, score: 70, cumulative reward: -137.76709563241923\n",
      "Episode: 1757/3000, score: 92, cumulative reward: -160.21039876692464\n",
      "Episode: 1758/3000, score: 54, cumulative reward: -123.27571142364994\n",
      "Episode: 1759/3000, score: 88, cumulative reward: -155.92241961327804\n",
      "Episode: 1760/3000, score: 85, cumulative reward: -666.5712655300831\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1761/3000, score: 79, cumulative reward: -685.1693673464238\n",
      "Episode: 1762/3000, score: 72, cumulative reward: -613.4549833029301\n",
      "Episode: 1763/3000, score: 70, cumulative reward: -452.3475616881976\n",
      "Episode: 1764/3000, score: 62, cumulative reward: -160.57470313177026\n",
      "Episode: 1765/3000, score: 79, cumulative reward: -369.22956164357777\n",
      "Episode: 1766/3000, score: 52, cumulative reward: -138.7931535580191\n",
      "Episode: 1767/3000, score: 78, cumulative reward: -168.32744640194048\n",
      "Episode: 1768/3000, score: 74, cumulative reward: -166.67629350387952\n",
      "Episode: 1769/3000, score: 70, cumulative reward: -519.4329365813694\n",
      "Episode: 1770/3000, score: 56, cumulative reward: -524.3543482216292\n",
      "Episode: 1771/3000, score: 63, cumulative reward: -577.967653938354\n",
      "Episode: 1772/3000, score: 62, cumulative reward: -627.7617260813116\n",
      "Episode: 1775/3000, score: 52, cumulative reward: -106.6300566779841\n",
      "Episode: 1776/3000, score: 82, cumulative reward: -183.5239795129773\n",
      "Episode: 1777/3000, score: 87, cumulative reward: -143.5346316059546\n",
      "Episode: 1778/3000, score: 64, cumulative reward: -108.19734419506722\n",
      "Episode: 1779/3000, score: 55, cumulative reward: -394.435285750969\n",
      "Episode: 1780/3000, score: 64, cumulative reward: -487.9062074611314\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1782/3000, score: 91, cumulative reward: -213.19783613744698\n",
      "Episode: 1783/3000, score: 81, cumulative reward: -262.92400353060117\n",
      "Episode: 1784/3000, score: 56, cumulative reward: -226.65801869241758\n",
      "Episode: 1785/3000, score: 67, cumulative reward: -399.2462644661871\n",
      "Episode: 1786/3000, score: 67, cumulative reward: -550.2967340630616\n",
      "Episode: 1787/3000, score: 75, cumulative reward: -152.55306576683003\n",
      "Episode: 1788/3000, score: 55, cumulative reward: -318.733504232516\n",
      "Episode: 1789/3000, score: 57, cumulative reward: -68.92547670006236\n",
      "Episode: 1790/3000, score: 55, cumulative reward: -378.60962290916734\n",
      "Episode: 1791/3000, score: 62, cumulative reward: -527.2306952495895\n",
      "Episode: 1792/3000, score: 85, cumulative reward: -913.7639358256621\n",
      "Episode: 1793/3000, score: 54, cumulative reward: -468.2338796799834\n",
      "Episode: 1794/3000, score: 76, cumulative reward: -134.1592679626935\n",
      "Episode: 1795/3000, score: 86, cumulative reward: -139.67348235798164\n",
      "Episode: 1796/3000, score: 65, cumulative reward: -157.77458772636186\n",
      "Episode: 1797/3000, score: 57, cumulative reward: -341.6993938253686\n",
      "Episode: 1798/3000, score: 79, cumulative reward: -508.73245135711556\n",
      "Episode: 1799/3000, score: 75, cumulative reward: -403.3598334594468\n",
      "Episode: 1800/3000, score: 75, cumulative reward: -738.7617331012933\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1801/3000, score: 84, cumulative reward: -793.3693759491294\n",
      "Episode: 1802/3000, score: 59, cumulative reward: -141.95228115556566\n",
      "Episode: 1803/3000, score: 59, cumulative reward: -189.0483747689564\n",
      "Episode: 1804/3000, score: 55, cumulative reward: -240.42470483356692\n",
      "Episode: 1805/3000, score: 82, cumulative reward: -282.34374041047977\n",
      "Episode: 1806/3000, score: 51, cumulative reward: -448.50928482427094\n",
      "Episode: 1807/3000, score: 84, cumulative reward: -439.0983438502835\n",
      "Episode: 1808/3000, score: 90, cumulative reward: -926.9037158897889\n",
      "Episode: 1809/3000, score: 65, cumulative reward: -642.6944080817956\n",
      "Episode: 1812/3000, score: 57, cumulative reward: -143.93954981617168\n",
      "Episode: 1813/3000, score: 73, cumulative reward: -159.71210496900324\n",
      "Episode: 1814/3000, score: 73, cumulative reward: -489.2058914251355\n",
      "Episode: 1815/3000, score: 54, cumulative reward: -341.4195847779672\n",
      "Episode: 1816/3000, score: 68, cumulative reward: -479.30690289813583\n",
      "Episode: 1817/3000, score: 72, cumulative reward: -674.379523772896\n",
      "Episode: 1818/3000, score: 49, cumulative reward: -320.232771485464\n",
      "Episode: 1819/3000, score: 66, cumulative reward: -433.07605240536225\n",
      "Episode: 1820/3000, score: 60, cumulative reward: -537.417588383137\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1821/3000, score: 57, cumulative reward: -478.6853089580924\n",
      "Episode: 1822/3000, score: 50, cumulative reward: -415.56629189692507\n",
      "Episode: 1823/3000, score: 70, cumulative reward: -236.48890914763086\n",
      "Episode: 1824/3000, score: 64, cumulative reward: -172.13821390070282\n",
      "Episode: 1825/3000, score: 53, cumulative reward: -406.63059174393027\n",
      "Episode: 1826/3000, score: 71, cumulative reward: -154.9773099010061\n",
      "Episode: 1827/3000, score: 53, cumulative reward: -111.97643744736035\n",
      "Episode: 1828/3000, score: 53, cumulative reward: -100.05779890688555\n",
      "Episode: 1829/3000, score: 68, cumulative reward: -167.18364916883291\n",
      "Episode: 1830/3000, score: 67, cumulative reward: -128.68473365242372\n",
      "Episode: 1831/3000, score: 83, cumulative reward: -151.1450919827786\n",
      "Episode: 1832/3000, score: 67, cumulative reward: -133.7238285844597\n",
      "Episode: 1833/3000, score: 73, cumulative reward: -157.4606317554885\n",
      "Episode: 1834/3000, score: 54, cumulative reward: -130.12034074960508\n",
      "Episode: 1835/3000, score: 59, cumulative reward: -124.9694680281253\n",
      "Episode: 1836/3000, score: 57, cumulative reward: -143.98831817493954\n",
      "Episode: 1837/3000, score: 83, cumulative reward: -156.56941557556692\n",
      "Episode: 1838/3000, score: 74, cumulative reward: -132.41894142902737\n",
      "Episode: 1839/3000, score: 88, cumulative reward: -94.54610987155205\n",
      "Episode: 1840/3000, score: 62, cumulative reward: -108.80942483752153\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1841/3000, score: 51, cumulative reward: -129.18638251837015\n",
      "Episode: 1842/3000, score: 61, cumulative reward: -126.61235883142959\n",
      "Episode: 1843/3000, score: 53, cumulative reward: -124.3855715754056\n",
      "Episode: 1844/3000, score: 67, cumulative reward: -142.19868602041535\n",
      "Episode: 1845/3000, score: 60, cumulative reward: -108.35544882714868\n",
      "Episode: 1846/3000, score: 57, cumulative reward: -148.86343490358195\n",
      "Episode: 1847/3000, score: 66, cumulative reward: -118.67924601633663\n",
      "Episode: 1848/3000, score: 59, cumulative reward: 14.189435109641963\n",
      "Episode: 1849/3000, score: 53, cumulative reward: -127.07489772948276\n",
      "Episode: 1850/3000, score: 55, cumulative reward: -134.86903919884253\n",
      "Episode: 1851/3000, score: 63, cumulative reward: -112.16205588032668\n",
      "Episode: 1853/3000, score: 61, cumulative reward: -138.39112544056388\n",
      "Episode: 1854/3000, score: 79, cumulative reward: -119.72310980318812\n",
      "Episode: 1855/3000, score: 86, cumulative reward: -107.33978436340487\n",
      "Episode: 1856/3000, score: 53, cumulative reward: -128.68194379051096\n",
      "Episode: 1857/3000, score: 75, cumulative reward: -153.75200466931068\n",
      "Episode: 1858/3000, score: 90, cumulative reward: -137.7507671709948\n",
      "Episode: 1859/3000, score: 87, cumulative reward: -103.73846086926909\n",
      "Episode: 1860/3000, score: 50, cumulative reward: -109.7673654252583\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1861/3000, score: 50, cumulative reward: -107.0452438391106\n",
      "Episode: 1862/3000, score: 62, cumulative reward: -140.4868421641287\n",
      "Episode: 1863/3000, score: 76, cumulative reward: -147.33356934473613\n",
      "Episode: 1864/3000, score: 89, cumulative reward: -188.32223926490502\n",
      "Episode: 1865/3000, score: 51, cumulative reward: -80.61843189955255\n",
      "Episode: 1866/3000, score: 72, cumulative reward: 17.075802836686194\n",
      "Episode: 1867/3000, score: 60, cumulative reward: -144.83267146312235\n",
      "Episode: 1868/3000, score: 59, cumulative reward: -155.2705870707776\n",
      "Episode: 1869/3000, score: 74, cumulative reward: -163.67672698551917\n",
      "Episode: 1870/3000, score: 76, cumulative reward: -136.58535297474626\n",
      "Episode: 1871/3000, score: 73, cumulative reward: -112.24510645045439\n",
      "Episode: 1872/3000, score: 74, cumulative reward: -183.7950459792154\n",
      "Episode: 1873/3000, score: 66, cumulative reward: -109.12574084648361\n",
      "Episode: 1874/3000, score: 53, cumulative reward: -122.40012665707614\n",
      "Episode: 1875/3000, score: 64, cumulative reward: -145.61525338427288\n",
      "Episode: 1876/3000, score: 63, cumulative reward: -173.38252026085587\n",
      "Episode: 1877/3000, score: 60, cumulative reward: -169.9727265565296\n",
      "Episode: 1878/3000, score: 51, cumulative reward: -120.00657376811998\n",
      "Episode: 1879/3000, score: 62, cumulative reward: -134.6998573955072\n",
      "Episode: 1880/3000, score: 84, cumulative reward: -141.85651835794164\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1881/3000, score: 86, cumulative reward: -94.34886986744456\n",
      "Episode: 1882/3000, score: 55, cumulative reward: -97.79708092504512\n",
      "Episode: 1883/3000, score: 63, cumulative reward: -144.21590529923574\n",
      "Episode: 1884/3000, score: 60, cumulative reward: -152.05718861822805\n",
      "Episode: 1885/3000, score: 54, cumulative reward: -109.82610996023075\n",
      "Episode: 1886/3000, score: 59, cumulative reward: -159.3534578384938\n",
      "Episode: 1887/3000, score: 90, cumulative reward: -149.9126770611481\n",
      "Episode: 1888/3000, score: 56, cumulative reward: -110.75709707310577\n",
      "Episode: 1889/3000, score: 85, cumulative reward: -119.2624556853159\n",
      "Episode: 1890/3000, score: 71, cumulative reward: -146.99238137408497\n",
      "Episode: 1891/3000, score: 52, cumulative reward: -108.26048699153495\n",
      "Episode: 1892/3000, score: 64, cumulative reward: -139.1556983675592\n",
      "Episode: 1893/3000, score: 61, cumulative reward: -145.07958583417366\n",
      "Episode: 1894/3000, score: 72, cumulative reward: -120.95103730512494\n",
      "Episode: 1895/3000, score: 68, cumulative reward: -124.90110386417666\n",
      "Episode: 1896/3000, score: 58, cumulative reward: -138.91833025594752\n",
      "Episode: 1897/3000, score: 63, cumulative reward: -132.2933306733945\n",
      "Episode: 1898/3000, score: 53, cumulative reward: -86.09945850630444\n",
      "Episode: 1900/3000, score: 80, cumulative reward: -107.84911112417764\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1901/3000, score: 55, cumulative reward: -98.2305528862882\n",
      "Episode: 1902/3000, score: 64, cumulative reward: -118.32461663238693\n",
      "Episode: 1903/3000, score: 68, cumulative reward: -144.13973225885343\n",
      "Episode: 1904/3000, score: 84, cumulative reward: -126.63534134025699\n",
      "Episode: 1905/3000, score: 78, cumulative reward: -208.7103143445372\n",
      "Episode: 1906/3000, score: 87, cumulative reward: -144.98452502453958\n",
      "Episode: 1907/3000, score: 86, cumulative reward: -133.45494861708832\n",
      "Episode: 1908/3000, score: 67, cumulative reward: 5.888014328975402\n",
      "Episode: 1909/3000, score: 52, cumulative reward: -105.29598207590908\n",
      "Episode: 1910/3000, score: 67, cumulative reward: -147.40436985148534\n",
      "Episode: 1911/3000, score: 83, cumulative reward: -179.99019475983349\n",
      "Episode: 1912/3000, score: 75, cumulative reward: -165.36554501313114\n",
      "Episode: 1913/3000, score: 78, cumulative reward: -140.26129017823507\n",
      "Episode: 1914/3000, score: 79, cumulative reward: -149.5792167857929\n",
      "Episode: 1915/3000, score: 58, cumulative reward: -142.63589506791058\n",
      "Episode: 1916/3000, score: 50, cumulative reward: -114.21503897893575\n",
      "Episode: 1917/3000, score: 90, cumulative reward: -145.77980611106642\n",
      "Episode: 1918/3000, score: 88, cumulative reward: -109.23708452179184\n",
      "Episode: 1919/3000, score: 63, cumulative reward: -158.59145139957548\n",
      "Episode: 1920/3000, score: 90, cumulative reward: -240.60405656052748\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1921/3000, score: 77, cumulative reward: -132.59689276998947\n",
      "Episode: 1922/3000, score: 60, cumulative reward: -134.20753106066311\n",
      "Episode: 1923/3000, score: 55, cumulative reward: -125.4722683382733\n",
      "Episode: 1924/3000, score: 53, cumulative reward: -130.2598211902659\n",
      "Episode: 1925/3000, score: 71, cumulative reward: -151.7493159874447\n",
      "Episode: 1926/3000, score: 88, cumulative reward: -139.7407608082352\n",
      "Episode: 1927/3000, score: 87, cumulative reward: -93.91429870600211\n",
      "Episode: 1928/3000, score: 86, cumulative reward: -127.33068818911522\n",
      "Episode: 1929/3000, score: 56, cumulative reward: -144.78164932654113\n",
      "Episode: 1930/3000, score: 65, cumulative reward: -127.18630877671538\n",
      "Episode: 1932/3000, score: 74, cumulative reward: -174.63921793106792\n",
      "Episode: 1933/3000, score: 89, cumulative reward: -180.31894194536176\n",
      "Episode: 1934/3000, score: 58, cumulative reward: -151.67165976699272\n",
      "Episode: 1935/3000, score: 70, cumulative reward: -121.1174609654166\n",
      "Episode: 1936/3000, score: 62, cumulative reward: -135.9668736093133\n",
      "Episode: 1937/3000, score: 56, cumulative reward: -151.25833207226\n",
      "Episode: 1938/3000, score: 65, cumulative reward: -135.69098664205833\n",
      "Episode: 1939/3000, score: 77, cumulative reward: -73.32149610309409\n",
      "Episode: 1940/3000, score: 61, cumulative reward: -144.0304281749958\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1941/3000, score: 63, cumulative reward: -168.65208987047131\n",
      "Episode: 1942/3000, score: 91, cumulative reward: -177.57758982966737\n",
      "Episode: 1943/3000, score: 71, cumulative reward: -142.6688209417762\n",
      "Episode: 1944/3000, score: 61, cumulative reward: -142.27963576523422\n",
      "Episode: 1945/3000, score: 63, cumulative reward: -132.22321368631876\n",
      "Episode: 1946/3000, score: 54, cumulative reward: -130.05550438831247\n",
      "Episode: 1947/3000, score: 54, cumulative reward: -113.08513487162105\n",
      "Episode: 1948/3000, score: 51, cumulative reward: -128.3772800149513\n",
      "Episode: 1949/3000, score: 80, cumulative reward: -100.32100941664038\n",
      "Episode: 1950/3000, score: 64, cumulative reward: -146.78260131124716\n",
      "Episode: 1951/3000, score: 86, cumulative reward: -111.77265766519255\n",
      "Episode: 1952/3000, score: 75, cumulative reward: -154.81654645663238\n",
      "Episode: 1953/3000, score: 83, cumulative reward: -329.1978420680373\n",
      "Episode: 1954/3000, score: 52, cumulative reward: -81.83793868753861\n",
      "Episode: 1955/3000, score: 51, cumulative reward: -128.03899127066498\n",
      "Episode: 1956/3000, score: 81, cumulative reward: -159.45885763288464\n",
      "Episode: 1957/3000, score: 65, cumulative reward: -140.0400767564201\n",
      "Episode: 1958/3000, score: 51, cumulative reward: -399.6306244223278\n",
      "Episode: 1959/3000, score: 79, cumulative reward: -375.8756485947933\n",
      "Episode: 1960/3000, score: 77, cumulative reward: -142.5086592668366\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1961/3000, score: 88, cumulative reward: -300.07321700308927\n",
      "Episode: 1962/3000, score: 78, cumulative reward: -592.8404585355271\n",
      "Episode: 1963/3000, score: 82, cumulative reward: -537.1618458444359\n",
      "Episode: 1964/3000, score: 76, cumulative reward: -303.8612981969202\n",
      "Episode: 1965/3000, score: 80, cumulative reward: -324.2939846681779\n",
      "Episode: 1966/3000, score: 79, cumulative reward: -192.19914729794385\n",
      "Episode: 1967/3000, score: 50, cumulative reward: -46.79488439444748\n",
      "Episode: 1968/3000, score: 59, cumulative reward: -111.0170971716002\n",
      "Episode: 1969/3000, score: 76, cumulative reward: -147.49265736785148\n",
      "Episode: 1970/3000, score: 88, cumulative reward: -34.80169535293467\n",
      "Episode: 1971/3000, score: 57, cumulative reward: -446.5096363237806\n",
      "Episode: 1973/3000, score: 72, cumulative reward: -139.0098035748203\n",
      "Episode: 1974/3000, score: 62, cumulative reward: -155.15269112214776\n",
      "Episode: 1975/3000, score: 55, cumulative reward: -132.07155880046426\n",
      "Episode: 1976/3000, score: 83, cumulative reward: -146.71194139185215\n",
      "Episode: 1977/3000, score: 90, cumulative reward: -85.12129451350171\n",
      "Episode: 1979/3000, score: 62, cumulative reward: -90.57172138104437\n",
      "Episode: 1980/3000, score: 95, cumulative reward: -179.812795135252\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 1982/3000, score: 82, cumulative reward: -213.19528716155935\n",
      "Episode: 1984/3000, score: 82, cumulative reward: -609.0509773081658\n",
      "Episode: 1986/3000, score: 80, cumulative reward: -345.16048825185055\n",
      "Episode: 1987/3000, score: 68, cumulative reward: -149.84112458205922\n",
      "Episode: 1988/3000, score: 81, cumulative reward: -143.0216084769039\n",
      "Episode: 1989/3000, score: 80, cumulative reward: -134.37635617037103\n",
      "Episode: 1990/3000, score: 90, cumulative reward: -82.87986668237961\n",
      "Episode: 1991/3000, score: 92, cumulative reward: -431.12112746337186\n",
      "Episode: 1992/3000, score: 74, cumulative reward: -555.6584881963231\n",
      "Episode: 1993/3000, score: 71, cumulative reward: -154.592145985043\n",
      "Episode: 1994/3000, score: 66, cumulative reward: -163.54430680859218\n",
      "Episode: 1995/3000, score: 58, cumulative reward: -144.50063536961173\n",
      "Episode: 1996/3000, score: 62, cumulative reward: -158.34668529814113\n",
      "Episode: 1997/3000, score: 60, cumulative reward: -109.29073865664145\n",
      "Episode: 1998/3000, score: 90, cumulative reward: -160.65078285280396\n",
      "Episode: 1999/3000, score: 63, cumulative reward: -167.95702628986388\n",
      "Episode: 2000/3000, score: 63, cumulative reward: -116.88825880905887\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2001/3000, score: 87, cumulative reward: -87.55565991804716\n",
      "Episode: 2002/3000, score: 60, cumulative reward: -139.88380895851736\n",
      "Episode: 2003/3000, score: 80, cumulative reward: -151.90881512528566\n",
      "Episode: 2004/3000, score: 64, cumulative reward: -135.0895890149803\n",
      "Episode: 2005/3000, score: 65, cumulative reward: -122.23454297287842\n",
      "Episode: 2006/3000, score: 62, cumulative reward: -129.68731853348584\n",
      "Episode: 2007/3000, score: 61, cumulative reward: -134.447709602575\n",
      "Episode: 2008/3000, score: 70, cumulative reward: -116.70548714237637\n",
      "Episode: 2009/3000, score: 72, cumulative reward: -160.17698321924394\n",
      "Episode: 2010/3000, score: 51, cumulative reward: -88.21224589021514\n",
      "Episode: 2011/3000, score: 64, cumulative reward: -153.23109124721447\n",
      "Episode: 2012/3000, score: 90, cumulative reward: -268.8931051211132\n",
      "Episode: 2013/3000, score: 74, cumulative reward: -166.46534628941356\n",
      "Episode: 2014/3000, score: 61, cumulative reward: -164.18314406901203\n",
      "Episode: 2015/3000, score: 83, cumulative reward: -73.18459934351488\n",
      "Episode: 2016/3000, score: 83, cumulative reward: -125.74765846145029\n",
      "Episode: 2017/3000, score: 77, cumulative reward: -149.9869074470437\n",
      "Episode: 2018/3000, score: 62, cumulative reward: -126.01457537774694\n",
      "Episode: 2019/3000, score: 73, cumulative reward: -122.45163992081456\n",
      "Episode: 2020/3000, score: 85, cumulative reward: -107.1720069801697\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2021/3000, score: 51, cumulative reward: -108.4335240854519\n",
      "Episode: 2022/3000, score: 56, cumulative reward: -95.38616688981008\n",
      "Episode: 2023/3000, score: 77, cumulative reward: -139.7124298386634\n",
      "Episode: 2024/3000, score: 83, cumulative reward: -115.57519897701582\n",
      "Episode: 2025/3000, score: 81, cumulative reward: -222.49046196817233\n",
      "Episode: 2026/3000, score: 54, cumulative reward: -106.71860002421596\n",
      "Episode: 2027/3000, score: 53, cumulative reward: -142.99109959558825\n",
      "Episode: 2028/3000, score: 87, cumulative reward: -178.6558426448071\n",
      "Episode: 2029/3000, score: 56, cumulative reward: -146.8565975870651\n",
      "Episode: 2030/3000, score: 84, cumulative reward: -138.18254095083438\n",
      "Episode: 2031/3000, score: 60, cumulative reward: -351.1151820325131\n",
      "Episode: 2032/3000, score: 73, cumulative reward: -481.76267521321336\n",
      "Episode: 2033/3000, score: 76, cumulative reward: -517.6333757452462\n",
      "Episode: 2034/3000, score: 90, cumulative reward: -145.54491973579508\n",
      "Episode: 2035/3000, score: 67, cumulative reward: -134.49489198183397\n",
      "Episode: 2036/3000, score: 73, cumulative reward: -138.18956823092546\n",
      "Episode: 2037/3000, score: 69, cumulative reward: -692.6778532671908\n",
      "Episode: 2038/3000, score: 75, cumulative reward: -470.5253223267157\n",
      "Episode: 2039/3000, score: 56, cumulative reward: -127.16445927259852\n",
      "Episode: 2040/3000, score: 63, cumulative reward: -165.95555723259287\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2041/3000, score: 67, cumulative reward: -258.10898534917527\n",
      "Episode: 2042/3000, score: 79, cumulative reward: -604.1751618910025\n",
      "Episode: 2046/3000, score: 81, cumulative reward: -131.92675767378293\n",
      "Episode: 2047/3000, score: 85, cumulative reward: -180.28520290790098\n",
      "Episode: 2048/3000, score: 89, cumulative reward: -249.54571562321166\n",
      "Episode: 2049/3000, score: 79, cumulative reward: -674.7713756602938\n",
      "Episode: 2050/3000, score: 71, cumulative reward: -133.83392520261478\n",
      "Episode: 2051/3000, score: 63, cumulative reward: -181.12783503181143\n",
      "Episode: 2052/3000, score: 50, cumulative reward: -457.14946165296635\n",
      "Episode: 2053/3000, score: 63, cumulative reward: -462.2050402886681\n",
      "Episode: 2054/3000, score: 56, cumulative reward: -92.89541424773154\n",
      "Episode: 2055/3000, score: 57, cumulative reward: -34.19493643618458\n",
      "Episode: 2056/3000, score: 75, cumulative reward: -134.96800113386604\n",
      "Episode: 2057/3000, score: 52, cumulative reward: -111.74291216209951\n",
      "Episode: 2058/3000, score: 74, cumulative reward: -146.00636259753855\n",
      "Episode: 2059/3000, score: 59, cumulative reward: -492.77387924596763\n",
      "Episode: 2060/3000, score: 55, cumulative reward: -474.0960524833258\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2061/3000, score: 49, cumulative reward: -441.96867183956465\n",
      "Episode: 2062/3000, score: 50, cumulative reward: -309.7851655809567\n",
      "Episode: 2063/3000, score: 71, cumulative reward: -563.6930671625746\n",
      "Episode: 2064/3000, score: 74, cumulative reward: -137.8802302099858\n",
      "Episode: 2065/3000, score: 75, cumulative reward: -482.6475495088237\n",
      "Episode: 2066/3000, score: 82, cumulative reward: -771.2013096244667\n",
      "Episode: 2067/3000, score: 53, cumulative reward: -479.8186823552507\n",
      "Episode: 2068/3000, score: 56, cumulative reward: -405.74043984489475\n",
      "Episode: 2069/3000, score: 70, cumulative reward: -141.67281784862348\n",
      "Episode: 2070/3000, score: 81, cumulative reward: -247.56527147494492\n",
      "Episode: 2071/3000, score: 78, cumulative reward: -802.3836572921092\n",
      "Episode: 2072/3000, score: 58, cumulative reward: -540.6501770795035\n",
      "Episode: 2073/3000, score: 71, cumulative reward: -578.7146187542244\n",
      "Episode: 2074/3000, score: 53, cumulative reward: -440.607972386584\n",
      "Episode: 2076/3000, score: 88, cumulative reward: -996.768378397293\n",
      "Episode: 2078/3000, score: 81, cumulative reward: -406.61512767566614\n",
      "Episode: 2079/3000, score: 52, cumulative reward: -196.98757138493886\n",
      "Episode: 2080/3000, score: 72, cumulative reward: -609.8333556867269\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2081/3000, score: 53, cumulative reward: -437.24069806193944\n",
      "Episode: 2082/3000, score: 63, cumulative reward: -519.9974865997567\n",
      "Episode: 2083/3000, score: 80, cumulative reward: -707.3603891189017\n",
      "Episode: 2084/3000, score: 77, cumulative reward: -738.4855652350207\n",
      "Episode: 2085/3000, score: 61, cumulative reward: -274.8816289318696\n",
      "Episode: 2086/3000, score: 61, cumulative reward: -135.3033750930803\n",
      "Episode: 2087/3000, score: 63, cumulative reward: -152.539785021793\n",
      "Episode: 2088/3000, score: 51, cumulative reward: -142.37603530717993\n",
      "Episode: 2089/3000, score: 79, cumulative reward: -698.021163522075\n",
      "Episode: 2090/3000, score: 74, cumulative reward: -632.0333352146555\n",
      "Episode: 2091/3000, score: 49, cumulative reward: -305.3156454917224\n",
      "Episode: 2092/3000, score: 49, cumulative reward: -342.14042093362355\n",
      "Episode: 2093/3000, score: 72, cumulative reward: -731.0942197078194\n",
      "Episode: 2094/3000, score: 60, cumulative reward: -443.37890613020414\n",
      "Episode: 2095/3000, score: 83, cumulative reward: -144.2609454888575\n",
      "Episode: 2096/3000, score: 54, cumulative reward: -487.9130518679947\n",
      "Episode: 2097/3000, score: 53, cumulative reward: -402.93848094520405\n",
      "Episode: 2098/3000, score: 62, cumulative reward: -585.7950052107834\n",
      "Episode: 2099/3000, score: 71, cumulative reward: -515.8327071407516\n",
      "Episode: 2100/3000, score: 50, cumulative reward: -247.69595714453118\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2101/3000, score: 68, cumulative reward: -175.1281200287612\n",
      "Episode: 2102/3000, score: 71, cumulative reward: -413.87320489328664\n",
      "Episode: 2103/3000, score: 55, cumulative reward: -514.8565232990127\n",
      "Episode: 2104/3000, score: 65, cumulative reward: -626.2555426716262\n",
      "Episode: 2105/3000, score: 71, cumulative reward: -509.433899236871\n",
      "Episode: 2107/3000, score: 80, cumulative reward: -522.987978320768\n",
      "Episode: 2108/3000, score: 60, cumulative reward: -570.0638695038454\n",
      "Episode: 2109/3000, score: 50, cumulative reward: -408.96725823559177\n",
      "Episode: 2110/3000, score: 57, cumulative reward: -108.75287079953848\n",
      "Episode: 2111/3000, score: 93, cumulative reward: -402.0753599539388\n",
      "Episode: 2112/3000, score: 58, cumulative reward: -272.99938020822174\n",
      "Episode: 2113/3000, score: 71, cumulative reward: -510.53255094094493\n",
      "Episode: 2114/3000, score: 50, cumulative reward: -405.9310743721985\n",
      "Episode: 2115/3000, score: 97, cumulative reward: -631.569220370389\n",
      "Episode: 2116/3000, score: 71, cumulative reward: -508.36520490018097\n",
      "Episode: 2117/3000, score: 79, cumulative reward: -769.1039501209833\n",
      "Episode: 2118/3000, score: 63, cumulative reward: -471.45380558938723\n",
      "Episode: 2119/3000, score: 56, cumulative reward: -126.527457623587\n",
      "Episode: 2120/3000, score: 57, cumulative reward: -123.6997482042126\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2121/3000, score: 81, cumulative reward: -503.2289813861637\n",
      "Episode: 2122/3000, score: 59, cumulative reward: -537.1420579970513\n",
      "Episode: 2123/3000, score: 56, cumulative reward: -495.84349479290427\n",
      "Episode: 2124/3000, score: 47, cumulative reward: -407.0684301612527\n",
      "Episode: 2125/3000, score: 59, cumulative reward: -436.86658475409865\n",
      "Episode: 2126/3000, score: 59, cumulative reward: -106.34774995049176\n",
      "Episode: 2127/3000, score: 80, cumulative reward: -708.9463431186056\n",
      "Episode: 2128/3000, score: 79, cumulative reward: -722.7492163837139\n",
      "Episode: 2129/3000, score: 82, cumulative reward: -981.1999059316574\n",
      "Episode: 2130/3000, score: 67, cumulative reward: -533.7707591037354\n",
      "Episode: 2131/3000, score: 49, cumulative reward: -410.1393032626954\n",
      "Episode: 2132/3000, score: 56, cumulative reward: -426.09839127497696\n",
      "Episode: 2133/3000, score: 51, cumulative reward: -415.53762453682833\n",
      "Episode: 2134/3000, score: 82, cumulative reward: -694.2397720163784\n",
      "Episode: 2135/3000, score: 63, cumulative reward: -506.643914834928\n",
      "Episode: 2136/3000, score: 78, cumulative reward: -718.7736104974631\n",
      "Episode: 2137/3000, score: 67, cumulative reward: -431.4889010890076\n",
      "Episode: 2139/3000, score: 77, cumulative reward: -671.8454269400178\n",
      "Episode: 2140/3000, score: 74, cumulative reward: -461.1077296840076\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2141/3000, score: 79, cumulative reward: -684.2988284499363\n",
      "Episode: 2142/3000, score: 69, cumulative reward: -128.12427713254547\n",
      "Episode: 2143/3000, score: 62, cumulative reward: -146.67215177995973\n",
      "Episode: 2144/3000, score: 52, cumulative reward: -142.9796667404314\n",
      "Episode: 2145/3000, score: 68, cumulative reward: -670.1911619808409\n",
      "Episode: 2147/3000, score: 77, cumulative reward: -137.90023782621583\n",
      "Episode: 2148/3000, score: 89, cumulative reward: -131.46781801409784\n",
      "Episode: 2149/3000, score: 73, cumulative reward: -150.30405661541565\n",
      "Episode: 2150/3000, score: 84, cumulative reward: -111.37557316325635\n",
      "Episode: 2151/3000, score: 58, cumulative reward: -106.30666154281235\n",
      "Episode: 2152/3000, score: 79, cumulative reward: -157.39991885425832\n",
      "Episode: 2153/3000, score: 76, cumulative reward: -179.22800884584018\n",
      "Episode: 2154/3000, score: 54, cumulative reward: -116.14953389955866\n",
      "Episode: 2155/3000, score: 68, cumulative reward: -153.3583195006132\n",
      "Episode: 2156/3000, score: 92, cumulative reward: -162.17995041046908\n",
      "Episode: 2157/3000, score: 77, cumulative reward: -135.52313056803965\n",
      "Episode: 2158/3000, score: 65, cumulative reward: -124.22706913891298\n",
      "Episode: 2159/3000, score: 89, cumulative reward: -100.50335828261399\n",
      "Episode: 2160/3000, score: 56, cumulative reward: -92.88129906366004\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2161/3000, score: 56, cumulative reward: -104.29111498999455\n",
      "Episode: 2162/3000, score: 61, cumulative reward: -140.46107868687886\n",
      "Episode: 2163/3000, score: 56, cumulative reward: -126.42894463663264\n",
      "Episode: 2164/3000, score: 77, cumulative reward: -136.92342481948126\n",
      "Episode: 2165/3000, score: 53, cumulative reward: -148.32810677597172\n",
      "Episode: 2166/3000, score: 69, cumulative reward: -66.8460779263906\n",
      "Episode: 2167/3000, score: 72, cumulative reward: -182.2661342972405\n",
      "Episode: 2168/3000, score: 59, cumulative reward: -137.90765868656067\n",
      "Episode: 2169/3000, score: 67, cumulative reward: -125.34975774537915\n",
      "Episode: 2170/3000, score: 62, cumulative reward: 23.047329806313087\n",
      "Episode: 2171/3000, score: 63, cumulative reward: -132.42056678766755\n",
      "Episode: 2172/3000, score: 80, cumulative reward: -146.97452870169025\n",
      "Episode: 2173/3000, score: 58, cumulative reward: -149.95282045352326\n",
      "Episode: 2174/3000, score: 51, cumulative reward: -123.55754930367092\n",
      "Episode: 2175/3000, score: 62, cumulative reward: -147.81637465408113\n",
      "Episode: 2176/3000, score: 60, cumulative reward: -130.0271071746711\n",
      "Episode: 2177/3000, score: 84, cumulative reward: -88.74564653381248\n",
      "Episode: 2178/3000, score: 71, cumulative reward: -186.4955003450151\n",
      "Episode: 2179/3000, score: 67, cumulative reward: -126.0660311383559\n",
      "Episode: 2180/3000, score: 56, cumulative reward: -94.57999567828878\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2181/3000, score: 69, cumulative reward: -145.4779761227857\n",
      "Episode: 2182/3000, score: 57, cumulative reward: -104.29854705387686\n",
      "Episode: 2183/3000, score: 85, cumulative reward: -92.52933758815007\n",
      "Episode: 2185/3000, score: 80, cumulative reward: -104.47203095971595\n",
      "Episode: 2186/3000, score: 69, cumulative reward: -157.30612531822317\n",
      "Episode: 2187/3000, score: 56, cumulative reward: -116.93417848078707\n",
      "Episode: 2188/3000, score: 78, cumulative reward: -175.1362550579289\n",
      "Episode: 2189/3000, score: 54, cumulative reward: -131.81978787132837\n",
      "Episode: 2190/3000, score: 83, cumulative reward: -120.56193563373941\n",
      "Episode: 2191/3000, score: 87, cumulative reward: -151.42130111517594\n",
      "Episode: 2192/3000, score: 50, cumulative reward: -98.75404433920875\n",
      "Episode: 2193/3000, score: 58, cumulative reward: -133.0151857706227\n",
      "Episode: 2194/3000, score: 86, cumulative reward: -157.7252191848463\n",
      "Episode: 2195/3000, score: 81, cumulative reward: -144.1131002055778\n",
      "Episode: 2197/3000, score: 71, cumulative reward: -167.60267984023673\n",
      "Episode: 2198/3000, score: 73, cumulative reward: -197.87311272913777\n",
      "Episode: 2199/3000, score: 63, cumulative reward: -135.16396349512004\n",
      "Episode: 2200/3000, score: 79, cumulative reward: -96.67749118297985\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2201/3000, score: 73, cumulative reward: -186.69978855300542\n",
      "Episode: 2202/3000, score: 78, cumulative reward: -127.81835210425939\n",
      "Episode: 2203/3000, score: 85, cumulative reward: -173.23968453679686\n",
      "Episode: 2204/3000, score: 52, cumulative reward: -128.86544433287767\n",
      "Episode: 2205/3000, score: 66, cumulative reward: -96.79103755752345\n",
      "Episode: 2206/3000, score: 76, cumulative reward: -203.286066354259\n",
      "Episode: 2207/3000, score: 56, cumulative reward: -125.88432796481942\n",
      "Episode: 2208/3000, score: 70, cumulative reward: -146.96053836746563\n",
      "Episode: 2209/3000, score: 57, cumulative reward: -102.58670865941069\n",
      "Episode: 2210/3000, score: 56, cumulative reward: -94.09532078694835\n",
      "Episode: 2211/3000, score: 63, cumulative reward: -160.27885068589643\n",
      "Episode: 2212/3000, score: 68, cumulative reward: -124.52906363136972\n",
      "Episode: 2213/3000, score: 76, cumulative reward: -115.93163739111881\n",
      "Episode: 2214/3000, score: 58, cumulative reward: -131.4622977048308\n",
      "Episode: 2215/3000, score: 80, cumulative reward: -122.85885344183725\n",
      "Episode: 2216/3000, score: 67, cumulative reward: -122.41278734091617\n",
      "Episode: 2217/3000, score: 64, cumulative reward: 38.75775871671672\n",
      "Episode: 2218/3000, score: 67, cumulative reward: -170.32612830927164\n",
      "Episode: 2219/3000, score: 55, cumulative reward: -136.39382775883965\n",
      "Episode: 2220/3000, score: 52, cumulative reward: -79.79628379883047\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2221/3000, score: 79, cumulative reward: -101.48063886362527\n",
      "Episode: 2222/3000, score: 53, cumulative reward: -144.0285934472048\n",
      "Episode: 2223/3000, score: 72, cumulative reward: -1.2430067648955543\n",
      "Episode: 2224/3000, score: 54, cumulative reward: -109.79501060243393\n",
      "Episode: 2225/3000, score: 62, cumulative reward: -125.06375659343709\n",
      "Episode: 2226/3000, score: 80, cumulative reward: -174.69137933639138\n",
      "Episode: 2227/3000, score: 95, cumulative reward: -0.7982650704038718\n",
      "Episode: 2228/3000, score: 57, cumulative reward: -146.70185505117018\n",
      "Episode: 2229/3000, score: 62, cumulative reward: -147.7443887761033\n",
      "Episode: 2230/3000, score: 78, cumulative reward: -184.17985258380244\n",
      "Episode: 2231/3000, score: 82, cumulative reward: -183.7487739842608\n",
      "Episode: 2232/3000, score: 86, cumulative reward: -182.42766528582342\n",
      "Episode: 2233/3000, score: 60, cumulative reward: -141.48257881594228\n",
      "Episode: 2234/3000, score: 78, cumulative reward: -158.12262466524828\n",
      "Episode: 2235/3000, score: 65, cumulative reward: -133.2752169336298\n",
      "Episode: 2236/3000, score: 86, cumulative reward: -159.18687513644005\n",
      "Episode: 2237/3000, score: 71, cumulative reward: -158.29973690141833\n",
      "Episode: 2238/3000, score: 84, cumulative reward: -78.83814690933696\n",
      "Episode: 2239/3000, score: 66, cumulative reward: -141.8084755267103\n",
      "Episode: 2240/3000, score: 58, cumulative reward: -133.31759953956896\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2241/3000, score: 90, cumulative reward: -81.58508060970166\n",
      "Episode: 2242/3000, score: 79, cumulative reward: -114.84102228050082\n",
      "Episode: 2243/3000, score: 77, cumulative reward: -163.90595781387975\n",
      "Episode: 2244/3000, score: 65, cumulative reward: -114.04263278572293\n",
      "Episode: 2245/3000, score: 74, cumulative reward: -163.96066361909607\n",
      "Episode: 2246/3000, score: 74, cumulative reward: -194.21638373593964\n",
      "Episode: 2247/3000, score: 79, cumulative reward: -115.60337107307447\n",
      "Episode: 2248/3000, score: 52, cumulative reward: -146.9601127143917\n",
      "Episode: 2249/3000, score: 83, cumulative reward: -104.43253110575935\n",
      "Episode: 2250/3000, score: 88, cumulative reward: -98.021895766308\n",
      "Episode: 2251/3000, score: 55, cumulative reward: -144.19234032741463\n",
      "Episode: 2252/3000, score: 87, cumulative reward: -168.72283980641953\n",
      "Episode: 2253/3000, score: 86, cumulative reward: -118.88299319028957\n",
      "Episode: 2254/3000, score: 64, cumulative reward: -163.45955155347596\n",
      "Episode: 2255/3000, score: 67, cumulative reward: -129.90134041740006\n",
      "Episode: 2256/3000, score: 75, cumulative reward: -114.91847470642338\n",
      "Episode: 2257/3000, score: 59, cumulative reward: -102.44137200707125\n",
      "Episode: 2258/3000, score: 51, cumulative reward: -106.09629148071679\n",
      "Episode: 2259/3000, score: 67, cumulative reward: -120.63977675864709\n",
      "Episode: 2260/3000, score: 61, cumulative reward: -108.71237742714936\n",
      "模型状态字典已保存至 c:\\Users\\isrya\\#MyFiles\\#MyCode\\GithubUoL\\COMP532\\AS02\\models\\model_0.pth\n",
      "Episode: 2261/3000, score: 79, cumulative reward: -128.40658964558767\n",
      "Episode: 2262/3000, score: 56, cumulative reward: -147.94483757548855\n",
      "Episode: 2263/3000, score: 75, cumulative reward: -113.21377989473362\n",
      "Episode: 2264/3000, score: 82, cumulative reward: -155.62103037157001\n",
      "Episode: 2265/3000, score: 89, cumulative reward: -184.86606948805098\n",
      "Episode: 2266/3000, score: 56, cumulative reward: -112.29903607504903\n",
      "Episode: 2267/3000, score: 62, cumulative reward: -129.41428516827023\n",
      "Episode: 2268/3000, score: 63, cumulative reward: -114.74206060526691\n",
      "Episode: 2269/3000, score: 55, cumulative reward: -141.97791036751465\n",
      "Episode: 2270/3000, score: 65, cumulative reward: -147.19407335505318\n",
      "Episode: 2271/3000, score: 93, cumulative reward: -173.12479353814814\n",
      "Episode: 2272/3000, score: 51, cumulative reward: -110.64010832231708\n",
      "Episode: 2273/3000, score: 67, cumulative reward: -156.45808558563127\n",
      "Episode: 2274/3000, score: 58, cumulative reward: -117.49587644676981\n",
      "Episode: 2275/3000, score: 68, cumulative reward: -142.1819971109125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size: \u001b[38;5;66;03m# 当记忆库中的样本数量大于32时, 开始经验回放\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m agent\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 学习速率调度器更新\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 每100个episode结束后, 保存模型的状态字典\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 55\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     53\u001b[0m rewards \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(rewards, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m next_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(next_states, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m dones \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 打印所有张量的形状\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# print(\"states: \", states.shape)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# print(\"actions: \", actions.shape)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# print(\"rewards: \", rewards)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(\"next_states: \", next_states.shape)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"dones: \", dones.shape)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m Q_targets_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(next_states)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# 使用目标网络计算下一个状态的Q值, 用于计算目标Q值\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "batch_size = 64\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True) # 创建模型保存目录\n",
    "\n",
    "\n",
    "agent = DQNAgent(env.observation_space.shape[0], env.action_space.n)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "agent.model.to(device)  # 移动模型到GPU\n",
    "\n",
    "# 定义训练参数\n",
    "e_range = 3000\n",
    "time_range = 100\n",
    "\n",
    "for e in range(e_range): # 训练1000个episode\n",
    "    full_state = env.reset()\n",
    "    state = full_state[0] # 提取向量\n",
    "    # print(\"初始状态\", state)\n",
    "    state = torch.from_numpy(np.reshape(state, [1, -1])).float().to(device) # 把state转换为 网络模型 接受的形状\n",
    "    \n",
    "    cumulative_reward = 0  # 初始化累积奖励为0\n",
    "    \n",
    "    for time in range(time_range): # 一个episode最多执行500个时间步\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, truncated, info = env.step(action)  # 执行动作, 获取下一个状态, 奖励, 完成标志, 和\n",
    "        cumulative_reward += reward # 累积奖励\n",
    "        \n",
    "        # print(\"下一个状态\", next_state)\n",
    "        next_state = torch.from_numpy(np.reshape(next_state, [1, -1])).float().to(device) # 把next_state转换为 网络模型 接受的形状\n",
    "        reward = torch.tensor([reward], device=device) # 把reward转换为张量\n",
    "        done = torch.tensor([done], device=device)\n",
    "        \n",
    "        # agent.store(state, action, reward, next_state, done) # 存储经验\n",
    "        agent.store(state.cpu().numpy(), action, reward.cpu().numpy(), next_state.cpu().numpy(), done.cpu().numpy()) # 存储经验\n",
    "        state = next_state # 更新状态\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode: {}/{}, score: {}, cumulative reward: {}\".format(e, e_range, time, cumulative_reward)) # 打印每个episode的时间步数和累积奖励\n",
    "            break\n",
    "        if len(agent.memory) > batch_size: # 当记忆库中的样本数量大于32时, 开始经验回放\n",
    "            agent.replay(batch_size)\n",
    "            \n",
    "            \n",
    "    agent.scheduler.step()  # 学习速率调度器更新\n",
    "    \n",
    "    # 每100个episode结束后, 保存模型的状态字典\n",
    "    if e % 20 == 0:\n",
    "        model_path = os.path.join(model_dir, f\"model_0.pth\")  # 使用 f-string 包含 episode 数\n",
    "        torch.save(agent.model.state_dict(), model_path)\n",
    "        print(\"模型状态字典已保存至\", model_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished, reward:  -148.33966024162137\n",
      "Episode finished, reward:  -129.56642250217718\n",
      "Episode finished, reward:  -152.88066544844287\n",
      "Episode finished, reward:  -140.5931593800495\n",
      "Episode finished, reward:  -113.11040461008781\n",
      "Episode finished, reward:  -128.4038435086263\n",
      "Episode finished, reward:  -149.8433896797823\n",
      "Episode finished, reward:  -105.58485566217254\n",
      "Episode finished, reward:  -124.97611273002431\n",
      "Episode finished, reward:  -123.97436145284013\n",
      "Episode finished, reward:  -139.27758897290153\n",
      "Episode finished, reward:  -106.00463601449772\n",
      "Episode finished, reward:  -157.23882840667795\n",
      "Episode finished, reward:  -157.5075288521311\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import torch# 确保从包含DQN类定义的文件中导入\n",
    "import os\n",
    "\n",
    "# 假设状态空间和动作空间的维度已知\n",
    "state_size = 8  # 根据你的环境设置\n",
    "action_size = 4  # 根据你的环境设置\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "model_path = os.path.join(model_dir, \"model_0.pth\")\n",
    "\n",
    "model = DQN(state_size, action_size)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "cumulative_reward = 0  # 初始化累积奖励为0\n",
    "\n",
    "for _ in range(1000):\n",
    "    # 将观测转换为适合模型的格式\n",
    "    state = torch.tensor([observation], dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():  # 禁止torch追踪此处的梯度计算，因为我们在推理而不是训练\n",
    "        action = model(state).max(1)[1].item()  # 获取最大Q值对应的动作\n",
    "\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    cumulative_reward += reward # 累积奖励\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(\"Episode finished, reward: \", cumulative_reward)\n",
    "        observation, info = env.reset()\n",
    "        cumulative_reward = 0  # 重置累积奖励为0\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LUNARLANDER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
